{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipdb\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    #Activation Functions\n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "    def d_tanh(self, x):\n",
    "        return 1 - np.square(np.tanh(x))\n",
    "    def sigmoid(self, x):\n",
    "#         return 1/(1+ np.exp(-x))\n",
    "        return expit(x)\n",
    "    def d_sigmoid(self, x):\n",
    "        return (1 - self.sigmoid(x)) * self.sigmoid(x)\n",
    "    def ReLu(self, z):\n",
    "        return np.maximum(0, z)\n",
    "    def d_ReLu(self, Z):\n",
    "        return Z > 0\n",
    "    \n",
    "    #For output layer, useful for multiclass classification\n",
    "    def softmax(self, Z):\n",
    "#         expZ = np.exp(Z - np.max(Z))\n",
    "#         return expZ / expZ.sum(axis=0, keepdims=True)\n",
    "         return np.exp(Z) / sum(np.exp(Z))\n",
    "    def d_softmax(self, Z):\n",
    "        pass\n",
    "    \n",
    "    activationFunctions = {\n",
    "        'tanh': (tanh, d_tanh),\n",
    "        'sigmoid': (sigmoid, d_sigmoid),\n",
    "        'reLu': (ReLu, d_ReLu),\n",
    "        'softmax': (softmax, d_softmax)\n",
    "    }\n",
    "    \n",
    "    #Input -> num of neurons in prev layer, Neurons --> num neurons in cur layer, Activation -> activation fxn to use\n",
    "    def __init__(self, inputs, neurons, activation):\n",
    "        self.neurons = neurons\n",
    "        self.W = np.random.rand(neurons, inputs) - 0.5\n",
    "        self.b = np.random.rand(neurons, 1) - 0.5\n",
    "        self.Z = None\n",
    "        self.A_prev = None\n",
    "        self.act, self.d_act = self.activationFunctions.get(activation)\n",
    "        \n",
    "    def initializeWeights(self, inputs, neurons):\n",
    "        self.W = np.random.rand(neurons, inputs) - 0.5\n",
    "        \n",
    "    def getNeuronCount(self):\n",
    "        return self.neurons\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self.W;\n",
    "    \n",
    "    def feedForward(self, A_prev):\n",
    "        #ipdb.set_trace()\n",
    "        self.A_prev = A_prev\n",
    "        self.Z = self.W.dot(self.A_prev) + self.b\n",
    "        self.A = self.act(self, self.Z)\n",
    "        return self.A\n",
    "    \n",
    "    #All derivatives are wrt to cost\n",
    "    #Expects dA of cur layer\n",
    "    #Special case where doing multi class classification with mutli class logloss, you can get the dZ wrt dC directly without having to first get dA\n",
    "    def backprop(self, dA, learning_rate, dZ_Special):\n",
    "        \n",
    "        #ipdb.set_trace()\n",
    "        \n",
    "        #elementt by element matrix multip, not a normal dot prod since both matrices have same shape (essentialyl scalar)\n",
    "        dZ = np.multiply(self.d_act(self, self.Z), dA) if dZ_Special.any() == None else dZ_Special\n",
    "        \n",
    "         # need to normalize weights and divide by number of samples\n",
    "        # because it is actually a sum of weights\n",
    "        dW = 1/dZ.shape[1] * np.dot(dZ, self.A_prev.T)\n",
    "        \n",
    "        # this is to match shape since biases is supposed to be a col vector with 1 col but dZ has m cols\n",
    "        # w/ m being num of samples, we want to take avg of all samples in dZ (i.e on a row by row basis, sum of cols\n",
    "        # and divide by total num of smamples)\n",
    "        db = 1 / dZ.shape[1] * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        \n",
    "        dA_prev = np.dot(self.W.T, dZ)\n",
    "        \n",
    "        self.W = self.W - learning_rate * dW\n",
    "        self.b = self.b - learning_rate * db\n",
    "        return dA_prev\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    \n",
    "    #Loss Functions, mse for regression, logloss for classification\n",
    "    def mse(self, a, target):\n",
    "        return np.square(a-target)\n",
    "    \n",
    "    def d_mse(self, a, target):\n",
    "        return 2*(a-target)\n",
    "    \n",
    "    def binary_logloss(self, a, target):\n",
    "        return -(target*np.log(a) + (1-target)*np.log(1-a))\n",
    "    \n",
    "    def d_binary_logloss(self, a, target):\n",
    "        return (a - target)/(a*(1 - a))\n",
    "    \n",
    "    #Source - https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/discussion/2644\n",
    "    def multi_logloss(self, a, target, eps=1e-15):\n",
    "        predictions = np.clip(a, eps, 1 - eps)\n",
    "\n",
    "        # normalize row sums to 1\n",
    "        predictions /= predictions.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        return -np.sum(target * np.log(predictions))/predictions.shape[0]\n",
    "    \n",
    "    def d_multi_logloss(self, a, target):\n",
    "        return np.zeros(a.shape) # kinda just a placeholder\n",
    "    \n",
    "    lossFunctions = {\n",
    "        'mse': (mse, d_mse),\n",
    "        'binary_logloss': (binary_logloss, d_binary_logloss),\n",
    "        'multi_logloss': (multi_logloss, d_multi_logloss)\n",
    "    }\n",
    "        \n",
    "    #LossFunction is either mse of logloss\n",
    "    def __init__(self, lossFunction):\n",
    "        self.layers = []\n",
    "        self.learning_rate = 0.1\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 10\n",
    "        self.classification = False if lossFunction == 'mse' else True\n",
    "        self.lossFunction = lossFunction\n",
    "        self.loss, self.d_loss = self.lossFunctions.get(lossFunction)\n",
    "    \n",
    "    #Units is 1-n and activationFunction is 'ReLu', 'sigmoid', 'tanh', or 'softmax'\n",
    "    def addLayer(self, units, activationFunction):\n",
    "        prevLayerNeuronCount = self.layers[-1].getNeuronCount() if len(self.layers) > 0 else 0\n",
    "        self.layers.append(Layer(prevLayerNeuronCount, units, activationFunction))\n",
    "        \n",
    "    def getNumBatches(self, num_samples, batch_size):\n",
    "        if (num_samples == batch_size):\n",
    "            return 1\n",
    "        elif (num_samples > batch_size):\n",
    "            if (num_samples % batch_size == 0):\n",
    "                return num_samples // batch_size\n",
    "            else:\n",
    "                return (num_samples // batch_size) + 1\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    def oneHot(self, x):\n",
    "        one_hot_X = np.zeros((x.max() + 1, x.size)) #making a matrix of 10 x m\n",
    "        one_hot_X[x, np.arange(x.size)] = 1 #going through all cols and setting the row w/ index corresponding to the y to 1, its very easy to iterate over numpy arays like this apparently\n",
    "        return one_hot_X\n",
    "    \n",
    "    #Convert one hot encoded 2d array to original array of 1d\n",
    "    def rev_one_hot(self, target):\n",
    "        rev_one_hot = np.argmax(target, 0)\n",
    "        return rev_one_hot\n",
    "    #Compare two 1d arrays\n",
    "    def get_accuracy(self, target, Y, accuracy_buffer):\n",
    "        #ipdb.set_trace()\n",
    "        return np.sum(abs(target-Y)<accuracy_buffer) / Y.size\n",
    "    \n",
    "    def get_layer_weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights.append(layer.getWeights())\n",
    "        return weights\n",
    "    \n",
    "    def fit(self, X, y, epochs = None, batch_size = None, learning_rate = None, accuracy_buffer = 0.1):\n",
    "        self.learning_rate = learning_rate if learning_rate != None else self.learning_rate\n",
    "        self.epochs = epochs if epochs != None else self.epochs\n",
    "        self.batch_size = batch_size if batch_size != None else self.batch_size\n",
    "        \n",
    "        #Need at min one layer\n",
    "        if (len(self.layers) == 0):\n",
    "            raise ValueError('No layers have been added. Need at least one layer. Please add a layer') \n",
    "        \n",
    "        #multi class classificaiton problem need y to be one hot encoded and must use multi log loss\n",
    "        multiClassProblem = self.classification and (y.max() - y.min() > 1)\n",
    "        if (multiClassProblem):\n",
    "            y = self.oneHot(y)\n",
    "            if (self.lossFunction != 'multi_logloss'):\n",
    "                raise ValueError('Loss Function Must be multi_logloss for multi class classification')\n",
    "        \n",
    "        epoch_costs = []\n",
    "        batches_cost_sum = 0\n",
    "        num_batches = self.getNumBatches(X.shape[1], self.batch_size)\n",
    "        \n",
    "        #Initializing weights of the first layer \n",
    "        #Need to do it right now because shape of input isnt known until now\n",
    "        self.layers[0].initializeWeights(X.shape[0], self.layers[0].getNeuronCount())\n",
    "        \n",
    "        ###-----Epoch iterations, training occurs here-----###\n",
    "        for epoch in range(self.epochs):\n",
    "            batches_cost_sum = 0\n",
    "            for batch in range(num_batches):\n",
    "                \n",
    "                ###-----Obtaining appropriate batch data-----###\n",
    "                A = X[:, batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "                \n",
    "                if (multiClassProblem): \n",
    "                    y_curBatch = y[:, batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "                else:\n",
    "                    y_curBatch = y[batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "            \n",
    "                ###-----Performing forward prop and backprop-----###\n",
    "                for layer in self.layers:\n",
    "                    A = layer.feedForward(A)\n",
    "                batches_cost_sum += 1/self.batch_size * np.sum(self.loss(self, A, y_curBatch))\n",
    "                \n",
    "                #For multi class classiifcaiton problems (class > 2) and using softmax, deriv of softmax w.r.t to Zfinal is just actual - pred\n",
    "                dZ_Special = A - y_curBatch if multiClassProblem else np.array([None])\n",
    "                \n",
    "                #After the final output layer dA is found like this since A is just the output\n",
    "                dA = self.d_loss(self, A, y_curBatch)\n",
    "                \n",
    "                #Only final layer does the special dZ matter and only if multi class\n",
    "                for layer in reversed(self.layers):\n",
    "                    if (layer == self.layers[-1]):\n",
    "                        dA = layer.backprop(dA, self.learning_rate, dZ_Special)\n",
    "                    else:\n",
    "                        dA = layer.backprop(dA, self.learning_rate, np.array([None]))\n",
    "                \n",
    "                ###-----Logging Metrics-----###\n",
    "                if (epoch % 10 == 0 and batch == 0):\n",
    "                    print(\"-----Epoch: \", epoch, \"-----\")\n",
    "                    #ipdb.set_trace()\n",
    "                    if (multiClassProblem):\n",
    "                        A = self.rev_one_hot(A)\n",
    "                        y_curBatch = self.rev_one_hot(y_curBatch)\n",
    "                    print(\"Accuracy:\", self.get_accuracy(A, y_curBatch, accuracy_buffer))\n",
    "                    print(\"Cost:\", batches_cost_sum)\n",
    "            epoch_costs.append(batches_cost_sum) \n",
    "        return epoch_costs, self.get_layer_weights()\n",
    "        \n",
    "    def predict(self, X):\n",
    "        A = X\n",
    "        for layer in self.layers:\n",
    "            A = layer.feedForward(A)\n",
    "        return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  0 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27927069857202735\n",
      "-----Epoch:  10 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27811005913771764\n",
      "-----Epoch:  20 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2775411455177044\n",
      "-----Epoch:  30 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2772353833514493\n",
      "-----Epoch:  40 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2770465202935726\n",
      "-----Epoch:  50 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2769087322887515\n",
      "-----Epoch:  60 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2767920074102846\n",
      "-----Epoch:  70 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2766823705504178\n",
      "-----Epoch:  80 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2765730463064654\n",
      "-----Epoch:  90 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27646048678008744\n",
      "-----Epoch:  100 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.276342577494123\n",
      "-----Epoch:  110 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27621782264619016\n",
      "-----Epoch:  120 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27608497167549195\n",
      "-----Epoch:  130 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27594284466070645\n",
      "-----Epoch:  140 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2757902469315671\n",
      "-----Epoch:  150 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2756259232309336\n",
      "-----Epoch:  160 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27544852890019905\n",
      "-----Epoch:  170 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2752566078844265\n",
      "-----Epoch:  180 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2750485729832014\n",
      "-----Epoch:  190 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2748226863794005\n",
      "-----Epoch:  200 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2745770397233246\n",
      "-----Epoch:  210 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27430953368752775\n",
      "-----Epoch:  220 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27401785728029343\n",
      "-----Epoch:  230 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.273699467468898\n",
      "-----Epoch:  240 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27335156988940773\n",
      "-----Epoch:  250 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2729711016413069\n",
      "-----Epoch:  260 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27255471739794157\n",
      "-----Epoch:  270 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2720987803119718\n",
      "-----Epoch:  280 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2715993594541259\n",
      "-----Epoch:  290 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.271052235778764\n",
      "-----Epoch:  300 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27045291883392925\n",
      "-----Epoch:  310 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2697966765847934\n",
      "-----Epoch:  320 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.26907858073994945\n",
      "-----Epoch:  330 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.26829356978740343\n",
      "-----Epoch:  340 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2674365314793569\n",
      "-----Epoch:  350 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.26650240567082245\n",
      "-----Epoch:  360 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2654863071534181\n",
      "-----Epoch:  370 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2643836664096923\n",
      "-----Epoch:  380 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.26319038408976797\n",
      "-----Epoch:  390 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2619029926178408\n",
      "-----Epoch:  400 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2605188159148521\n",
      "-----Epoch:  410 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.259036116120485\n",
      "-----Epoch:  420 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2574542148243366\n",
      "-----Epoch:  430 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2557735760851396\n",
      "-----Epoch:  440 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2539958397499689\n",
      "-----Epoch:  450 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.25212379641591054\n",
      "-----Epoch:  460 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2501612996731404\n",
      "-----Epoch:  470 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2481131166076881\n",
      "-----Epoch:  480 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.24598472325196444\n",
      "-----Epoch:  490 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.24378205694047916\n",
      "-----Epoch:  500 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.24151124156278203\n",
      "-----Epoch:  510 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2391783038862629\n",
      "-----Epoch:  520 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.23678889912058307\n",
      "-----Epoch:  530 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2343480617213649\n",
      "-----Epoch:  540 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2318599933925728\n",
      "-----Epoch:  550 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.22932789486420538\n",
      "-----Epoch:  560 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.22675384191762712\n",
      "-----Epoch:  570 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.22413869995319718\n",
      "-----Epoch:  580 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.22148206579445137\n",
      "-----Epoch:  590 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.21878222108956846\n",
      "-----Epoch:  600 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.21603607939923056\n",
      "-----Epoch:  610 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.21323910979091304\n",
      "-----Epoch:  620 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.21038522452036995\n",
      "-----Epoch:  630 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.20746662805668006\n",
      "-----Epoch:  640 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.20447363960011034\n",
      "-----Epoch:  650 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.20139452044538603\n",
      "-----Epoch:  660 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.19821535828221346\n",
      "-----Epoch:  670 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.19492007784104579\n",
      "-----Epoch:  680 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.1914906547181765\n",
      "-----Epoch:  690 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.1879076011584232\n",
      "-----Epoch:  700 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.18415076829249322\n",
      "-----Epoch:  710 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.18020047604646589\n",
      "-----Epoch:  720 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.17603895208747417\n",
      "-----Epoch:  730 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.17165204046592095\n",
      "-----Epoch:  740 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.16703111444848545\n",
      "-----Epoch:  750 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.1621750656599253\n",
      "-----Epoch:  760 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.15709212960291655\n",
      "-----Epoch:  770 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.1518011874600466\n",
      "-----Epoch:  780 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.14633214493835786\n",
      "-----Epoch:  790 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.1407251022893766\n",
      "-----Epoch:  800 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.1350282831081664\n",
      "-----Epoch:  810 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.12929498605854114\n",
      "-----Epoch:  820 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.12358004467477424\n",
      "-----Epoch:  830 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.11793635263445042\n",
      "-----Epoch:  840 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.11241193280465936\n",
      "-----Epoch:  850 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.10704784987021317\n",
      "-----Epoch:  860 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.10187706067385804\n",
      "-----Epoch:  870 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.09692412439108312\n",
      "-----Epoch:  880 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.09220558836567572\n",
      "-----Epoch:  890 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.0877308272660333\n",
      "-----Epoch:  900 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.0835031264208551\n",
      "-----Epoch:  910 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.07952084184482977\n",
      "-----Epoch:  920 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.07577851984695823\n",
      "-----Epoch:  930 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.07226790553538409\n",
      "-----Epoch:  940 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.06897880609778723\n",
      "-----Epoch:  950 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.06589980029140041\n",
      "-----Epoch:  960 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.06301880150016156\n",
      "-----Epoch:  970 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.06032349030215246\n",
      "-----Epoch:  980 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.05780163602479626\n",
      "-----Epoch:  990 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.05544132712779516\n",
      "-----Epoch:  1000 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.05323112882479889\n",
      "-----Epoch:  1010 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.051160184067690975\n",
      "-----Epoch:  1020 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.04921827145860404\n",
      "-----Epoch:  1030 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.04739583116397511\n",
      "-----Epoch:  1040 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.04568396765741111\n",
      "-----Epoch:  1050 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.044074436185872076\n",
      "-----Epoch:  1060 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.04255961824793495\n",
      "-----Epoch:  1070 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.0411324900720645\n",
      "-----Epoch:  1080 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.039786587050060745\n",
      "-----Epoch:  1090 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.03851596627456689\n",
      "-----Epoch:  1100 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.037315168709200264\n",
      "-----Epoch:  1110 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.03617918204897959\n",
      "-----Epoch:  1120 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.03510340497588821\n",
      "-----Epoch:  1130 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.034083613253532374\n",
      "-----Epoch:  1140 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.033115927914743076\n",
      "-----Epoch:  1150 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.032196785659729325\n",
      "-----Epoch:  1160 -----\n",
      "Accuracy: 0.75\n",
      "Cost: 0.03132291148675125\n",
      "-----Epoch:  1170 -----\n",
      "Accuracy: 0.75\n",
      "Cost: 0.030491293511925983\n",
      "-----Epoch:  1180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.029699159891788698\n",
      "-----Epoch:  1190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.028943957735561767\n",
      "-----Epoch:  1200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.028223333879174323\n",
      "-----Epoch:  1210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.027535117386500607\n",
      "-----Epoch:  1220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.02687730364249954\n",
      "-----Epoch:  1230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.026248039906065158\n",
      "-----Epoch:  1240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.02564561219605917\n",
      "-----Epoch:  1250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.025068433391202974\n",
      "-----Epoch:  1260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.02451503243254692\n",
      "-----Epoch:  1270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.023984044525607973\n",
      "-----Epoch:  1280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.023474202247633743\n",
      "-----Epoch:  1290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.022984327473579425\n",
      "-----Epoch:  1300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.022513324042130398\n",
      "-----Epoch:  1310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.022060171090377053\n",
      "-----Epoch:  1320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.021623916992511507\n",
      "-----Epoch:  1330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.021203673844144715\n",
      "-----Epoch:  1340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.02079861243954913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  1350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.020407957694331715\n",
      "-----Epoch:  1360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.020030984470759957\n",
      "-----Epoch:  1370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.019667013767233316\n",
      "-----Epoch:  1380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.019315409237245798\n",
      "-----Epoch:  1390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01897557400665602\n",
      "-----Epoch:  1400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.018646947761204784\n",
      "-----Epoch:  1410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01832900407902353\n",
      "-----Epoch:  1420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01802124798539878\n",
      "-----Epoch:  1430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.017723213709314928\n",
      "-----Epoch:  1440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01743446262332693\n",
      "-----Epoch:  1450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.017154581350131645\n",
      "-----Epoch:  1460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.016883180020837486\n",
      "-----Epoch:  1470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0166198906713938\n",
      "-----Epoch:  1480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.016364365764954297\n",
      "-----Epoch:  1490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01611627682912467\n",
      "-----Epoch:  1500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.015875313198102637\n",
      "-----Epoch:  1510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.015641180850666635\n",
      "-----Epoch:  1520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01541360133582314\n",
      "-----Epoch:  1530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.015192310778688073\n",
      "-----Epoch:  1540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01497705895986893\n",
      "-----Epoch:  1550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.014767608462233696\n",
      "-----Epoch:  1560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.014563733879512592\n",
      "-----Epoch:  1570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0143652210816826\n",
      "-----Epoch:  1580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.014171866532539344\n",
      "-----Epoch:  1590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.013983476655270608\n",
      "-----Epoch:  1600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01379986724221784\n",
      "-----Epoch:  1610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.013620862905345447\n",
      "-----Epoch:  1620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.013446296564242064\n",
      "-----Epoch:  1630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.013276008968751533\n",
      "-----Epoch:  1640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01310984825358051\n",
      "-----Epoch:  1650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.012947669522454665\n",
      "-----Epoch:  1660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.012789334459600675\n",
      "-----Epoch:  1670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.012634710966515268\n",
      "-----Epoch:  1680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01248367282215421\n",
      "-----Epoch:  1690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.012336099364824465\n",
      "-----Epoch:  1700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.012191875194205254\n",
      "-----Epoch:  1710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.012050889892049036\n",
      "-----Epoch:  1720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.011913037760230456\n",
      "-----Epoch:  1730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.011778217574917607\n",
      "-----Epoch:  1740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01164633235573453\n",
      "-----Epoch:  1750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01151728914887517\n",
      "-----Epoch:  1760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.011390998823206853\n",
      "-----Epoch:  1770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01126737587847712\n",
      "-----Epoch:  1780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.011146338264804372\n",
      "-----Epoch:  1790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.011027807212695183\n",
      "-----Epoch:  1800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010911707072887834\n",
      "-----Epoch:  1810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01079796516537333\n",
      "-----Epoch:  1820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010686511636994186\n",
      "-----Epoch:  1830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010577279327063184\n",
      "-----Epoch:  1840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010470203640487187\n",
      "-----Epoch:  1850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010365222427916237\n",
      "-----Epoch:  1860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010262275872473532\n",
      "-----Epoch:  1870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01016130638265303\n",
      "-----Epoch:  1880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010062258491000392\n",
      "-----Epoch:  1890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009965078758220216\n",
      "-----Epoch:  1900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009869715682376929\n",
      "-----Epoch:  1910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009776119612879462\n",
      "-----Epoch:  1920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009684242668961056\n",
      "-----Epoch:  1930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009594038662385796\n",
      "-----Epoch:  1940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00950546302412999\n",
      "-----Epoch:  1950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009418472734804645\n",
      "-----Epoch:  1960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009333026258600545\n",
      "-----Epoch:  1970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00924908348055069\n",
      "-----Epoch:  1980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00916660564692004\n",
      "-----Epoch:  1990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009085555308543016\n",
      "-----Epoch:  2000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009005896266942287\n",
      "-----Epoch:  2010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008927593523071401\n",
      "-----Epoch:  2020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008850613228535623\n",
      "-----Epoch:  2030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008774922639152609\n",
      "-----Epoch:  2040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008700490070724593\n",
      "-----Epoch:  2050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008627284856901233\n",
      "-----Epoch:  2060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008555277309019216\n",
      "-----Epoch:  2070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008484438677812496\n",
      "-----Epoch:  2080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008414741116893165\n",
      "-----Epoch:  2090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008346157647908463\n",
      "-----Epoch:  2100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008278662127286014\n",
      "-----Epoch:  2110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00821222921448383\n",
      "-----Epoch:  2120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00814683434166679\n",
      "-----Epoch:  2130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008082453684736299\n",
      "-----Epoch:  2140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008019064135643192\n",
      "-----Epoch:  2150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007956643275918945\n",
      "-----Epoch:  2160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007895169351363359\n",
      "-----Epoch:  2170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007834621247830548\n",
      "-----Epoch:  2180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007774978468058837\n",
      "-----Epoch:  2190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007716221109491859\n",
      "-----Epoch:  2200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007658329843043446\n",
      "-----Epoch:  2210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007601285892758819\n",
      "-----Epoch:  2220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007545071016329204\n",
      "-----Epoch:  2230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007489667486418498\n",
      "-----Epoch:  2240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007435058072763215\n",
      "-----Epoch:  2250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007381226025008496\n",
      "-----Epoch:  2260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007328155056245584\n",
      "-----Epoch:  2270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007275829327217809\n",
      "-----Epoch:  2280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0072242334311635945\n",
      "-----Epoch:  2290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007173352379267039\n",
      "-----Epoch:  2300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007123171586687946\n",
      "-----Epoch:  2310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0070736768591450954\n",
      "-----Epoch:  2320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007024854380026613\n",
      "-----Epoch:  2330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006976690698004787\n",
      "-----Epoch:  2340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0069291727151314575\n",
      "-----Epoch:  2350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00688228767539319\n",
      "-----Epoch:  2360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006836023153705776\n",
      "-----Epoch:  2370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006790367045328008\n",
      "-----Epoch:  2380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006745307555676976\n",
      "-----Epoch:  2390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006700833190527006\n",
      "-----Epoch:  2400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006656932746575763\n",
      "-----Epoch:  2410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006613595302361393\n",
      "-----Epoch:  2420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006570810209515757\n",
      "-----Epoch:  2430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006528567084339772\n",
      "-----Epoch:  2440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006486855799686467\n",
      "-----Epoch:  2450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006445666477139462\n",
      "-----Epoch:  2460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006404989479473994\n",
      "-----Epoch:  2470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0063648154033891435\n",
      "-----Epoch:  2480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006325135072499573\n",
      "-----Epoch:  2490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0062859395305763155\n",
      "-----Epoch:  2500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006247220035026521\n",
      "-----Epoch:  2510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006208968050602093\n",
      "-----Epoch:  2520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00617117524332823\n",
      "-----Epoch:  2530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006133833474642827\n",
      "-----Epoch:  2540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006096934795738356\n",
      "-----Epoch:  2550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006060471442098207\n",
      "-----Epoch:  2560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006024435828219519\n",
      "-----Epoch:  2570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005988820542515615\n",
      "-----Epoch:  2580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005953618342390484\n",
      "-----Epoch:  2590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005918822149479017\n",
      "-----Epoch:  2600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005884425045046079\n",
      "-----Epoch:  2610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00585042026553892\n",
      "-----Epoch:  2620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005816801198286559\n",
      "-----Epoch:  2630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005783561377340639\n",
      "-----Epoch:  2640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0057506944794522745\n",
      "-----Epoch:  2650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005718194320180367\n",
      "-----Epoch:  2660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005686054850125213\n",
      "-----Epoch:  2670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005654270151284211\n",
      "-----Epoch:  2680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005622834433523779\n",
      "-----Epoch:  2690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005591742031164186\n",
      "-----Epoch:  2700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005560987399672503\n",
      "-----Epoch:  2710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005530565112460002\n",
      "-----Epoch:  2720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005500469857780098\n",
      "-----Epoch:  2730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005470696435723195\n",
      "-----Epoch:  2740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0054412397553051635\n",
      "-----Epoch:  2750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00541209483164539\n",
      "-----Epoch:  2760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005383256783232409\n",
      "-----Epoch:  2770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005354720829272412\n",
      "-----Epoch:  2780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005326482287119344\n",
      "-----Epoch:  2790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005298536569782476\n",
      "-----Epoch:  2800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005270879183509241\n",
      "-----Epoch:  2810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0052435057254408834\n",
      "-----Epoch:  2820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00521641188133801\n",
      "-----Epoch:  2830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005189593423373652\n",
      "-----Epoch:  2840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005163046207991917\n",
      "-----Epoch:  2850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00513676617382966\n",
      "-----Epoch:  2860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00511074933969885\n",
      "-----Epoch:  2870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005084991802628252\n",
      "-----Epoch:  2880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005059489735961466\n",
      "-----Epoch:  2890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005034239387510421\n",
      "-----Epoch:  2900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005009237077761665\n",
      "-----Epoch:  2910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0049844791981342\n",
      "-----Epoch:  2920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004959962209286886\n",
      "-----Epoch:  2930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004935682639473964\n",
      "-----Epoch:  2940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004911637082946976\n",
      "-----Epoch:  2950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0048878221984015565\n",
      "-----Epoch:  2960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004864234707467775\n",
      "-----Epoch:  2970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004840871393242671\n",
      "-----Epoch:  2980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004817729098863115\n",
      "-----Epoch:  2990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004794804726118538\n",
      "-----Epoch:  3000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004772095234101397\n",
      "-----Epoch:  3010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004749597637894821\n",
      "-----Epoch:  3020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004727309007295941\n",
      "-----Epoch:  3030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004705226465573909\n",
      "-----Epoch:  3040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004683347188261321\n",
      "-----Epoch:  3050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0046616684019782015\n",
      "-----Epoch:  3060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00464018738328763\n",
      "-----Epoch:  3070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004618901457581538\n",
      "-----Epoch:  3080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004597807997996563\n",
      "-----Epoch:  3090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0045769044243578775\n",
      "-----Epoch:  3100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004556188202151641\n",
      "-----Epoch:  3110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004535656841523602\n",
      "-----Epoch:  3120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0045153078963043715\n",
      "-----Epoch:  3130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004495138963059664\n",
      "-----Epoch:  3140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004475147680165413\n",
      "-----Epoch:  3150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004455331726906479\n",
      "-----Epoch:  3160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004435688822598526\n",
      "-----Epoch:  3170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00441621672573254\n",
      "-----Epoch:  3180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004396913233140801\n",
      "-----Epoch:  3190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0043777761791842455\n",
      "-----Epoch:  3200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004358803434960101\n",
      "-----Epoch:  3210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0043399929075296625\n",
      "-----Epoch:  3220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0043213425391653475\n",
      "-----Epoch:  3230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004302850306616398\n",
      "-----Epoch:  3240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004284514220392784\n",
      "-----Epoch:  3250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0042663323240671475\n",
      "-----Epoch:  3260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004248302693593629\n",
      "-----Epoch:  3270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004230423436643352\n",
      "-----Epoch:  3280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004212692691956357\n",
      "-----Epoch:  3290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004195108628709368\n",
      "-----Epoch:  3300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004177669445898517\n",
      "-----Epoch:  3310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004160373371737333\n",
      "-----Epoch:  3320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0041432186630690265\n",
      "-----Epoch:  3330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004126203604792854\n",
      "-----Epoch:  3340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004109326509304352\n",
      "-----Epoch:  3350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00409258571594858\n",
      "-----Epoch:  3360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004075979590486572\n",
      "-----Epoch:  3370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0040595065245742955\n",
      "-----Epoch:  3380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004043164935253652\n",
      "-----Epoch:  3390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004026953264455778\n",
      "-----Epoch:  3400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0040108699785156125\n",
      "-----Epoch:  3410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0039949135676978316\n",
      "-----Epoch:  3420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003979082545733862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  3430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003963375449369368\n",
      "-----Epoch:  3440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003947790837922262\n",
      "-----Epoch:  3450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003932327292850884\n",
      "-----Epoch:  3460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003916983417331879\n",
      "-----Epoch:  3470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0039017578358477496\n",
      "-----Epoch:  3480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0038866491937836565\n",
      "-----Epoch:  3490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003871656157033529\n",
      "-----Epoch:  3500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003856777411614762\n",
      "-----Epoch:  3510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0038420116632916276\n",
      "-----Epoch:  3520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0038273576372071672\n",
      "-----Epoch:  3530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0038128140775231323\n",
      "-----Epoch:  3540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003798379747068122\n",
      "-----Epoch:  3550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0037840534269930346\n",
      "-----Epoch:  3560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0037698339164347104\n",
      "-----Epoch:  3570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0037557200321863744\n",
      "-----Epoch:  3580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0037417106083755397\n",
      "-----Epoch:  3590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003727804496149028\n",
      "-----Epoch:  3600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003714000563364432\n",
      "-----Epoch:  3610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003700297694288754\n",
      "-----Epoch:  3620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003686694789303033\n",
      "-----Epoch:  3630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0036731907646136383\n",
      "-----Epoch:  3640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003659784551969532\n",
      "-----Epoch:  3650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0036464750983857598\n",
      "-----Epoch:  3660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003633261365872552\n",
      "-----Epoch:  3670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0036201423311703904\n",
      "-----Epoch:  3680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0036071169854904176\n",
      "-----Epoch:  3690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003594184334260657\n",
      "-----Epoch:  3700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003581343396877085\n",
      "-----Epoch:  3710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0035685932064603064\n",
      "-----Epoch:  3720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0035559328096169997\n",
      "-----Epoch:  3730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003543361266206394\n",
      "-----Epoch:  3740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003530877649111745\n",
      "-----Epoch:  3750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003518481044016192\n",
      "-----Epoch:  3760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0035061705491835093\n",
      "-----Epoch:  3770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003493945275243024\n",
      "-----Epoch:  3780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003481804344979271\n",
      "-----Epoch:  3790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0034697468931256963\n",
      "-----Epoch:  3800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003457772066162462\n",
      "-----Epoch:  3810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0034458790221186726\n",
      "-----Epoch:  3820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0034340669303781083\n",
      "-----Epoch:  3830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003422334971489308\n",
      "-----Epoch:  3840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003410682336979007\n",
      "-----Epoch:  3850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003399108229169763\n",
      "-----Epoch:  3860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003387611861000721\n",
      "-----Epoch:  3870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003376192455852358\n",
      "-----Epoch:  3880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00336484924737428\n",
      "-----Epoch:  3890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0033535814793166766\n",
      "-----Epoch:  3900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003342388405365127\n",
      "-----Epoch:  3910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003331269288978249\n",
      "-----Epoch:  3920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0033202234032290016\n",
      "-----Epoch:  3930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0033092500306486257\n",
      "-----Epoch:  3940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032983484630739624\n",
      "-----Epoch:  3950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032875180014974997\n",
      "-----Epoch:  3960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003276757955920225\n",
      "-----Epoch:  3970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032660676452076934\n",
      "-----Epoch:  3980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032554463969483916\n",
      "-----Epoch:  3990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032448935473149104\n",
      "-----Epoch:  4000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003234408440928098\n",
      "-----Epoch:  4010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00322399043072321\n",
      "-----Epoch:  4020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00321363887781914\n",
      "-----Epoch:  4030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032033531513896113\n",
      "-----Epoch:  4040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0031931326285372847\n",
      "-----Epoch:  4050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0031829766941696594\n",
      "-----Epoch:  4060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0031728847408778976\n",
      "-----Epoch:  4070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0031628561688173728\n",
      "-----Epoch:  4080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003152890385590687\n",
      "-----Epoch:  4090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0031429868061328783\n",
      "-----Epoch:  4100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0031331448525985604\n",
      "-----Epoch:  4110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003123363954251299\n",
      "-----Epoch:  4120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0031136435473550143\n",
      "-----Epoch:  4130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003103983075067177\n",
      "-----Epoch:  4140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0030943819873341036\n",
      "-----Epoch:  4150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00308483974078819\n",
      "-----Epoch:  4160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00307535579864687\n",
      "-----Epoch:  4170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003065929630613554\n",
      "-----Epoch:  4180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003056560712780044\n",
      "-----Epoch:  4190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0030472485275310638\n",
      "-----Epoch:  4200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0030379925634503504\n",
      "-----Epoch:  4210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003028792315228319\n",
      "-----Epoch:  4220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0030196472835714518\n",
      "-----Epoch:  4230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0030105569751134294\n",
      "-----Epoch:  4240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003001520902327424\n",
      "-----Epoch:  4250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029925385834405245\n",
      "-----Epoch:  4260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029836095423490198\n",
      "-----Epoch:  4270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029747333085358377\n",
      "-----Epoch:  4280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029659094169887604\n",
      "-----Epoch:  4290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029571374081206353\n",
      "-----Epoch:  4300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029484168276904172\n",
      "-----Epoch:  4310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029397472267262688\n",
      "-----Epoch:  4320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002931128161449226\n",
      "-----Epoch:  4330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029225591931988193\n",
      "-----Epoch:  4340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002914039888359461\n",
      "-----Epoch:  4350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029055698182885656\n",
      "-----Epoch:  4360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028971485592454585\n",
      "-----Epoch:  4370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002888775692321809\n",
      "-----Epoch:  4380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028804508033731797\n",
      "-----Epoch:  4390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028721734829514852\n",
      "-----Epoch:  4400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028639433262389862\n",
      "-----Epoch:  4410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002855759932983193\n",
      "-----Epoch:  4420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002847622907432668\n",
      "-----Epoch:  4430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028395318582743606\n",
      "-----Epoch:  4440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028314863985715736\n",
      "-----Epoch:  4450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028234861457030963\n",
      "-----Epoch:  4460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028155307213035504\n",
      "-----Epoch:  4470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002807619751204301\n",
      "-----Epoch:  4480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002799752865375796\n",
      "-----Epoch:  4490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027919296978704895\n",
      "-----Epoch:  4500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002784149886766995\n",
      "-----Epoch:  4510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027764130741148468\n",
      "-----Epoch:  4520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027687189058805176\n",
      "-----Epoch:  4530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027610670318939535\n",
      "-----Epoch:  4540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002753457105796355\n",
      "-----Epoch:  4550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002745888784988377\n",
      "-----Epoch:  4560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027383617305795477\n",
      "-----Epoch:  4570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027308756073383027\n",
      "-----Epoch:  4580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002723430083642845\n",
      "-----Epoch:  4590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027160248314328666\n",
      "-----Epoch:  4600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002708659526161958\n",
      "-----Epoch:  4610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002701333846750721\n",
      "-----Epoch:  4620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026940474755409024\n",
      "-----Epoch:  4630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026868000982498926\n",
      "-----Epoch:  4640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026795914039262517\n",
      "-----Epoch:  4650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002672421084905651\n",
      "-----Epoch:  4660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026652888367678347\n",
      "-----Epoch:  4670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002658194358293956\n",
      "-----Epoch:  4680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026511373514247656\n",
      "-----Epoch:  4690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002644117521219414\n",
      "-----Epoch:  4700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002637134575814778\n",
      "-----Epoch:  4710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00263018822638562\n",
      "-----Epoch:  4720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002623278187105292\n",
      "-----Epoch:  4730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026164041751068606\n",
      "-----Epoch:  4740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026095659104451666\n",
      "-----Epoch:  4750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002602763116059216\n",
      "-----Epoch:  4760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002595995517735126\n",
      "-----Epoch:  4770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025892628440699894\n",
      "-----Epoch:  4780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002582564826435764\n",
      "-----Epoch:  4790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025759011989441305\n",
      "-----Epoch:  4800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002569271698411802\n",
      "-----Epoch:  4810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025626760643260096\n",
      "-----Epoch:  4820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025561140388112137\n",
      "-----Epoch:  4830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025495853665955352\n",
      "-----Epoch:  4840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002543089794978252\n",
      "-----Epoch:  4850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025366270737975046\n",
      "-----Epoch:  4860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025301969553986636\n",
      "-----Epoch:  4870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002523799194602924\n",
      "-----Epoch:  4880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025174335486766314\n",
      "-----Epoch:  4890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025110997773009794\n",
      "-----Epoch:  4900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025047976425419585\n",
      "-----Epoch:  4910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024985269088211083\n",
      "-----Epoch:  4920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002492287342886336\n",
      "-----Epoch:  4930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024860787137835566\n",
      "-----Epoch:  4940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024799007928282533\n",
      "-----Epoch:  4950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024737533535779416\n",
      "-----Epoch:  4960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002467636171804761\n",
      "-----Epoch:  4970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024615490254685578\n",
      "-----Epoch:  4980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024554916946902547\n",
      "-----Epoch:  4990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024494639617257093\n",
      "-----Epoch:  5000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002443465610940011\n",
      "-----Epoch:  5010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024374964287819825\n",
      "-----Epoch:  5020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024315562037590735\n",
      "-----Epoch:  5030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024256447264128125\n",
      "-----Epoch:  5040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002419761789294442\n",
      "-----Epoch:  5050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002413907186940743\n",
      "-----Epoch:  5060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002408080715850631\n",
      "-----Epoch:  5070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002402282174461718\n",
      "-----Epoch:  5080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023965113631273637\n",
      "-----Epoch:  5090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023907680840939485\n",
      "-----Epoch:  5100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023850521414786976\n",
      "-----Epoch:  5110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002379363341247528\n",
      "-----Epoch:  5120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023737014911933496\n",
      "-----Epoch:  5130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002368066400914698\n",
      "-----Epoch:  5140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002362457881794693\n",
      "-----Epoch:  5150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023568757469800083\n",
      "-----Epoch:  5160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002351319811360622\n",
      "-----Epoch:  5170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023457898915493908\n",
      "-----Epoch:  5180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023402858058621874\n",
      "-----Epoch:  5190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023348073742981597\n",
      "-----Epoch:  5200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002329354418520404\n",
      "-----Epoch:  5210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002323926761836697\n",
      "-----Epoch:  5220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023185242291807887\n",
      "-----Epoch:  5230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023131466470936554\n",
      "-----Epoch:  5240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023077938437051832\n",
      "-----Epoch:  5250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002302465648716032\n",
      "-----Epoch:  5260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002297161893379809\n",
      "-----Epoch:  5270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022918824104854233\n",
      "-----Epoch:  5280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022866270343396902\n",
      "-----Epoch:  5290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00228139560075019\n",
      "-----Epoch:  5300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022761879470084008\n",
      "-----Epoch:  5310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002271003911872916\n",
      "-----Epoch:  5320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002265843335553088\n",
      "-----Epoch:  5330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022607060596926626\n",
      "-----Epoch:  5340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022555919273538265\n",
      "-----Epoch:  5350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022505007830014296\n",
      "-----Epoch:  5360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002245432472487328\n",
      "-----Epoch:  5370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022403868430349158\n",
      "-----Epoch:  5380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022353637432241495\n",
      "-----Epoch:  5390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022303630229763395\n",
      "-----Epoch:  5400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022253845335394964\n",
      "-----Epoch:  5410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022204281274736323\n",
      "-----Epoch:  5420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002215493658636493\n",
      "-----Epoch:  5430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022105809821691114\n",
      "-----Epoch:  5440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022056899544821286\n",
      "-----Epoch:  5450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002200820433241598\n",
      "-----Epoch:  5460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002195972277355527\n",
      "-----Epoch:  5470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021911453469602876\n",
      "-----Epoch:  5480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021863395034074566\n",
      "-----Epoch:  5490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002181554609250401\n",
      "-----Epoch:  5500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021767905282316334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  5510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002172047125269734\n",
      "-----Epoch:  5520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002167324266446895\n",
      "-----Epoch:  5530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002162621818996364\n",
      "-----Epoch:  5540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002157939651290121\n",
      "-----Epoch:  5550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002153277632826757\n",
      "-----Epoch:  5560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002148635634219482\n",
      "-----Epoch:  5570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00214401352718419\n",
      "-----Epoch:  5580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002139411184527828\n",
      "-----Epoch:  5590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021348284801368986\n",
      "-----Epoch:  5600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002130265288965929\n",
      "-----Epoch:  5610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021257214870263213\n",
      "-----Epoch:  5620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002121196951375093\n",
      "-----Epoch:  5630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002116691560104049\n",
      "-----Epoch:  5640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021122051923289035\n",
      "-----Epoch:  5650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002107737728178547\n",
      "-----Epoch:  5660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021032890487844166\n",
      "-----Epoch:  5670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00209885903627016\n",
      "-----Epoch:  5680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020944475737412907\n",
      "-----Epoch:  5690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020900545452749763\n",
      "-----Epoch:  5700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020856798359099884\n",
      "-----Epoch:  5710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020813233316368663\n",
      "-----Epoch:  5720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020769849193879586\n",
      "-----Epoch:  5730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002072664487027824\n",
      "-----Epoch:  5740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002068361923343648\n",
      "-----Epoch:  5750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020640771180357796\n",
      "-----Epoch:  5760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020598099617084547\n",
      "-----Epoch:  5770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002055560345860381\n",
      "-----Epoch:  5780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020513281628759985\n",
      "-----Epoch:  5790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002047113306016095\n",
      "-----Epoch:  5800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020429156694091112\n",
      "-----Epoch:  5810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002038735148042342\n",
      "-----Epoch:  5820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002034571637753234\n",
      "-----Epoch:  5830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020304250352208555\n",
      "-----Epoch:  5840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002026295237957368\n",
      "-----Epoch:  5850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020221821442997123\n",
      "-----Epoch:  5860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00201808565340137\n",
      "-----Epoch:  5870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020140056652240873\n",
      "-----Epoch:  5880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020099420805299215\n",
      "-----Epoch:  5890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020058948008732005\n",
      "-----Epoch:  5900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002001863728592716\n",
      "-----Epoch:  5910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019978487668038214\n",
      "-----Epoch:  5920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019938498193908527\n",
      "-----Epoch:  5930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019898667909995617\n",
      "-----Epoch:  5940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019858995870294183\n",
      "-----Epoch:  5950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019819481136263703\n",
      "-----Epoch:  5960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00197801227767546\n",
      "-----Epoch:  5970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019740919867935317\n",
      "-----Epoch:  5980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019701871493221315\n",
      "-----Epoch:  5990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001966297674320359\n",
      "-----Epoch:  6000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001962423471557919\n",
      "-----Epoch:  6010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019585644515082512\n",
      "-----Epoch:  6020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019547205253415975\n",
      "-----Epoch:  6030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019508916049182459\n",
      "-----Epoch:  6040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019470776027820235\n",
      "-----Epoch:  6050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019432784321535227\n",
      "-----Epoch:  6060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001939494006923525\n",
      "-----Epoch:  6070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019357242416468594\n",
      "-----Epoch:  6080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019319690515356815\n",
      "-----Epoch:  6090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019282283524533332\n",
      "-----Epoch:  6100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019245020609081395\n",
      "-----Epoch:  6110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019207900940472694\n",
      "-----Epoch:  6120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019170923696504667\n",
      "-----Epoch:  6130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019134088061242274\n",
      "-----Epoch:  6140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019097393224958002\n",
      "-----Epoch:  6150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019060838384072872\n",
      "-----Epoch:  6160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019024422741097575\n",
      "-----Epoch:  6170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018988145504576642\n",
      "-----Epoch:  6180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018952005889029924\n",
      "-----Epoch:  6190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018916003114898116\n",
      "-----Epoch:  6200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001888013640848482\n",
      "-----Epoch:  6210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018844405001904542\n",
      "-----Epoch:  6220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018808808133025448\n",
      "-----Epoch:  6230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018773345045417827\n",
      "-----Epoch:  6240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018738014988299865\n",
      "-----Epoch:  6250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018702817216485791\n",
      "-----Epoch:  6260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018667750990332928\n",
      "-----Epoch:  6270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018632815575691153\n",
      "-----Epoch:  6280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018598010243852327\n",
      "-----Epoch:  6290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018563334271499224\n",
      "-----Epoch:  6300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001852878694065619\n",
      "-----Epoch:  6310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001849436753864045\n",
      "-----Epoch:  6320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018460075358012413\n",
      "-----Epoch:  6330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018425909696529249\n",
      "-----Epoch:  6340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018391869857095678\n",
      "-----Epoch:  6350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018357955147718316\n",
      "-----Epoch:  6360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018324164881457815\n",
      "-----Epoch:  6370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018290498376384676\n",
      "-----Epoch:  6380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018256954955531875\n",
      "-----Epoch:  6390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018223533946850673\n",
      "-----Epoch:  6400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001819023468316669\n",
      "-----Epoch:  6410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018157056502135006\n",
      "-----Epoch:  6420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018123998746196865\n",
      "-----Epoch:  6430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018091060762537047\n",
      "-----Epoch:  6440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001805824190304014\n",
      "-----Epoch:  6450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001802554152424969\n",
      "-----Epoch:  6460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017992958987325858\n",
      "-----Epoch:  6470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017960493658003768\n",
      "-----Epoch:  6480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017928144906553549\n",
      "-----Epoch:  6490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017895912107739346\n",
      "-----Epoch:  6500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017863794640779374\n",
      "-----Epoch:  6510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017831791889306961\n",
      "-----Epoch:  6520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001779990324133094\n",
      "-----Epoch:  6530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017768128089196275\n",
      "-----Epoch:  6540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017736465829547212\n",
      "-----Epoch:  6550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017704915863289306\n",
      "-----Epoch:  6560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017673477595549888\n",
      "-----Epoch:  6570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001764215043564408\n",
      "-----Epoch:  6580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001761093379703467\n",
      "-----Epoch:  6590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017579827097299447\n",
      "-----Epoch:  6600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017548829758092057\n",
      "-----Epoch:  6610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017517941205108072\n",
      "-----Epoch:  6620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017487160868050065\n",
      "-----Epoch:  6630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017456488180591875\n",
      "-----Epoch:  6640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017425922580344083\n",
      "-----Epoch:  6650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001739546350882116\n",
      "-----Epoch:  6660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017365110411406608\n",
      "-----Epoch:  6670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001733486273731957\n",
      "-----Epoch:  6680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001730471993958245\n",
      "-----Epoch:  6690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017274681474987745\n",
      "-----Epoch:  6700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001724474680406542\n",
      "-----Epoch:  6710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017214915391052252\n",
      "-----Epoch:  6720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001718518670385708\n",
      "-----Epoch:  6730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017155560214032921\n",
      "-----Epoch:  6740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001712603539674483\n",
      "-----Epoch:  6750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017096611730736651\n",
      "-----Epoch:  6760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017067288698304794\n",
      "-----Epoch:  6770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017038065785264457\n",
      "-----Epoch:  6780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001700894248092172\n",
      "-----Epoch:  6790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001697991827804412\n",
      "-----Epoch:  6800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016950992672829651\n",
      "-----Epoch:  6810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016922165164879911\n",
      "-----Epoch:  6820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016893435257171322\n",
      "-----Epoch:  6830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016864802456024273\n",
      "-----Epoch:  6840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016836266271078267\n",
      "-----Epoch:  6850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016807826215262068\n",
      "-----Epoch:  6860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016779481804767738\n",
      "-----Epoch:  6870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001675123255902123\n",
      "-----Epoch:  6880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016723078000657685\n",
      "-----Epoch:  6890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016695017655493898\n",
      "-----Epoch:  6900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016667051052500844\n",
      "-----Epoch:  6910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016639177723779396\n",
      "-----Epoch:  6920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016611397204533405\n",
      "-----Epoch:  6930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001658370903304354\n",
      "-----Epoch:  6940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016556112750643033\n",
      "-----Epoch:  6950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016528607901692201\n",
      "-----Epoch:  6960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016501194033552774\n",
      "-----Epoch:  6970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016473870696564277\n",
      "-----Epoch:  6980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00164466374440195\n",
      "-----Epoch:  6990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016419493832138894\n",
      "-----Epoch:  7000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001639243942004914\n",
      "-----Epoch:  7010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016365473769757027\n",
      "-----Epoch:  7020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016338596446128326\n",
      "-----Epoch:  7030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016311807016861357\n",
      "-----Epoch:  7040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016285105052468115\n",
      "-----Epoch:  7050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016258490126247471\n",
      "-----Epoch:  7060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016231961814265788\n",
      "-----Epoch:  7070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016205519695332107\n",
      "-----Epoch:  7080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001617916335097788\n",
      "-----Epoch:  7090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016152892365433845\n",
      "-----Epoch:  7100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001612670632560908\n",
      "-----Epoch:  7110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001610060482106902\n",
      "-----Epoch:  7120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016074587444014827\n",
      "-----Epoch:  7130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016048653789260882\n",
      "-----Epoch:  7140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016022803454215355\n",
      "-----Epoch:  7150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015997036038859391\n",
      "-----Epoch:  7160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015971351145725695\n",
      "-----Epoch:  7170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015945748379878806\n",
      "-----Epoch:  7180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015920227348895492\n",
      "-----Epoch:  7190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015894787662843566\n",
      "-----Epoch:  7200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00158694289342642\n",
      "-----Epoch:  7210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015844150778149173\n",
      "-----Epoch:  7220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015818952811925302\n",
      "-----Epoch:  7230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015793834655432487\n",
      "-----Epoch:  7240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015768795930906126\n",
      "-----Epoch:  7250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001574383626295764\n",
      "-----Epoch:  7260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015718955278556318\n",
      "-----Epoch:  7270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015694152607009949\n",
      "-----Epoch:  7280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001566942787994815\n",
      "-----Epoch:  7290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015644780731303093\n",
      "-----Epoch:  7300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015620210797291161\n",
      "-----Epoch:  7310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015595717716396593\n",
      "-----Epoch:  7320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00155713011293528\n",
      "-----Epoch:  7330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015546960679125017\n",
      "-----Epoch:  7340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015522696010893515\n",
      "-----Epoch:  7350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015498506772036137\n",
      "-----Epoch:  7360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015474392612110973\n",
      "-----Epoch:  7370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015450353182840451\n",
      "-----Epoch:  7380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015426388138094355\n",
      "-----Epoch:  7390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015402497133872467\n",
      "-----Epoch:  7400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015378679828289366\n",
      "-----Epoch:  7410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015354935881557758\n",
      "-----Epoch:  7420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015331264955972931\n",
      "-----Epoch:  7430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015307666715894876\n",
      "-----Epoch:  7440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015284140827735737\n",
      "-----Epoch:  7450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015260686959941618\n",
      "-----Epoch:  7460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001523730478297813\n",
      "-----Epoch:  7470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015213993969314778\n",
      "-----Epoch:  7480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001519075419341016\n",
      "-----Epoch:  7490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001516758513169659\n",
      "-----Epoch:  7500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015144486462565314\n",
      "-----Epoch:  7510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00151214578663511\n",
      "-----Epoch:  7520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00150984990253194\n",
      "-----Epoch:  7530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015075609623649562\n",
      "-----Epoch:  7540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015052789347421677\n",
      "-----Epoch:  7550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015030037884601927\n",
      "-----Epoch:  7560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015007354925029642\n",
      "-----Epoch:  7570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014984740160401092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  7580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014962193284257545\n",
      "-----Epoch:  7590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001493971399197042\n",
      "-----Epoch:  7600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014917301980728543\n",
      "-----Epoch:  7610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014894956949523766\n",
      "-----Epoch:  7620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014872678599137778\n",
      "-----Epoch:  7630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001485046663212972\n",
      "-----Epoch:  7640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014828320752821459\n",
      "-----Epoch:  7650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014806240667285852\n",
      "-----Epoch:  7660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014784226083333488\n",
      "-----Epoch:  7670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014762276710499952\n",
      "-----Epoch:  7680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014740392260032117\n",
      "-----Epoch:  7690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014718572444877413\n",
      "-----Epoch:  7700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001469681697966957\n",
      "-----Epoch:  7710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014675125580717457\n",
      "-----Epoch:  7720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001465349796599292\n",
      "-----Epoch:  7730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014631933855117187\n",
      "-----Epoch:  7740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014610432969350375\n",
      "-----Epoch:  7750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014588995031578685\n",
      "-----Epoch:  7760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001456761976630323\n",
      "-----Epoch:  7770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014546306899627028\n",
      "-----Epoch:  7780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014525056159245492\n",
      "-----Epoch:  7790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00145038672744333\n",
      "-----Epoch:  7800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014482739976032692\n",
      "-----Epoch:  7810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014461673996443549\n",
      "-----Epoch:  7820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014440669069611363\n",
      "-----Epoch:  7830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00144197249310162\n",
      "-----Epoch:  7840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014398841317661037\n",
      "-----Epoch:  7850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014378017968062575\n",
      "-----Epoch:  7860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014357254622237815\n",
      "-----Epoch:  7870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014336551021696007\n",
      "-----Epoch:  7880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014315906909426537\n",
      "-----Epoch:  7890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001429532202988767\n",
      "-----Epoch:  7900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014274796128997973\n",
      "-----Epoch:  7910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014254328954124533\n",
      "-----Epoch:  7920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001423392025407282\n",
      "-----Epoch:  7930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001421356977907701\n",
      "-----Epoch:  7940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014193277280789406\n",
      "-----Epoch:  7950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014173042512270442\n",
      "-----Epoch:  7960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014152865227978987\n",
      "-----Epoch:  7970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014132745183762004\n",
      "-----Epoch:  7980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014112682136845894\n",
      "-----Epoch:  7990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014092675845824793\n",
      "-----Epoch:  8000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014072726070652804\n",
      "-----Epoch:  8010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014052832572633994\n",
      "-----Epoch:  8020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014032995114411934\n",
      "-----Epoch:  8030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014013213459962031\n",
      "-----Epoch:  8040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013993487374579757\n",
      "-----Epoch:  8050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00139738166248752\n",
      "-----Epoch:  8060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013954200978759717\n",
      "-----Epoch:  8070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013934640205439737\n",
      "-----Epoch:  8080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013915134075406742\n",
      "-----Epoch:  8090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013895682360427948\n",
      "-----Epoch:  8100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013876284833538861\n",
      "-----Epoch:  8110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013856941269032507\n",
      "-----Epoch:  8120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001383765144245255\n",
      "-----Epoch:  8130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001381841513058429\n",
      "-----Epoch:  8140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013799232111444467\n",
      "-----Epoch:  8150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001378010216427536\n",
      "-----Epoch:  8160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013761025069534264\n",
      "-----Epoch:  8170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013742000608886144\n",
      "-----Epoch:  8180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013723028565195004\n",
      "-----Epoch:  8190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013704108722516445\n",
      "-----Epoch:  8200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013685240866088003\n",
      "-----Epoch:  8210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013666424782322292\n",
      "-----Epoch:  8220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001364766025879957\n",
      "-----Epoch:  8230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013628947084256974\n",
      "-----Epoch:  8240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013610285048585094\n",
      "-----Epoch:  8250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013591673942814663\n",
      "-----Epoch:  8260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013573113559114352\n",
      "-----Epoch:  8270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013554603690779346\n",
      "-----Epoch:  8280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001353614413222392\n",
      "-----Epoch:  8290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013517734678977018\n",
      "-----Epoch:  8300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013499375127670604\n",
      "-----Epoch:  8310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013481065276035032\n",
      "-----Epoch:  8320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013462804922891058\n",
      "-----Epoch:  8330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013444593868140874\n",
      "-----Epoch:  8340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013426431912763792\n",
      "-----Epoch:  8350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013408318858806612\n",
      "-----Epoch:  8360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013390254509376984\n",
      "-----Epoch:  8370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013372238668637874\n",
      "-----Epoch:  8380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013354271141798153\n",
      "-----Epoch:  8390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013336351735106855\n",
      "-----Epoch:  8400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013318480255846638\n",
      "-----Epoch:  8410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013300656512326616\n",
      "-----Epoch:  8420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013282880313874145\n",
      "-----Epoch:  8430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001326515147083053\n",
      "-----Epoch:  8440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013247469794542635\n",
      "-----Epoch:  8450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013229835097356328\n",
      "-----Epoch:  8460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013212247192610875\n",
      "-----Epoch:  8470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001319470589463108\n",
      "-----Epoch:  8480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013177211018721765\n",
      "-----Epoch:  8490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001315976238116125\n",
      "-----Epoch:  8500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013142359799193839\n",
      "-----Epoch:  8510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013125003091025305\n",
      "-----Epoch:  8520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013107692075815143\n",
      "-----Epoch:  8530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013090426573671176\n",
      "-----Epoch:  8540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013073206405641925\n",
      "-----Epoch:  8550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013056031393712867\n",
      "-----Epoch:  8560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013038901360798824\n",
      "-----Epoch:  8570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013021816130736994\n",
      "-----Epoch:  8580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013004775528282998\n",
      "-----Epoch:  8590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012987779379103693\n",
      "-----Epoch:  8600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001297082750977202\n",
      "-----Epoch:  8610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001295391974775969\n",
      "-----Epoch:  8620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012937055921432789\n",
      "-----Epoch:  8630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012920235860046055\n",
      "-----Epoch:  8640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001290345939373526\n",
      "-----Epoch:  8650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012886726353514583\n",
      "-----Epoch:  8660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012870036571268108\n",
      "-----Epoch:  8670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001285338987974597\n",
      "-----Epoch:  8680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012836786112557985\n",
      "-----Epoch:  8690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012820225104168232\n",
      "-----Epoch:  8700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012803706689889678\n",
      "-----Epoch:  8710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012787230705879208\n",
      "-----Epoch:  8720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012770796989131584\n",
      "-----Epoch:  8730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00127544053774746\n",
      "-----Epoch:  8740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012738055709563018\n",
      "-----Epoch:  8750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012721747824874193\n",
      "-----Epoch:  8760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012705481563702109\n",
      "-----Epoch:  8770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012689256767153218\n",
      "-----Epoch:  8780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012673073277139494\n",
      "-----Epoch:  8790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001265693093637561\n",
      "-----Epoch:  8800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012640829588372305\n",
      "-----Epoch:  8810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001262476907743101\n",
      "-----Epoch:  8820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012608749248641127\n",
      "-----Epoch:  8830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012592769947871972\n",
      "-----Epoch:  8840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001257683102177061\n",
      "-----Epoch:  8850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012560932317755022\n",
      "-----Epoch:  8860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012545073684010505\n",
      "-----Epoch:  8870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012529254969484383\n",
      "-----Epoch:  8880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012513476023880976\n",
      "-----Epoch:  8890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001249773669765764\n",
      "-----Epoch:  8900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012482036842019059\n",
      "-----Epoch:  8910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012466376308913304\n",
      "-----Epoch:  8920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012450754951026897\n",
      "-----Epoch:  8930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012435172621780646\n",
      "-----Epoch:  8940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001241962917532438\n",
      "-----Epoch:  8950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012404124466533113\n",
      "-----Epoch:  8960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012388658351001553\n",
      "-----Epoch:  8970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012373230685041965\n",
      "-----Epoch:  8980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012357841325675856\n",
      "-----Epoch:  8990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001234249013063376\n",
      "-----Epoch:  9000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012327176958347927\n",
      "-----Epoch:  9010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012311901667949072\n",
      "-----Epoch:  9020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012296664119262437\n",
      "-----Epoch:  9030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00122814641728032\n",
      "-----Epoch:  9040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012266301689771075\n",
      "-----Epoch:  9050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012251176532048404\n",
      "-----Epoch:  9060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001223608856219443\n",
      "-----Epoch:  9070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012221037643441364\n",
      "-----Epoch:  9080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012206023639690013\n",
      "-----Epoch:  9090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001219104641550719\n",
      "-----Epoch:  9100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001217610583611909\n",
      "-----Epoch:  9110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012161201767410174\n",
      "-----Epoch:  9120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012146334075917203\n",
      "-----Epoch:  9130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012131502628824988\n",
      "-----Epoch:  9140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012116707293964354\n",
      "-----Epoch:  9150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012101947939806878\n",
      "-----Epoch:  9160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012087224435461605\n",
      "-----Epoch:  9170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012072536650669927\n",
      "-----Epoch:  9180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012057884455803519\n",
      "-----Epoch:  9190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012043267721859536\n",
      "-----Epoch:  9200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012028686320457458\n",
      "-----Epoch:  9210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012014140123833932\n",
      "-----Epoch:  9220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011999629004841197\n",
      "-----Epoch:  9230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011985152836941804\n",
      "-----Epoch:  9240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011970711494204923\n",
      "-----Epoch:  9250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001195630485130408\n",
      "-----Epoch:  9260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011941932783512675\n",
      "-----Epoch:  9270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011927595166699387\n",
      "-----Epoch:  9280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011913291877327034\n",
      "-----Epoch:  9290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011899022792446643\n",
      "-----Epoch:  9300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011884787789695518\n",
      "-----Epoch:  9310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011870586747292772\n",
      "-----Epoch:  9320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011856419544036293\n",
      "-----Epoch:  9330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011842286059300133\n",
      "-----Epoch:  9340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011828186173028826\n",
      "-----Epoch:  9350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011814119765737353\n",
      "-----Epoch:  9360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011800086718504214\n",
      "-----Epoch:  9370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011786086912970602\n",
      "-----Epoch:  9380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011772120231336178\n",
      "-----Epoch:  9390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001175818655635579\n",
      "-----Epoch:  9400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011744285771336114\n",
      "-----Epoch:  9410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001173041776013341\n",
      "-----Epoch:  9420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011716582407147907\n",
      "-----Epoch:  9430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001170277959732369\n",
      "-----Epoch:  9440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011689009216143875\n",
      "-----Epoch:  9450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011675271149626466\n",
      "-----Epoch:  9460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001166156528432354\n",
      "-----Epoch:  9470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001164789150731635\n",
      "-----Epoch:  9480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011634249706212931\n",
      "-----Epoch:  9490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011620639769145426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  9500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011607061584765928\n",
      "-----Epoch:  9510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011593515042244353\n",
      "-----Epoch:  9520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011580000031265172\n",
      "-----Epoch:  9530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001156651644202484\n",
      "-----Epoch:  9540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001155306416522765\n",
      "-----Epoch:  9550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011539643092084145\n",
      "-----Epoch:  9560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011526253114307764\n",
      "-----Epoch:  9570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011512894124111465\n",
      "-----Epoch:  9580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011499566014205487\n",
      "-----Epoch:  9590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001148626867779366\n",
      "-----Epoch:  9600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011473002008572024\n",
      "-----Epoch:  9610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011459765900724151\n",
      "-----Epoch:  9620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001144656024892011\n",
      "-----Epoch:  9630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011433384948312223\n",
      "-----Epoch:  9640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011420239894533361\n",
      "-----Epoch:  9650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011407124983693598\n",
      "-----Epoch:  9660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011394040112377949\n",
      "-----Epoch:  9670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011380985177643014\n",
      "-----Epoch:  9680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011367960077015074\n",
      "-----Epoch:  9690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011354964708486484\n",
      "-----Epoch:  9700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011341998970514342\n",
      "-----Epoch:  9710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011329062762016112\n",
      "-----Epoch:  9720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011316155982368937\n",
      "-----Epoch:  9730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001130327853140539\n",
      "-----Epoch:  9740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011290430309412233\n",
      "-----Epoch:  9750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011277611217126499\n",
      "-----Epoch:  9760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011264821155734012\n",
      "-----Epoch:  9770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011252060026866494\n",
      "-----Epoch:  9780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001123932773259897\n",
      "-----Epoch:  9790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011226624175447312\n",
      "-----Epoch:  9800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011213949258366532\n",
      "-----Epoch:  9810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011201302884746767\n",
      "-----Epoch:  9820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011188684958411707\n",
      "-----Epoch:  9830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011176095383616336\n",
      "-----Epoch:  9840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001116353406504503\n",
      "-----Epoch:  9850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011151000907806978\n",
      "-----Epoch:  9860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011138495817436817\n",
      "-----Epoch:  9870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011126018699889613\n",
      "-----Epoch:  9880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011113569461540182\n",
      "-----Epoch:  9890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011101148009180276\n",
      "-----Epoch:  9900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011088754250015902\n",
      "-----Epoch:  9910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011076388091665408\n",
      "-----Epoch:  9920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011064049442157246\n",
      "-----Epoch:  9930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00110517382099276\n",
      "-----Epoch:  9940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011039454303817832\n",
      "-----Epoch:  9950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011027197633073115\n",
      "-----Epoch:  9960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011014968107338847\n",
      "-----Epoch:  9970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011002765636659313\n",
      "-----Epoch:  9980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001099059013147622\n",
      "-----Epoch:  9990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010978441502624884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa611102ac0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TRAINING THE XOR FUNCTION\n",
    "\n",
    "x_train = np.array([[0, 0, 1, 1], \n",
    "                    [0, 1, 0, 1]]) # 2 inputs and 4 samples, i.e 2x4\n",
    "y_train = np.array([0, 1, 1, 0]) #1 x num of samples\n",
    "Xor_net = NeuralNet('binary_logloss')\n",
    "Xor_net.addLayer(3, 'tanh')\n",
    "Xor_net.addLayer(1, 'sigmoid')\n",
    "costs, weights = Xor_net.fit(x_train, y_train, 10000)\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the XOR b/w 1 and 0 is: 1\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[1], [0]])\n",
    "pred = 1 if Xor_net.predict(test) else 0\n",
    "print(\"The result of the XOR b/w 1 and 0 is:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  0 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.8124434930660652\n",
      "-----Epoch:  10 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.5028903042489244\n",
      "-----Epoch:  20 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.4839048488523723\n",
      "-----Epoch:  30 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.46727603218511576\n",
      "-----Epoch:  40 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.45243846205140364\n",
      "-----Epoch:  50 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.4391539604120788\n",
      "-----Epoch:  60 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.427215242450443\n",
      "-----Epoch:  70 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.41644314571245805\n",
      "-----Epoch:  80 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.40668369950956534\n",
      "-----Epoch:  90 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.39780505389300075\n",
      "-----Epoch:  100 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.38969451294912255\n",
      "-----Epoch:  110 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.3822558052657171\n",
      "-----Epoch:  120 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.37540665113462945\n",
      "-----Epoch:  130 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.36907664030567067\n",
      "-----Epoch:  140 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.36320540772275783\n",
      "-----Epoch:  150 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3577410811286928\n",
      "-----Epoch:  160 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3526389689200943\n",
      "-----Epoch:  170 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.34786045586480374\n",
      "-----Epoch:  180 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.34337207610087\n",
      "-----Epoch:  190 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3391447358706976\n",
      "-----Epoch:  200 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.33515306190358657\n",
      "-----Epoch:  210 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3313748547943981\n",
      "-----Epoch:  220 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.32779062990413554\n",
      "-----Epoch:  230 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3243832311296351\n",
      "-----Epoch:  240 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.32113750532913615\n",
      "-----Epoch:  250 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3180400272632392\n",
      "-----Epoch:  260 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3150788666510256\n",
      "-----Epoch:  270 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.31224339039046467\n",
      "-----Epoch:  280 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.30952409419278715\n",
      "-----Epoch:  290 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.30691245887150576\n",
      "-----Epoch:  300 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.30440082734311424\n",
      "-----Epoch:  310 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.30198229906829893\n",
      "-----Epoch:  320 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.2996506392152655\n",
      "-----Epoch:  330 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.29740020028180025\n",
      "-----Epoch:  340 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.295225854287592\n",
      "-----Epoch:  350 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.29312293395764594\n",
      "-----Epoch:  360 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.29108718157320174\n",
      "-----Epoch:  370 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.2891147043781447\n",
      "-----Epoch:  380 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.28720193560439417\n",
      "-----Epoch:  390 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.2853456003256205\n",
      "-----Epoch:  400 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.2835426854701543\n",
      "-----Epoch:  410 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.28179041342540767\n",
      "-----Epoch:  420 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2800862187510185\n",
      "-----Epoch:  430 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.27842772758914985\n",
      "-----Epoch:  440 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2768127394202378\n",
      "-----Epoch:  450 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.27523921086294395\n",
      "-----Epoch:  460 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2737052412596817\n",
      "-----Epoch:  470 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.272209059825176\n",
      "-----Epoch:  480 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2707490141661292\n",
      "-----Epoch:  490 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.26932356000611624\n",
      "-----Epoch:  500 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.26793125197203177\n",
      "-----Epoch:  510 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2665707353173768\n",
      "-----Epoch:  520 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2652407384739164\n",
      "-----Epoch:  530 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2639400663371705\n",
      "-----Epoch:  540 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.26266759420318403\n",
      "-----Epoch:  550 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2614222622843423\n",
      "-----Epoch:  560 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2602030707409138\n",
      "-----Epoch:  570 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2590090751727091\n",
      "-----Epoch:  580 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2578393825219295\n",
      "-----Epoch:  590 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.25669314734408144\n",
      "-----Epoch:  600 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2555695684088816\n",
      "-----Epoch:  610 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2544678855974789\n",
      "-----Epoch:  620 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2533873770661618\n",
      "-----Epoch:  630 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2523273566500833\n",
      "-----Epoch:  640 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.25128717148347507\n",
      "-----Epoch:  650 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.25026619981541703\n",
      "-----Epoch:  660 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24926384900249143\n",
      "-----Epoch:  670 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24827955366165844\n",
      "-----Epoch:  680 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24731277396845297\n",
      "-----Epoch:  690 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24636299408716217\n",
      "-----Epoch:  700 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24542972072102098\n",
      "-----Epoch:  710 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24451248177168747\n",
      "-----Epoch:  720 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24361082509834195\n",
      "-----Epoch:  730 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24272431736771863\n",
      "-----Epoch:  740 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24185254298723438\n",
      "-----Epoch:  750 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24099510311414474\n",
      "-----Epoch:  760 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24015161473433733\n",
      "-----Epoch:  770 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2393217098049817\n",
      "-----Epoch:  780 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23850503445580068\n",
      "-----Epoch:  790 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23770124824421243\n",
      "-----Epoch:  800 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2369100234600353\n",
      "-----Epoch:  810 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23613104447583472\n",
      "-----Epoch:  820 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23536400713934716\n",
      "-----Epoch:  830 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2346086182047339\n",
      "-----Epoch:  840 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23386459479970234\n",
      "-----Epoch:  850 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23313166392579268\n",
      "-----Epoch:  860 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23240956198935755\n",
      "-----Epoch:  870 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23169803436097705\n",
      "-----Epoch:  880 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23099683496123885\n",
      "-----Epoch:  890 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2303057258709886\n",
      "-----Epoch:  900 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22962447696430935\n",
      "-----Epoch:  910 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22895286556263514\n",
      "-----Epoch:  920 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2282906761085282\n",
      "-----Epoch:  930 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22763769985777121\n",
      "-----Epoch:  940 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2269937345885302\n",
      "-----Epoch:  950 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2263585843264429\n",
      "-----Epoch:  960 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22573205908457386\n",
      "-----Epoch:  970 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22511397461726315\n",
      "-----Epoch:  980 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2245041521869646\n",
      "-----Epoch:  990 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22390241834324076\n",
      "-----Epoch:  1000 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22330860471314457\n",
      "-----Epoch:  1010 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22272254780226947\n",
      "-----Epoch:  1020 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22214408880580946\n",
      "-----Epoch:  1030 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2215730734290117\n",
      "-----Epoch:  1040 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22100935171645283\n",
      "-----Epoch:  1050 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22045277788960704\n",
      "-----Epoch:  1060 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.21990321019221565\n",
      "-----Epoch:  1070 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.219360510742997\n",
      "-----Epoch:  1080 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.218824545395271\n",
      "-----Epoch:  1090 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.21829518360309985\n",
      "-----Epoch:  1100 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.21777229829357447\n",
      "-----Epoch:  1110 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21725576574489922\n",
      "-----Epoch:  1120 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2167454654699527\n",
      "-----Epoch:  1130 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21624128010502167\n",
      "-----Epoch:  1140 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21574309530342664\n",
      "-----Epoch:  1150 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21525079963377253\n",
      "-----Epoch:  1160 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21476428448258025\n",
      "-----Epoch:  1170 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21428344396106358\n",
      "-----Epoch:  1180 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21380817481583791\n",
      "-----Epoch:  1190 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2133383763433524\n",
      "-----Epoch:  1200 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21287395030785894\n",
      "-----Epoch:  1210 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2124148008627346\n",
      "-----Epoch:  1220 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21196083447498984\n",
      "-----Epoch:  1230 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21151195985280383\n",
      "-----Epoch:  1240 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2110680878759375\n",
      "-----Epoch:  1250 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21062913152888335\n",
      "-----Epoch:  1260 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2101950058366185\n",
      "-----Epoch:  1270 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20976562780283886\n",
      "-----Epoch:  1280 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20934091635055296\n",
      "-----Epoch:  1290 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20892079226492719\n",
      "-----Epoch:  1300 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20850517813827685\n",
      "-----Epoch:  1310 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20809399831710268\n",
      "-----Epoch:  1320 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20768717885108068\n",
      "-----Epoch:  1330 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20728464744391625\n",
      "-----Epoch:  1340 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2068863334059787\n",
      "-----Epoch:  1350 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.206492167608637\n",
      "-----Epoch:  1360 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20610208244022143\n",
      "-----Epoch:  1370 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20571601176354082\n",
      "-----Epoch:  1380 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20533389087488751\n",
      "-----Epoch:  1390 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2049556564644652\n",
      "-----Epoch:  1400 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.204581246578181\n",
      "-----Epoch:  1410 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20421060058074259\n",
      "-----Epoch:  1420 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20384365912000624\n",
      "-----Epoch:  1430 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20348036409252435\n",
      "-----Epoch:  1440 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20312065861024187\n",
      "-----Epoch:  1450 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20276448696829694\n",
      "-----Epoch:  1460 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20241179461387754\n",
      "-----Epoch:  1470 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20206252811609635\n",
      "-----Epoch:  1480 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2017166351368386\n",
      "-----Epoch:  1490 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20137406440254849\n",
      "-----Epoch:  1500 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20103476567691425\n",
      "-----Epoch:  1510 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2006986897344193\n",
      "-----Epoch:  1520 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2003657883347248\n",
      "-----Epoch:  1530 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20003601419785172\n",
      "-----Epoch:  1540 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19970932098013316\n",
      "-----Epoch:  1550 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19938566325090668\n",
      "-----Epoch:  1560 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19906499646992004\n",
      "-----Epoch:  1570 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19874727696542283\n",
      "-----Epoch:  1580 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19843246191291958\n",
      "-----Epoch:  1590 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19812050931455982\n",
      "-----Epoch:  1600 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19781137797914178\n",
      "-----Epoch:  1610 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19750502750270849\n",
      "-----Epoch:  1620 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1972014182497137\n",
      "-----Epoch:  1630 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19690051133473865\n",
      "-----Epoch:  1640 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1966022686047394\n",
      "-----Epoch:  1650 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19630665262180702\n",
      "-----Epoch:  1660 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19601362664642175\n",
      "-----Epoch:  1670 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19572315462118525\n",
      "-----Epoch:  1680 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19543520115501267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  1690 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19514973150777185\n",
      "-----Epoch:  1700 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1948667115753517\n",
      "-----Epoch:  1710 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19458610787514613\n",
      "-----Epoch:  1720 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19430788753194048\n",
      "-----Epoch:  1730 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1940320182641872\n",
      "-----Epoch:  1740 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19375846837065558\n",
      "-----Epoch:  1750 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19348720671744624\n",
      "-----Epoch:  1760 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19321820272535717\n",
      "-----Epoch:  1770 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1929514263575893\n",
      "-----Epoch:  1780 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19268684810778214\n",
      "-----Epoch:  1790 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19242443898836803\n",
      "-----Epoch:  1800 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1921641705192343\n",
      "-----Epoch:  1810 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1919060147166858\n",
      "-----Epoch:  1820 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1916499440826953\n",
      "-----Epoch:  1830 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19139593159443555\n",
      "-----Epoch:  1840 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19114395069408274\n",
      "-----Epoch:  1850 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1908939752788833\n",
      "-----Epoch:  1860 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19064597969147612\n",
      "-----Epoch:  1870 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1903999387104617\n",
      "-----Epoch:  1880 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19015582754121288\n",
      "-----Epoch:  1890 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.18991362180691648\n",
      "-----Epoch:  1900 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.18967329753984175\n",
      "-----Epoch:  1910 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.18943483117282792\n",
      "-----Epoch:  1920 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18919819953098385\n",
      "-----Epoch:  1930 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18896337982359412\n",
      "-----Epoch:  1940 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18873034963622584\n",
      "-----Epoch:  1950 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18849908692302886\n",
      "-----Epoch:  1960 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18826956999922553\n",
      "-----Epoch:  1970 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1880417775337834\n",
      "-----Epoch:  1980 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18781568854226594\n",
      "-----Epoch:  1990 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18759128237985606\n",
      "-----Epoch:  2000 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18736853873454795\n",
      "-----Epoch:  2010 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18714743762050187\n",
      "-----Epoch:  2020 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18692795937155718\n",
      "-----Epoch:  2030 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18671008463490055\n",
      "-----Epoch:  2040 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18649379436488284\n",
      "-----Epoch:  2050 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1862790698169831\n",
      "-----Epoch:  2060 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18606589254191208\n",
      "-----Epoch:  2070 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1858542443798561\n",
      "-----Epoch:  2080 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18564410745485294\n",
      "-----Epoch:  2090 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18543546416929862\n",
      "-----Epoch:  2100 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1852282971985818\n",
      "-----Epoch:  2110 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18502258948584002\n",
      "-----Epoch:  2120 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1848183242368373\n",
      "-----Epoch:  2130 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18461548491495783\n",
      "-----Epoch:  2140 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18441405523631368\n",
      "-----Epoch:  2150 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18421401916496327\n",
      "-----Epoch:  2160 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18401536090823722\n",
      "-----Epoch:  2170 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18381806491216987\n",
      "-----Epoch:  2180 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18362211585703148\n",
      "-----Epoch:  2190 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1834274986529621\n",
      "-----Epoch:  2200 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18323419843570046\n",
      "-----Epoch:  2210 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18304220056240852\n",
      "-----Epoch:  2220 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18285149060758693\n",
      "-----Epoch:  2230 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18266205435908126\n",
      "-----Epoch:  2240 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18247387781417457\n",
      "-----Epoch:  2250 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18228694717576574\n",
      "-----Epoch:  2260 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18210124884863044\n",
      "-----Epoch:  2270 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.181916769435763\n",
      "-----Epoch:  2280 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18173349573479686\n",
      "-----Epoch:  2290 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18155141473450284\n",
      "-----Epoch:  2300 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1813705136113607\n",
      "-----Epoch:  2310 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18119077972620518\n",
      "-----Epoch:  2320 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1810122006209426\n",
      "-----Epoch:  2330 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18083476401533724\n",
      "-----Epoch:  2340 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18065845780386525\n",
      "-----Epoch:  2350 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.180483270052635\n",
      "-----Epoch:  2360 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18030918899637133\n",
      "-----Epoch:  2370 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18013620303546352\n",
      "-----Epoch:  2380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17996430073307418\n",
      "-----Epoch:  2390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17979347081230812\n",
      "-----Epoch:  2400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17962370215344026\n",
      "-----Epoch:  2410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17945498379119904\n",
      "-----Epoch:  2420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17928730491210798\n",
      "-----Epoch:  2430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17912065485187945\n",
      "-----Epoch:  2440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17895502309286276\n",
      "-----Epoch:  2450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17879039926154366\n",
      "-----Epoch:  2460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17862677312609443\n",
      "-----Epoch:  2470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17846413459397426\n",
      "-----Epoch:  2480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1783024737095761\n",
      "-----Epoch:  2490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.178141780651923\n",
      "-----Epoch:  2500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17798204573240814\n",
      "-----Epoch:  2510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17782325939258226\n",
      "-----Epoch:  2520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17766541220198268\n",
      "-----Epoch:  2530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1775084948560075\n",
      "-----Epoch:  2540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17735249817382967\n",
      "-----Epoch:  2550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17719741309635378\n",
      "-----Epoch:  2560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17704323068421246\n",
      "-----Epoch:  2570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1768899421158009\n",
      "-----Epoch:  2580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17673753868535125\n",
      "-----Epoch:  2590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17658601180104339\n",
      "-----Epoch:  2600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17643535298315235\n",
      "-----Epoch:  2610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17628555386223235\n",
      "-----Epoch:  2620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17613660617733484\n",
      "-----Epoch:  2630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1759885017742605\n",
      "-----Epoch:  2640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1758412326038465\n",
      "-----Epoch:  2650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1756947907202837\n",
      "-----Epoch:  2660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17554916827946862\n",
      "-----Epoch:  2670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17540435753738445\n",
      "-----Epoch:  2680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17526035084851366\n",
      "-----Epoch:  2690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17511714066428105\n",
      "-----Epoch:  2700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17497471953152466\n",
      "-----Epoch:  2710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17483308009099646\n",
      "-----Epoch:  2720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17469221507589017\n",
      "-----Epoch:  2730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17455211731039755\n",
      "-----Epoch:  2740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17441277970829078\n",
      "-----Epoch:  2750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17427419527153087\n",
      "-----Epoch:  2760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17413635708890227\n",
      "-----Epoch:  2770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17399925833467247\n",
      "-----Epoch:  2780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17386289226727603\n",
      "-----Epoch:  2790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1737272522280231\n",
      "-----Epoch:  2800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17359233163983057\n",
      "-----Epoch:  2810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17345812400597768\n",
      "-----Epoch:  2820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17332462290888279\n",
      "-----Epoch:  2830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17319182200890348\n",
      "-----Epoch:  2840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17305971504315731\n",
      "-----Epoch:  2850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17292829582436442\n",
      "-----Epoch:  2860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17279755823971066\n",
      "-----Epoch:  2870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17266749624973105\n",
      "-----Epoch:  2880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17253810388721325\n",
      "-----Epoch:  2890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1724093752561201\n",
      "-----Epoch:  2900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17228130453053223\n",
      "-----Epoch:  2910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17215388595360795\n",
      "-----Epoch:  2920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17202711383656313\n",
      "-----Epoch:  2930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17190098255766728\n",
      "-----Epoch:  2940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17177548656125932\n",
      "-----Epoch:  2950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1716506203567777\n",
      "-----Epoch:  2960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17152637851781022\n",
      "-----Epoch:  2970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17140275568115948\n",
      "-----Epoch:  2980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17127974654592318\n",
      "-----Epoch:  2990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17115734587259246\n",
      "-----Epoch:  3000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17103554848216423\n",
      "-----Epoch:  3010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1709143492552693\n",
      "-----Epoch:  3020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17079374313131598\n",
      "-----Epoch:  3030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.170673725107647\n",
      "-----Epoch:  3040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1705542902387127\n",
      "-----Epoch:  3050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17043543363525623\n",
      "-----Epoch:  3060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17031715046351378\n",
      "-----Epoch:  3070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1701994359444289\n",
      "-----Epoch:  3080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17008228535287848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  3090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16996569401691278\n",
      "-----Epoch:  3100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16984965731700818\n",
      "-----Epoch:  3110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16973417068533236\n",
      "-----Epoch:  3120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16961922960502163\n",
      "-----Epoch:  3130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16950482960947022\n",
      "-----Epoch:  3140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16939096628163178\n",
      "-----Epoch:  3150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16927763525333175\n",
      "-----Epoch:  3160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1691648322045922\n",
      "-----Epoch:  3170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1690525528629665\n",
      "-----Epoch:  3180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1689407930028858\n",
      "-----Epoch:  3190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16882954844501624\n",
      "-----Epoch:  3200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16871881505562583\n",
      "-----Epoch:  3210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1686085887459632\n",
      "-----Epoch:  3220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16849886547164405\n",
      "-----Epoch:  3230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16838964123205075\n",
      "-----Epoch:  3240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1682809120697384\n",
      "-----Epoch:  3250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16817267406985298\n",
      "-----Epoch:  3260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1680649233595573\n",
      "-----Epoch:  3270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16795765610746693\n",
      "-----Epoch:  3280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1678508685230956\n",
      "-----Epoch:  3290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1677445568563077\n",
      "-----Epoch:  3300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1676387173967814\n",
      "-----Epoch:  3310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16753334647347992\n",
      "-----Epoch:  3320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16742844045412933\n",
      "-----Epoch:  3330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1673239957447084\n",
      "-----Epoch:  3340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16722000878894197\n",
      "-----Epoch:  3350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1671164760678061\n",
      "-----Epoch:  3360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16701339409903837\n",
      "-----Epoch:  3370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16691075943665776\n",
      "-----Epoch:  3380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16680856867049068\n",
      "-----Epoch:  3390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16670681842570506\n",
      "-----Epoch:  3400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1666055053623511\n",
      "-----Epoch:  3410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16650462617491057\n",
      "-----Epoch:  3420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1664041775918506\n",
      "-----Epoch:  3430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16630415637518717\n",
      "-----Epoch:  3440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16620455932005307\n",
      "-----Epoch:  3450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16610538325427388\n",
      "-----Epoch:  3460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1660066250379496\n",
      "-----Epoch:  3470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1659082815630431\n",
      "-----Epoch:  3480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16581034975297526\n",
      "-----Epoch:  3490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16571282656222486\n",
      "-----Epoch:  3500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16561570897593633\n",
      "-----Epoch:  3510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16551899400953174\n",
      "-----Epoch:  3520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16542267870833008\n",
      "-----Epoch:  3530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16532676014717143\n",
      "-----Epoch:  3540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16523123543004722\n",
      "-----Epoch:  3550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16513610168973494\n",
      "-----Epoch:  3560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1650413560874405\n",
      "-----Epoch:  3570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16494699581244335\n",
      "-----Epoch:  3580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16485301808174915\n",
      "-----Epoch:  3590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1647594201397457\n",
      "-----Epoch:  3600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16466619925786552\n",
      "-----Epoch:  3610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1645733527342523\n",
      "-----Epoch:  3620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1644808778934328\n",
      "-----Epoch:  3630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1643887720859937\n",
      "-----Epoch:  3640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1642970326882624\n",
      "-----Epoch:  3650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16420565710199375\n",
      "-----Epoch:  3660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16411464275406\n",
      "-----Epoch:  3670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1640239870961466\n",
      "-----Epoch:  3680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1639336876044507\n",
      "-----Epoch:  3690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16384374177938643\n",
      "-----Epoch:  3700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16375414714529182\n",
      "-----Epoch:  3710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16366490125014177\n",
      "-----Epoch:  3720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16357600166526468\n",
      "-----Epoch:  3730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1634874459850627\n",
      "-----Epoch:  3740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1633992318267361\n",
      "-----Epoch:  3750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1633113568300131\n",
      "-----Epoch:  3760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16322381865688051\n",
      "-----Epoch:  3770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16313661499132115\n",
      "-----Epoch:  3780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16304974353905333\n",
      "-----Epoch:  3790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16296320202727466\n",
      "-----Epoch:  3800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16287698820440905\n",
      "-----Epoch:  3810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16279109983985787\n",
      "-----Epoch:  3820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16270553472375415\n",
      "-----Epoch:  3830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16262029066672004\n",
      "-----Epoch:  3840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16253536549962858\n",
      "-----Epoch:  3850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16245075707336795\n",
      "-----Epoch:  3860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16236646325860837\n",
      "-----Epoch:  3870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16228248194557496\n",
      "-----Epoch:  3880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16219881104382006\n",
      "-----Epoch:  3890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16211544848200188\n",
      "-----Epoch:  3900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16203239220766377\n",
      "-----Epoch:  3910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16194964018701882\n",
      "-----Epoch:  3920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16186719040473524\n",
      "-----Epoch:  3930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16178504086372622\n",
      "-----Epoch:  3940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16170318958494206\n",
      "-----Epoch:  3950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16162163460716505\n",
      "-----Epoch:  3960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16154037398680732\n",
      "-----Epoch:  3970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16145940579771156\n",
      "-----Epoch:  3980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16137872813095422\n",
      "-----Epoch:  3990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16129833909465177\n",
      "-----Epoch:  4000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16121823681376843\n",
      "-----Epoch:  4010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16113841942992813\n",
      "-----Epoch:  4020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16105888510122834\n",
      "-----Epoch:  4030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16097963200205517\n",
      "-----Epoch:  4040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16090065832290296\n",
      "-----Epoch:  4050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16082196227019555\n",
      "-----Epoch:  4060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1607435420661085\n",
      "-----Epoch:  4070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1606653959483961\n",
      "-----Epoch:  4080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.160587522170219\n",
      "-----Epoch:  4090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1605099189999749\n",
      "-----Epoch:  4100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16043258472113045\n",
      "-----Epoch:  4110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16035551763205674\n",
      "-----Epoch:  4120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1602787160458664\n",
      "-----Epoch:  4130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16020217829025218\n",
      "-----Epoch:  4140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1601259027073287\n",
      "-----Epoch:  4150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16004988765347555\n",
      "-----Epoch:  4160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1599741314991827\n",
      "-----Epoch:  4170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15989863262889775\n",
      "-----Epoch:  4180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15982338944087562\n",
      "-----Epoch:  4190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15974840034702983\n",
      "-----Epoch:  4200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15967366377278536\n",
      "-----Epoch:  4210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1595991781569341\n",
      "-----Epoch:  4220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15952494195149178\n",
      "-----Epoch:  4230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15945095362155662\n",
      "-----Epoch:  4240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15937721164517074\n",
      "-----Epoch:  4250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15930371451318148\n",
      "-----Epoch:  4260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15923046072910613\n",
      "-----Epoch:  4270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15915744880899818\n",
      "-----Epoch:  4280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1590846772813144\n",
      "-----Epoch:  4290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15901214468678426\n",
      "-----Epoch:  4300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1589398495782811\n",
      "-----Epoch:  4310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15886779052069464\n",
      "-----Epoch:  4320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1587959660908049\n",
      "-----Epoch:  4330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1587243748771583\n",
      "-----Epoch:  4340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.158653015479945\n",
      "-----Epoch:  4350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15858188651087737\n",
      "-----Epoch:  4360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15851098659307095\n",
      "-----Epoch:  4370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1584403143609258\n",
      "-----Epoch:  4380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15836986846001022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  4390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15829964754694537\n",
      "-----Epoch:  4400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15822965028929162\n",
      "-----Epoch:  4410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15815987536543566\n",
      "-----Epoch:  4420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15809032146448068\n",
      "-----Epoch:  4430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15802098728613548\n",
      "-----Epoch:  4440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15795187154060675\n",
      "-----Epoch:  4450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15788297294849235\n",
      "-----Epoch:  4460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15781429024067553\n",
      "-----Epoch:  4470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15774582215822058\n",
      "-----Epoch:  4480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15767756745226924\n",
      "-----Epoch:  4490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15760952488393967\n",
      "-----Epoch:  4500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15754169322422595\n",
      "-----Epoch:  4510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1574740712538978\n",
      "-----Epoch:  4520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15740665776340326\n",
      "-----Epoch:  4530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15733945155277146\n",
      "-----Epoch:  4540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15727245143151675\n",
      "-----Epoch:  4550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15720565621854404\n",
      "-----Epoch:  4560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15713906474205586\n",
      "-----Epoch:  4570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1570726758394587\n",
      "-----Epoch:  4580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15700648835727316\n",
      "-----Epoch:  4590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15694050115104252\n",
      "-----Epoch:  4600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15687471308524506\n",
      "-----Epoch:  4610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15680912303320446\n",
      "-----Epoch:  4620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15674372987700347\n",
      "-----Epoch:  4630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15667853250739813\n",
      "-----Epoch:  4640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15661352982373267\n",
      "-----Epoch:  4650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15654872073385528\n",
      "-----Epoch:  4660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15648410415403535\n",
      "-----Epoch:  4670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15641967900888118\n",
      "-----Epoch:  4680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15635544423125958\n",
      "-----Epoch:  4690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1562913987622152\n",
      "-----Epoch:  4700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1562275415508913\n",
      "-----Epoch:  4710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.156163871554452\n",
      "-----Epoch:  4720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15610038773800458\n",
      "-----Epoch:  4730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15603708907452282\n",
      "-----Epoch:  4740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15597397454477233\n",
      "-----Epoch:  4750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15591104313723506\n",
      "-----Epoch:  4760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15584829384803553\n",
      "-----Epoch:  4770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15578572568086832\n",
      "-----Epoch:  4780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1557233376469257\n",
      "-----Epoch:  4790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1556611287648261\n",
      "-----Epoch:  4800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15559909806054406\n",
      "-----Epoch:  4810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15553724456734017\n",
      "-----Epoch:  4820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15547556732569257\n",
      "-----Epoch:  4830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15541406538322872\n",
      "-----Epoch:  4840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15535273779465741\n",
      "-----Epoch:  4850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15529158362170342\n",
      "-----Epoch:  4860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15523060193304083\n",
      "-----Epoch:  4870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15516979180422807\n",
      "-----Epoch:  4880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.155109152317644\n",
      "-----Epoch:  4890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15504868256242388\n",
      "-----Epoch:  4900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1549883816343965\n",
      "-----Epoch:  4910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15492824863602236\n",
      "-----Epoch:  4920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15486828267633168\n",
      "-----Epoch:  4930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15480848287086418\n",
      "-----Epoch:  4940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15474884834160815\n",
      "-----Epoch:  4950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15468937821694187\n",
      "-----Epoch:  4960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15463007163157416\n",
      "-----Epoch:  4970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15457092772648676\n",
      "-----Epoch:  4980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15451194564887605\n",
      "-----Epoch:  4990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15445312455209712\n",
      "-----Epoch:  5000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15439446359560702\n",
      "-----Epoch:  5010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15433596194490906\n",
      "-----Epoch:  5020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15427761877149787\n",
      "-----Epoch:  5030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15421943325280535\n",
      "-----Epoch:  5040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1541614045721465\n",
      "-----Epoch:  5050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15410353191866594\n",
      "-----Epoch:  5060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15404581448728594\n",
      "-----Epoch:  5070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15398825147865391\n",
      "-----Epoch:  5080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15393084209909116\n",
      "-----Epoch:  5090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1538735855605413\n",
      "-----Epoch:  5100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15381648108052062\n",
      "-----Epoch:  5110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.153759527882068\n",
      "-----Epoch:  5120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15370272519369563\n",
      "-----Epoch:  5130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15364607224933968\n",
      "-----Epoch:  5140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15358956828831283\n",
      "-----Epoch:  5150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15353321255525632\n",
      "-----Epoch:  5160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15347700430009215\n",
      "-----Epoch:  5170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15342094277797702\n",
      "-----Epoch:  5180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1533650272492559\n",
      "-----Epoch:  5190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15330925697941636\n",
      "-----Epoch:  5200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1532536312390431\n",
      "-----Epoch:  5210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1531981493037733\n",
      "-----Epoch:  5220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15314281045425207\n",
      "-----Epoch:  5230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1530876139760895\n",
      "-----Epoch:  5240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15303255915981614\n",
      "-----Epoch:  5250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15297764530084076\n",
      "-----Epoch:  5260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15292287169940819\n",
      "-----Epoch:  5270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15286823766055602\n",
      "-----Epoch:  5280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1528137424940747\n",
      "-----Epoch:  5290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1527593855144651\n",
      "-----Epoch:  5300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15270516604089845\n",
      "-----Epoch:  5310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15265108339717604\n",
      "-----Epoch:  5320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15259713691168902\n",
      "-----Epoch:  5330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15254332591737918\n",
      "-----Epoch:  5340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15248964975169976\n",
      "-----Epoch:  5350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15243610775657734\n",
      "-----Epoch:  5360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15238269927837253\n",
      "-----Epoch:  5370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15232942366784355\n",
      "-----Epoch:  5380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15227628028010748\n",
      "-----Epoch:  5390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15222326847460377\n",
      "-----Epoch:  5400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15217038761505758\n",
      "-----Epoch:  5410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15211763706944362\n",
      "-----Epoch:  5420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15206501620994942\n",
      "-----Epoch:  5430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15201252441294086\n",
      "-----Epoch:  5440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15196016105892599\n",
      "-----Epoch:  5450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15190792553252092\n",
      "-----Epoch:  5460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1518558172224148\n",
      "-----Epoch:  5470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15180383552133597\n",
      "-----Epoch:  5480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15175197982601776\n",
      "-----Epoch:  5490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15170024953716565\n",
      "-----Epoch:  5500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15164864405942358\n",
      "-----Epoch:  5510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15159716280134142\n",
      "-----Epoch:  5520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1515458051753424\n",
      "-----Epoch:  5530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1514945705976914\n",
      "-----Epoch:  5540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.151443458488462\n",
      "-----Epoch:  5550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1513924682715064\n",
      "-----Epoch:  5560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15134159937442357\n",
      "-----Epoch:  5570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15129085122852792\n",
      "-----Epoch:  5580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15124022326881936\n",
      "-----Epoch:  5590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15118971493395306\n",
      "-----Epoch:  5600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15113932566620927\n",
      "-----Epoch:  5610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15108905491146327\n",
      "-----Epoch:  5620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15103890211915713\n",
      "-----Epoch:  5630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15098886674226897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  5640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15093894823728604\n",
      "-----Epoch:  5650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1508891460641746\n",
      "-----Epoch:  5660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15083945968635257\n",
      "-----Epoch:  5670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15078988857066122\n",
      "-----Epoch:  5680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15074043218733782\n",
      "-----Epoch:  5690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1506910900099876\n",
      "-----Epoch:  5700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15064186151555747\n",
      "-----Epoch:  5710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15059274618430843\n",
      "-----Epoch:  5720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15054374349978913\n",
      "-----Epoch:  5730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15049485294880968\n",
      "-----Epoch:  5740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1504460740214155\n",
      "-----Epoch:  5750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15039740621086106\n",
      "-----Epoch:  5760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1503488490135851\n",
      "-----Epoch:  5770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15030040192918437\n",
      "-----Epoch:  5780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1502520644603887\n",
      "-----Epoch:  5790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15020383611303711\n",
      "-----Epoch:  5800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15015571639605155\n",
      "-----Epoch:  5810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.150107704821414\n",
      "-----Epoch:  5820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1500598009041413\n",
      "-----Epoch:  5830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15001200416226157\n",
      "-----Epoch:  5840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14996431411679054\n",
      "-----Epoch:  5850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14991673029170802\n",
      "-----Epoch:  5860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1498692522139345\n",
      "-----Epoch:  5870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14982187941330857\n",
      "-----Epoch:  5880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14977461142256351\n",
      "-----Epoch:  5890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14972744777730496\n",
      "-----Epoch:  5900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1496803880159884\n",
      "-----Epoch:  5910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14963343167989715\n",
      "-----Epoch:  5920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14958657831312064\n",
      "-----Epoch:  5930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14953982746253183\n",
      "-----Epoch:  5940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14949317867776624\n",
      "-----Epoch:  5950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14944663151120074\n",
      "-----Epoch:  5960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14940018551793194\n",
      "-----Epoch:  5970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14935384025575535\n",
      "-----Epoch:  5980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14930759528514467\n",
      "-----Epoch:  5990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1492614501692314\n",
      "-----Epoch:  6000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14921540447378404\n",
      "-----Epoch:  6010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14916945776718823\n",
      "-----Epoch:  6020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14912360962042656\n",
      "-----Epoch:  6030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14907785960705885\n",
      "-----Epoch:  6040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14903220730320255\n",
      "-----Epoch:  6050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14898665228751304\n",
      "-----Epoch:  6060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14894119414116466\n",
      "-----Epoch:  6070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14889583244783128\n",
      "-----Epoch:  6080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14885056679366737\n",
      "-----Epoch:  6090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14880539676728985\n",
      "-----Epoch:  6100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14876032195975886\n",
      "-----Epoch:  6110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14871534196455946\n",
      "-----Epoch:  6120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14867045637758353\n",
      "-----Epoch:  6130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14862566479711145\n",
      "-----Epoch:  6140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1485809668237947\n",
      "-----Epoch:  6150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14853636206063725\n",
      "-----Epoch:  6160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14849185011297902\n",
      "-----Epoch:  6170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14844743058847754\n",
      "-----Epoch:  6180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14840310309709118\n",
      "-----Epoch:  6190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14835886725106145\n",
      "-----Epoch:  6200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14831472266489723\n",
      "-----Epoch:  6210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1482706689553562\n",
      "-----Epoch:  6220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14822670574143001\n",
      "-----Epoch:  6230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14818283264432644\n",
      "-----Epoch:  6240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14813904928745333\n",
      "-----Epoch:  6250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14809535529640303\n",
      "-----Epoch:  6260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1480517502989354\n",
      "-----Epoch:  6270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14800823392496243\n",
      "-----Epoch:  6280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14796480580653207\n",
      "-----Epoch:  6290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1479214655778129\n",
      "-----Epoch:  6300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14787821287507885\n",
      "-----Epoch:  6310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14783504733669292\n",
      "-----Epoch:  6320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14779196860309285\n",
      "-----Epoch:  6330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14774897631677555\n",
      "-----Epoch:  6340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1477060701222823\n",
      "-----Epoch:  6350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14766324966618366\n",
      "-----Epoch:  6360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14762051459706524\n",
      "-----Epoch:  6370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1475778645655123\n",
      "-----Epoch:  6380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14753529922409642\n",
      "-----Epoch:  6390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14749281822736024\n",
      "-----Epoch:  6400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14745042123180344\n",
      "-----Epoch:  6410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14740810789586892\n",
      "-----Epoch:  6420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14736587787992894\n",
      "-----Epoch:  6430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1473237308462705\n",
      "-----Epoch:  6440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1472816664590829\n",
      "-----Epoch:  6450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1472396843844426\n",
      "-----Epoch:  6460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14719778429030123\n",
      "-----Epoch:  6470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14715596584647114\n",
      "-----Epoch:  6480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1471142287246128\n",
      "-----Epoch:  6490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14707257259822104\n",
      "-----Epoch:  6500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14703099714261306\n",
      "-----Epoch:  6510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1469895020349141\n",
      "-----Epoch:  6520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14694808695404618\n",
      "-----Epoch:  6530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14690675158071398\n",
      "-----Epoch:  6540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14686549559739315\n",
      "-----Epoch:  6550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14682431868831777\n",
      "-----Epoch:  6560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14678322053946746\n",
      "-----Epoch:  6570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14674220083855594\n",
      "-----Epoch:  6580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14670125927501773\n",
      "-----Epoch:  6590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14666039553999763\n",
      "-----Epoch:  6600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14661960932633697\n",
      "-----Epoch:  6610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14657890032856338\n",
      "-----Epoch:  6620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14653826824287794\n",
      "-----Epoch:  6630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14649771276714413\n",
      "-----Epoch:  6640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14645723360087606\n",
      "-----Epoch:  6650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14641683044522677\n",
      "-----Epoch:  6660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14637650300297766\n",
      "-----Epoch:  6670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14633625097852615\n",
      "-----Epoch:  6680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14629607407787515\n",
      "-----Epoch:  6690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.146255972008622\n",
      "-----Epoch:  6700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14621594447994737\n",
      "-----Epoch:  6710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14617599120260436\n",
      "-----Epoch:  6720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14613611188890738\n",
      "-----Epoch:  6730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14609630625272205\n",
      "-----Epoch:  6740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14605657400945443\n",
      "-----Epoch:  6750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1460169148760398\n",
      "-----Epoch:  6760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14597732857093307\n",
      "-----Epoch:  6770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14593781481409804\n",
      "-----Epoch:  6780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1458983733269971\n",
      "-----Epoch:  6790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14585900383258107\n",
      "-----Epoch:  6800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14581970605527922\n",
      "-----Epoch:  6810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14578047972098895\n",
      "-----Epoch:  6820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14574132455706643\n",
      "-----Epoch:  6830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14570224029231565\n",
      "-----Epoch:  6840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14566322665697992\n",
      "-----Epoch:  6850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14562428338273148\n",
      "-----Epoch:  6860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14558541020266177\n",
      "-----Epoch:  6870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14554660685127221\n",
      "-----Epoch:  6880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14550787306446458\n",
      "-----Epoch:  6890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14546920857953147\n",
      "-----Epoch:  6900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14543061313514768\n",
      "-----Epoch:  6910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14539208647135987\n",
      "-----Epoch:  6920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1453536283295784\n",
      "-----Epoch:  6930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14531523845256747\n",
      "-----Epoch:  6940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14527691658443675\n",
      "-----Epoch:  6950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14523866247063197\n",
      "-----Epoch:  6960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14520047585792636\n",
      "-----Epoch:  6970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14516235649441156\n",
      "-----Epoch:  6980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14512430412948926\n",
      "-----Epoch:  6990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14508631851386186\n",
      "-----Epoch:  7000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14504839939952496\n",
      "-----Epoch:  7010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1450105465397579\n",
      "-----Epoch:  7020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14497275968911558\n",
      "-----Epoch:  7030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1449350386034199\n",
      "-----Epoch:  7040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14489738303975236\n",
      "-----Epoch:  7050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1448597927564446\n",
      "-----Epoch:  7060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14482226751307042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  7070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14478480707043878\n",
      "-----Epoch:  7080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14474741119058418\n",
      "-----Epoch:  7090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14471007963675994\n",
      "-----Epoch:  7100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14467281217342917\n",
      "-----Epoch:  7110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14463560856625812\n",
      "-----Epoch:  7120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14459846858210698\n",
      "-----Epoch:  7130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14456139198902349\n",
      "-----Epoch:  7140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14452437855623437\n",
      "-----Epoch:  7150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1444874280541378\n",
      "-----Epoch:  7160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14445054025429635\n",
      "-----Epoch:  7170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14441371492942887\n",
      "-----Epoch:  7180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14437695185340327\n",
      "-----Epoch:  7190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14434025080122945\n",
      "-----Epoch:  7200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14430361154905155\n",
      "-----Epoch:  7210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1442670338741405\n",
      "-----Epoch:  7220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14423051755488767\n",
      "-----Epoch:  7230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14419406237079674\n",
      "-----Epoch:  7240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14415766810247715\n",
      "-----Epoch:  7250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14412133453163684\n",
      "-----Epoch:  7260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14408506144107527\n",
      "-----Epoch:  7270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14404884861467668\n",
      "-----Epoch:  7280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14401269583740275\n",
      "-----Epoch:  7290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14397660289528644\n",
      "-----Epoch:  7300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14394056957542464\n",
      "-----Epoch:  7310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14390459566597133\n",
      "-----Epoch:  7320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14386868095613173\n",
      "-----Epoch:  7330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14383282523615448\n",
      "-----Epoch:  7340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14379702829732627\n",
      "-----Epoch:  7350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14376128993196452\n",
      "-----Epoch:  7360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.143725609933411\n",
      "-----Epoch:  7370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14368998809602568\n",
      "-----Epoch:  7380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1436544242151802\n",
      "-----Epoch:  7390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14361891808725127\n",
      "-----Epoch:  7400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1435834695096151\n",
      "-----Epoch:  7410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14354807828064037\n",
      "-----Epoch:  7420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14351274419968238\n",
      "-----Epoch:  7430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14347746706707695\n",
      "-----Epoch:  7440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1434422466841346\n",
      "-----Epoch:  7450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14340708285313372\n",
      "-----Epoch:  7460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14337197537731503\n",
      "-----Epoch:  7470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14333692406087595\n",
      "-----Epoch:  7480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14330192870896427\n",
      "-----Epoch:  7490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14326698912767202\n",
      "-----Epoch:  7500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14323210512403028\n",
      "-----Epoch:  7510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14319727650600328\n",
      "-----Epoch:  7520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14316250308248177\n",
      "-----Epoch:  7530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14312778466327886\n",
      "-----Epoch:  7540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14309312105912292\n",
      "-----Epoch:  7550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.143058512081653\n",
      "-----Epoch:  7560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14302395754341238\n",
      "-----Epoch:  7570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14298945725784398\n",
      "-----Epoch:  7580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14295501103928396\n",
      "-----Epoch:  7590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14292061870295703\n",
      "-----Epoch:  7600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14288628006497056\n",
      "-----Epoch:  7610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1428519949423094\n",
      "-----Epoch:  7620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1428177631528303\n",
      "-----Epoch:  7630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1427835845152572\n",
      "-----Epoch:  7640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1427494588491755\n",
      "-----Epoch:  7650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14271538597502667\n",
      "-----Epoch:  7660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14268136571410367\n",
      "-----Epoch:  7670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14264739788854533\n",
      "-----Epoch:  7680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1426134823213317\n",
      "-----Epoch:  7690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14257961883627832\n",
      "-----Epoch:  7700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.142545807258032\n",
      "-----Epoch:  7710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1425120474120651\n",
      "-----Epoch:  7720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14247833912467098\n",
      "-----Epoch:  7730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1424446822229593\n",
      "-----Epoch:  7740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14241107653485044\n",
      "-----Epoch:  7750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14237752188907118\n",
      "-----Epoch:  7760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14234401811515004\n",
      "-----Epoch:  7770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14231056504341172\n",
      "-----Epoch:  7780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1422771625049734\n",
      "-----Epoch:  7790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1422438103317393\n",
      "-----Epoch:  7800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14221050835639626\n",
      "-----Epoch:  7810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14217725641240875\n",
      "-----Epoch:  7820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14214405433401497\n",
      "-----Epoch:  7830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14211090195622206\n",
      "-----Epoch:  7840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14207779911480053\n",
      "-----Epoch:  7850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14204474564628164\n",
      "-----Epoch:  7860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14201174138795114\n",
      "-----Epoch:  7870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14197878617784596\n",
      "-----Epoch:  7880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14194587985474932\n",
      "-----Epoch:  7890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14191302225818644\n",
      "-----Epoch:  7900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14188021322842012\n",
      "-----Epoch:  7910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1418474526064465\n",
      "-----Epoch:  7920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1418147402339913\n",
      "-----Epoch:  7930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14178207595350406\n",
      "-----Epoch:  7940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14174945960815563\n",
      "-----Epoch:  7950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14171689104183324\n",
      "-----Epoch:  7960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14168437009913598\n",
      "-----Epoch:  7970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.141651896625371\n",
      "-----Epoch:  7980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14161947046654993\n",
      "-----Epoch:  7990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14158709146938356\n",
      "-----Epoch:  8000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14155475948127913\n",
      "-----Epoch:  8010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1415224743503352\n",
      "-----Epoch:  8020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1414902359253385\n",
      "-----Epoch:  8030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1414580440557597\n",
      "-----Epoch:  8040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14142589859174878\n",
      "-----Epoch:  8050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1413937993841324\n",
      "-----Epoch:  8060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14136174628440906\n",
      "-----Epoch:  8070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1413297391447453\n",
      "-----Epoch:  8080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14129777781797248\n",
      "-----Epoch:  8090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14126586215758233\n",
      "-----Epoch:  8100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14123399201772346\n",
      "-----Epoch:  8110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14120216725319765\n",
      "-----Epoch:  8120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1411703877194561\n",
      "-----Epoch:  8130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1411386532725955\n",
      "-----Epoch:  8140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1411069637693547\n",
      "-----Epoch:  8150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14107531906711077\n",
      "-----Epoch:  8160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14104371902387575\n",
      "-----Epoch:  8170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14101216349829246\n",
      "-----Epoch:  8180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1409806523496316\n",
      "-----Epoch:  8190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14094918543778778\n",
      "-----Epoch:  8200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14091776262327596\n",
      "-----Epoch:  8210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14088638376722817\n",
      "-----Epoch:  8220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14085504873139013\n",
      "-----Epoch:  8230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14082375737811745\n",
      "-----Epoch:  8240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1407925095703721\n",
      "-----Epoch:  8250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14076130517171964\n",
      "-----Epoch:  8260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14073014404632567\n",
      "-----Epoch:  8270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14069902605895165\n",
      "-----Epoch:  8280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14066795107495253\n",
      "-----Epoch:  8290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14063691896027333\n",
      "-----Epoch:  8300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14060592958144505\n",
      "-----Epoch:  8310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14057498280558228\n",
      "-----Epoch:  8320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1405440785003798\n",
      "-----Epoch:  8330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14051321653410884\n",
      "-----Epoch:  8340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14048239677561433\n",
      "-----Epoch:  8350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14045161909431172\n",
      "-----Epoch:  8360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14042088336018363\n",
      "-----Epoch:  8370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14039018944377676\n",
      "-----Epoch:  8380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14035953721619898\n",
      "-----Epoch:  8390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14032892654911577\n",
      "-----Epoch:  8400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14029835731474757\n",
      "-----Epoch:  8410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14026782938586668\n",
      "-----Epoch:  8420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14023734263579402\n",
      "-----Epoch:  8430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14020689693839627\n",
      "-----Epoch:  8440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14017649216808264\n",
      "-----Epoch:  8450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14014612819980235\n",
      "-----Epoch:  8460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1401158049090414\n",
      "-----Epoch:  8470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14008552217181933\n",
      "-----Epoch:  8480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.140055279864687\n",
      "-----Epoch:  8490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.140025077864723\n",
      "-----Epoch:  8500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1399949160495312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  8510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13996479429723793\n",
      "-----Epoch:  8520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13993471248648867\n",
      "-----Epoch:  8530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1399046704964458\n",
      "-----Epoch:  8540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13987466820678537\n",
      "-----Epoch:  8550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13984470549769465\n",
      "-----Epoch:  8560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13981478224986907\n",
      "-----Epoch:  8570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1397848983445095\n",
      "-----Epoch:  8580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13975505366331986\n",
      "-----Epoch:  8590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13972524808850412\n",
      "-----Epoch:  8600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13969548150276342\n",
      "-----Epoch:  8610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13966575378929402\n",
      "-----Epoch:  8620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13963606483178373\n",
      "-----Epoch:  8630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13960641451441047\n",
      "-----Epoch:  8640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13957680272183823\n",
      "-----Epoch:  8650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1395472293392157\n",
      "-----Epoch:  8660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.139517694252173\n",
      "-----Epoch:  8670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1394881973468194\n",
      "-----Epoch:  8680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13945873850974042\n",
      "-----Epoch:  8690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13942931762799568\n",
      "-----Epoch:  8700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13939993458911626\n",
      "-----Epoch:  8710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1393705892811019\n",
      "-----Epoch:  8720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13934128159241918\n",
      "-----Epoch:  8730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.139312011411998\n",
      "-----Epoch:  8740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1392827786292304\n",
      "-----Epoch:  8750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.139253583133967\n",
      "-----Epoch:  8760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13922442481651526\n",
      "-----Epoch:  8770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13919530356763654\n",
      "-----Epoch:  8780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13916621927854447\n",
      "-----Epoch:  8790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13913717184090163\n",
      "-----Epoch:  8800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13910816114681804\n",
      "-----Epoch:  8810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13907918708884806\n",
      "-----Epoch:  8820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13905024955998863\n",
      "-----Epoch:  8830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13902134845367678\n",
      "-----Epoch:  8840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13899248366378694\n",
      "-----Epoch:  8850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13896365508462952\n",
      "-----Epoch:  8860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13893486261094762\n",
      "-----Epoch:  8870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13890610613791557\n",
      "-----Epoch:  8880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13887738556113602\n",
      "-----Epoch:  8890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13884870077663836\n",
      "-----Epoch:  8900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13882005168087605\n",
      "-----Epoch:  8910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13879143817072462\n",
      "-----Epoch:  8920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1387628601434793\n",
      "-----Epoch:  8930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13873431749685292\n",
      "-----Epoch:  8940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1387058101289738\n",
      "-----Epoch:  8950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13867733793838366\n",
      "-----Epoch:  8960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13864890082403547\n",
      "-----Epoch:  8970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.138620498685291\n",
      "-----Epoch:  8980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.138592131421919\n",
      "-----Epoch:  8990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1385637989340934\n",
      "-----Epoch:  9000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13853550112239027\n",
      "-----Epoch:  9010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13850723788778702\n",
      "-----Epoch:  9020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13847900913165936\n",
      "-----Epoch:  9030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13845081475577956\n",
      "-----Epoch:  9040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1384226546623144\n",
      "-----Epoch:  9050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1383945287538235\n",
      "-----Epoch:  9060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13836643693325665\n",
      "-----Epoch:  9070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13833837910395236\n",
      "-----Epoch:  9080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1383103551696356\n",
      "-----Epoch:  9090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1382823650344159\n",
      "-----Epoch:  9100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13825440860278562\n",
      "-----Epoch:  9110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13822648577961755\n",
      "-----Epoch:  9120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13819859647016317\n",
      "-----Epoch:  9130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13817074058005105\n",
      "-----Epoch:  9140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13814291801528442\n",
      "-----Epoch:  9150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1381151286822397\n",
      "-----Epoch:  9160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1380873724876641\n",
      "-----Epoch:  9170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13805964933867465\n",
      "-----Epoch:  9180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1380319591427552\n",
      "-----Epoch:  9190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13800430180775555\n",
      "-----Epoch:  9200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13797667724188864\n",
      "-----Epoch:  9210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13794908535373002\n",
      "-----Epoch:  9220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13792152605221444\n",
      "-----Epoch:  9230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13789399924663567\n",
      "-----Epoch:  9240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1378665048466434\n",
      "-----Epoch:  9250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1378390427622422\n",
      "-----Epoch:  9260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13781161290378927\n",
      "-----Epoch:  9270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13778421518199332\n",
      "-----Epoch:  9280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13775684950791195\n",
      "-----Epoch:  9290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13772951579295076\n",
      "-----Epoch:  9300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13770221394886112\n",
      "-----Epoch:  9310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1376749438877384\n",
      "-----Epoch:  9320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13764770552202063\n",
      "-----Epoch:  9330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13762049876448654\n",
      "-----Epoch:  9340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13759332352825393\n",
      "-----Epoch:  9350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13756617972677773\n",
      "-----Epoch:  9360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13753906727384893\n",
      "-----Epoch:  9370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13751198608359264\n",
      "-----Epoch:  9380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13748493607046575\n",
      "-----Epoch:  9390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13745791714925645\n",
      "-----Epoch:  9400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1374309292350821\n",
      "-----Epoch:  9410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1374039722433872\n",
      "-----Epoch:  9420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13737704608994256\n",
      "-----Epoch:  9430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13735015069084286\n",
      "-----Epoch:  9440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13732328596250568\n",
      "-----Epoch:  9450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13729645182166983\n",
      "-----Epoch:  9460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13726964818539364\n",
      "-----Epoch:  9470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13724287497105322\n",
      "-----Epoch:  9480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1372161320963413\n",
      "-----Epoch:  9490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13718941947926538\n",
      "-----Epoch:  9500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13716273703814658\n",
      "-----Epoch:  9510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13713608469161745\n",
      "-----Epoch:  9520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13710946235862098\n",
      "-----Epoch:  9530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1370828699584093\n",
      "-----Epoch:  9540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13705630741054123\n",
      "-----Epoch:  9550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13702977463488195\n",
      "-----Epoch:  9560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13700327155160055\n",
      "-----Epoch:  9570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13697679808116928\n",
      "-----Epoch:  9580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1369503541443616\n",
      "-----Epoch:  9590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1369239396622509\n",
      "-----Epoch:  9600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13689755455620922\n",
      "-----Epoch:  9610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13687119874790557\n",
      "-----Epoch:  9620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13684487215930427\n",
      "-----Epoch:  9630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13681857471266431\n",
      "-----Epoch:  9640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1367923063305372\n",
      "-----Epoch:  9650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13676606693576593\n",
      "-----Epoch:  9660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13673985645148312\n",
      "-----Epoch:  9670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13671367480111066\n",
      "-----Epoch:  9680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13668752190835687\n",
      "-----Epoch:  9690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13666139769721639\n",
      "-----Epoch:  9700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13663530209196825\n",
      "-----Epoch:  9710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13660923501717448\n",
      "-----Epoch:  9720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13658319639767888\n",
      "-----Epoch:  9730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13655718615860563\n",
      "-----Epoch:  9740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13653120422535833\n",
      "-----Epoch:  9750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13650525052361792\n",
      "-----Epoch:  9760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1364793249793418\n",
      "-----Epoch:  9770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1364534275187628\n",
      "-----Epoch:  9780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1364275580683874\n",
      "-----Epoch:  9790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1364017165549946\n",
      "-----Epoch:  9800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13637590290563448\n",
      "-----Epoch:  9810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13635011704762748\n",
      "-----Epoch:  9820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13632435890856226\n",
      "-----Epoch:  9830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13629862841629525\n",
      "-----Epoch:  9840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1362729254989489\n",
      "-----Epoch:  9850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1362472500849105\n",
      "-----Epoch:  9860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13622160210283127\n",
      "-----Epoch:  9870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13619598148162457\n",
      "-----Epoch:  9880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13617038815046495\n",
      "-----Epoch:  9890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.136144822038787\n",
      "-----Epoch:  9900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13611928307628438\n",
      "-----Epoch:  9910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1360937711929077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  9920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13606828631886433\n",
      "-----Epoch:  9930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13604282838461676\n",
      "-----Epoch:  9940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13601739732088122\n",
      "-----Epoch:  9950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13599199305862691\n",
      "-----Epoch:  9960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13596661552907446\n",
      "-----Epoch:  9970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13594126466369513\n",
      "-----Epoch:  9980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13591594039420946\n",
      "-----Epoch:  9990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13589064265258563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa611208b20>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TRAINING ON FLOWER PROBLEM (petal length and age --> color)\n",
    "\n",
    "X_train = np.array([[3, 2, 4, 3, 3.5, 2, 5.5, 1],\n",
    "                    [1.5, 1, 1.5, 1, 0.5, 0.5, 1, 1]])\n",
    "y_train = np.array([1, 0, 1, 0, 1, 0, 1, 0])\n",
    "\n",
    "Flower_net = NeuralNet('binary_logloss')\n",
    "Flower_net.addLayer(1, 'sigmoid')\n",
    "costs, weights = Flower_net.fit(X_train, y_train, 10000)\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing Flower problem\n",
    "\n",
    "def vis_data():\n",
    "    plt.axis([0, 6, 0 ,3])\n",
    "    plt.grid()\n",
    "    for i in range(X_train.shape[1]):\n",
    "        point  = X_train[:, i]\n",
    "        color = 'r'\n",
    "        if y_train[i] == 0:\n",
    "            color = 'b'\n",
    "        plt.scatter(point[0], point[1], c=color)\n",
    "    \n",
    "# check out the networks predictions in the x,y plane\n",
    "for x in np.linspace(0, 6, 30):\n",
    "    for y in np.linspace(0, 3, 30):\n",
    "        test = np.array([[x],[y]])\n",
    "        pred = Flower_net.predict(test)\n",
    "        c = 'b'\n",
    "        if pred > .5:\n",
    "            c = 'r'\n",
    "        plt.scatter([x],[y],c=c, alpha=.2)\n",
    "\n",
    "vis_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING ON MNIST\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation].astype(np.int)\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=60000, test_size=10000)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).T\n",
    "X_test = scaler.transform(X_test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = NeuralNet('multi_logloss')\n",
    "mnist_net.addLayer(64, 'reLu')\n",
    "mnist_net.addLayer(10, 'softmax')\n",
    "costs, weights = mnist_net.fit(X_train, y_train, 2000, 60000)\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mnist_net.predict(X_test)\n",
    "test_accuracy = 100*np.sum(y_test == np.argmax(y_pred, 0), axis=0) / X_test.shape[1]\n",
    "print(\"Test Accuracy on MNIST: \" + test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
