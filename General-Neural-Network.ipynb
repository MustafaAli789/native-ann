{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipdb\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    #Activation Functions\n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "    def d_tanh(self, x):\n",
    "        return 1 - np.square(np.tanh(x))\n",
    "    def sigmoid(self, x):\n",
    "#         return 1/(1+ np.exp(-x))\n",
    "        return expit(x)\n",
    "    def d_sigmoid(self, x):\n",
    "        return (1 - self.sigmoid(x)) * self.sigmoid(x)\n",
    "    def ReLu(self, z):\n",
    "        return np.maximum(0, z)\n",
    "    def d_ReLu(self, Z):\n",
    "        return Z > 0\n",
    "    \n",
    "    #For output layer, useful for multiclass classification\n",
    "    def softmax(self, Z):\n",
    "#         expZ = np.exp(Z - np.max(Z))\n",
    "#         return expZ / expZ.sum(axis=0, keepdims=True)\n",
    "         return np.exp(Z) / sum(np.exp(Z))\n",
    "    def d_softmax(self, Z):\n",
    "        pass\n",
    "    \n",
    "    activationFunctions = {\n",
    "        'tanh': (tanh, d_tanh),\n",
    "        'sigmoid': (sigmoid, d_sigmoid),\n",
    "        'reLu': (ReLu, d_ReLu),\n",
    "        'softmax': (softmax, d_softmax)\n",
    "    }\n",
    "    \n",
    "    #Input -> num of neurons in prev layer, Neurons --> num neurons in cur layer, Activation -> activation fxn to use\n",
    "    def __init__(self, inputs, neurons, activation):\n",
    "        self.neurons = neurons\n",
    "        self.W = np.random.rand(neurons, inputs) - 0.5\n",
    "        self.b = np.random.rand(neurons, 1) - 0.5\n",
    "        self.Z = None\n",
    "        self.A_prev = None\n",
    "        self.act, self.d_act = self.activationFunctions.get(activation)\n",
    "        \n",
    "    def initializeWeights(self, inputs, neurons):\n",
    "        self.W = np.random.randn(neurons, inputs)\n",
    "        \n",
    "    def getNeuronCount(self):\n",
    "        return self.neurons\n",
    "    \n",
    "    def feedForward(self, A_prev):\n",
    "        ipdb.set_trace()\n",
    "        self.A_prev = A_prev\n",
    "        self.Z = self.W.dot(self.A_prev) + self.b\n",
    "        self.A = self.act(self, self.Z)\n",
    "        return self.A\n",
    "    \n",
    "    #All derivatives are wrt to cost\n",
    "    #Expects dA of cur layer\n",
    "    #Special case where doing multi class classification with mutli class logloss, you can get the dZ wrt dC directly without having to first get dA\n",
    "    def backprop(self, dA, learning_rate, dZ_Special):\n",
    "        \n",
    "        ipdb.set_trace()\n",
    "        \n",
    "        #elementt by element matrix multip, not a normal dot prod since both matrices have same shape (essentialyl scalar)\n",
    "        dZ = np.multiply(self.d_act(self, self.Z), dA) if dZ_Special.any() == None else dZ_Special\n",
    "        \n",
    "         # need to normalize weights and divide by number of samples\n",
    "        # because it is actually a sum of weights\n",
    "        dW = 1/dZ.shape[1] * np.dot(dZ, self.A_prev.T)\n",
    "        \n",
    "        # this is to match shape since biases is supposed to be a col vector with 1 col but dZ has m cols\n",
    "        # w/ m being num of samples, we want to take avg of all samples in dZ (i.e on a row by row basis, sum of cols\n",
    "        # and divide by total num of smamples)\n",
    "        db = 1 / dZ.shape[1] * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        \n",
    "        dA_prev = np.dot(self.W.T, dZ)\n",
    "        \n",
    "        self.W = self.W - learning_rate * dW\n",
    "        self.b = self.b - learning_rate * db\n",
    "        return dA_prev\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    \n",
    "    #Loss Functions, mse for regression, logloss for classification\n",
    "    def mse(self, a, target):\n",
    "        return np.square(a-target)\n",
    "    \n",
    "    def d_mse(self, a, target):\n",
    "        return 2*(a-target)\n",
    "    \n",
    "    def binary_logloss(self, a, target):\n",
    "        return -(target*np.log(a) + (1-target)*np.log(1-a))\n",
    "    \n",
    "    def d_binary_logloss(self, a, target):\n",
    "        return (a - target)/(a*(1 - a))\n",
    "    \n",
    "    def multi_logloss(self, a, target, eps=1e-15):\n",
    "        predictions = np.clip(a, eps, 1 - eps)\n",
    "\n",
    "        # normalize row sums to 1\n",
    "        predictions /= predictions.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        return -np.sum(target * np.log(predictions))/predictions.shape[0]\n",
    "    \n",
    "    def d_multi_logloss(self, a, target):\n",
    "        return np.zeros(a.shape) # kinda just a placeholder\n",
    "    \n",
    "    lossFunctions = {\n",
    "        'mse': (mse, d_mse),\n",
    "        'binary_logloss': (binary_logloss, d_binary_logloss),\n",
    "        'multi_logloss': (multi_logloss, d_multi_logloss)\n",
    "    }\n",
    "        \n",
    "    #LossFunction is either mse of logloss\n",
    "    def __init__(self, lossFunction):\n",
    "        self.layers = []\n",
    "        self.learning_rate = 0.1\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 10\n",
    "        self.classification = False if lossFunction == 'mse' else True\n",
    "        self.lossFunction = lossFunction\n",
    "        self.loss, self.d_loss = self.lossFunctions.get(lossFunction)\n",
    "    \n",
    "    #Units is 1-n and activationFunction is 'ReLu', 'sigmoid', 'tanh', or 'softmax'\n",
    "    def addLayer(self, units, activationFunction):\n",
    "        prevLayerNeuronCount = self.layers[-1].getNeuronCount() if len(self.layers) > 0 else 0\n",
    "        self.layers.append(Layer(prevLayerNeuronCount, units, activationFunction))\n",
    "        \n",
    "    def getNumBatches(self, num_samples, batch_size):\n",
    "        if (num_samples == batch_size):\n",
    "            return 1\n",
    "        elif (num_samples > batch_size):\n",
    "            if (num_samples % batch_size == 0):\n",
    "                return num_samples // batch_size\n",
    "            else:\n",
    "                return (num_samples // batch_size) + 1\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    def oneHot(self, x):\n",
    "        one_hot_X = np.zeros((x.max() + 1, x.size)) #making a matrix of 10 x m\n",
    "        one_hot_X[x, np.arange(x.size)] = 1 #going through all cols and setting the row w/ index corresponding to the y to 1, its very easy to iterate over numpy arays like this apparently\n",
    "        return one_hot_X\n",
    "    \n",
    "    def fit(self, X, y, epochs = None, batch_size = None, learning_rate = None):\n",
    "        self.learning_rate = learning_rate if learning_rate != None else self.learning_rate\n",
    "        self.epochs = epochs if epochs != None else self.epochs\n",
    "        self.batch_size = batch_size if batch_size != None else self.batch_size\n",
    "        \n",
    "        #need at min one layer\n",
    "        if (len(self.layers) == 0):\n",
    "            raise ValueError('No layers have been added. Need at least one layer. Please add a layer') \n",
    "        \n",
    "        #multi class classificaiton problem need y to be one hot encoded and must use multi log loss\n",
    "        multiClassProblem = self.classification and (y.max() - y.min() > 1)\n",
    "        if (multiClassProblem):\n",
    "            y = self.oneHot(y)\n",
    "            if (self.lossFunction != 'multi_logloss'):\n",
    "                raise ValueError('Loss Function Must be multi_logloss for multi class classification')\n",
    "        \n",
    "        epoch_costs = []\n",
    "        batches_cost_sum = 0\n",
    "        num_batches = self.getNumBatches(X.shape[1], self.batch_size)\n",
    "        \n",
    "        #Initializing weights of the first layer \n",
    "        #need to do it right now because shape of input isnt known until now\n",
    "        self.layers[0].initializeWeights(X.shape[0], self.layers[0].getNeuronCount())\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            batches_cost_sum = 0\n",
    "            for batch in range(num_batches):\n",
    "                #ipdb.set_trace()\n",
    "                A = X[:, batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "                \n",
    "                if (multiClassProblem): \n",
    "                    y_curBatch = y[:, batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "                else:\n",
    "                    y_CurBatch = y[batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "            \n",
    "                ipdb.set_trace()\n",
    "                for layer in self.layers:\n",
    "                    A = layer.feedForward(A)\n",
    "                batches_cost_sum += 1/self.batch_size * np.sum(self.loss(self, A, y_curBatch))\n",
    "                dZ_Special = A - y_curBatch if multiClassProblem else np.array([None])\n",
    "                dA = self.d_loss(self, A, y_curBatch) # after the final output layer dA is found like this since A is just the output\n",
    "                for layer in reversed(self.layers):\n",
    "                    if (layer == self.layers[-1]):\n",
    "                        dA = layer.backprop(dA, self.learning_rate, dZ_Special)\n",
    "                    else:\n",
    "                        dA = layer.backprop(dA, self.learning_rate, np.array([None]))\n",
    "            epoch_costs.append(batches_cost_sum) \n",
    "            print(\"Epoch: \", epoch, \"Cost:\", batches_cost_sum)\n",
    "        return epoch_costs\n",
    "        \n",
    "    def predict(self, X):\n",
    "        #ipdb.set_trace()\n",
    "        A = X\n",
    "        for layer in self.layers:\n",
    "            A = layer.feedForward(A)\n",
    "        return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = np.array([[0, 0, 1, 1], \n",
    "#                     [0, 1, 0, 1]]) # 2 inputs and 4 samples, i.e 2x4\n",
    "# y_train = np.array([0, 1, 1, 0]) #1 x num of samples\n",
    "# net = NeuralNet('logloss')\n",
    "# net.addLayer(3, 'tanh')\n",
    "# net.addLayer(1, 'sigmoid')\n",
    "# costs = net.fit(x_train, y_train, 10000)\n",
    "# plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = np.array([[1], [1]])\n",
    "# a = net.predict(test)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 1 ... 7 1 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation].astype(np.int)\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "print(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=60000, test_size=10000)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).T\n",
    "X_test = scaler.transform(X_test).T\n",
    "\n",
    "# X_train = X_train.T\n",
    "# X_test = X_test.T\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(X_test[:, 50].reshape(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -4.41807799e-03, -5.75481961e-03, -4.08251693e-03, -4.08251693e-03,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -4.08251693e-03, -6.22758214e-03, -9.25077752e-03, -1.21835863e-02,\n",
       "       -1.53249132e-02, -1.99029541e-02, -2.51311477e-02, -3.01796547e-02,\n",
       "       -3.30781150e-02, -3.29569552e-02, -3.30971892e-02, -3.06662937e-02,\n",
       "       -3.04491119e-02, -2.75168402e-02, -2.25822735e-02, -1.78517586e-02,\n",
       "       -1.54166835e-02, -1.09624331e-02, -8.32486080e-03, -4.38069356e-03,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -4.08251693e-03, -5.39534598e-03,\n",
       "       -8.52241235e-03, -1.15910450e-02, -1.84399525e-02, -2.84881002e-02,\n",
       "       -3.85936153e-02, -5.35136705e-02, -6.90627543e-02, -8.59976726e-02,\n",
       "       -1.01836566e-01, -1.17546324e-01, -1.30635125e-01, -1.39051695e-01,\n",
       "       -1.38312843e-01, -1.29767590e-01, -1.18779326e-01, -1.00683526e-01,\n",
       "       -7.78541137e-02, -5.51732353e-02, -3.83107560e-02, -2.37509873e-02,\n",
       "       -1.30407876e-02, -6.74089541e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -5.36837753e-03, -7.89513743e-03,\n",
       "       -1.42086587e-02, -2.26742507e-02, -3.56187114e-02, -5.63227738e-02,\n",
       "       -8.08930118e-02, -1.09330876e-01, -1.38841137e-01, -1.69529899e-01,\n",
       "       -1.98992626e-01, -2.27273092e-01, -2.50256628e-01, -2.62379344e-01,\n",
       "       -2.61249893e-01, -2.45106910e-01, -2.19628653e-01, -1.84610992e-01,\n",
       "       -1.45562637e-01, -1.06361992e-01, -7.59408764e-02, -4.72937635e-02,\n",
       "       -2.92232612e-02, -1.49799294e-02, -6.48517340e-03,  0.00000000e+00,\n",
       "        0.00000000e+00, -4.08251693e-03, -7.76342302e-03, -1.54432365e-02,\n",
       "       -2.45586261e-02, -4.92365879e-02, -7.93565517e-02, -1.17928701e-01,\n",
       "       -1.62612873e-01, -2.14953982e-01, -2.69938024e-01, -3.29468699e-01,\n",
       "       -2.22982433e-01, -2.27352414e-01,  1.35859739e-01,  1.54600304e+00,\n",
       "        2.44640582e+00,  2.65149469e+00,  3.04684156e+00,  3.63791370e+00,\n",
       "        2.97926938e+00,  2.26130502e+00, -5.19770041e-02, -1.08315793e-01,\n",
       "       -7.05830334e-02, -3.78516401e-02, -1.51080131e-02, -5.77049806e-03,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.12115669e-02, -2.07308063e-02,\n",
       "       -5.27097043e-02, -9.12453230e-02, -1.40480877e-01, -1.97440231e-01,\n",
       "       -2.65012519e-01, -3.42914503e-01, -4.13224635e-01,  2.36193097e-02,\n",
       "        1.63823080e+00,  1.72675961e+00,  1.55958480e+00,  1.49243502e+00,\n",
       "        1.51891055e+00,  1.64357873e+00,  1.89628441e+00,  2.28052532e+00,\n",
       "        2.84949071e+00,  3.74851357e+00,  4.79712691e-01, -1.89038435e-01,\n",
       "       -1.30334689e-01, -7.40266870e-02, -3.25702050e-02, -8.20891834e-03,\n",
       "        0.00000000e+00, -5.57015293e-03, -1.43295823e-02, -3.58731494e-02,\n",
       "       -8.02280286e-02, -1.33697868e-01, -1.98419807e-01, -2.75077870e-01,\n",
       "       -3.64734877e-01, -1.82055196e-01,  1.23037650e+00,  1.77984923e+00,\n",
       "        1.50807790e+00,  1.31292058e+00,  1.19410458e+00,  1.14428064e+00,\n",
       "        9.65032708e-01, -2.39898916e-01, -1.26078744e-01,  9.07934911e-01,\n",
       "        2.13829518e+00,  2.79177340e+00,  6.34886226e-01, -2.46849340e-01,\n",
       "       -1.71971076e-01, -1.02699709e-01, -4.80731759e-02, -1.65012400e-02,\n",
       "       -4.08251693e-03, -1.36138235e-02, -2.56099805e-02, -5.87218238e-02,\n",
       "       -1.13264489e-01, -1.78151779e-01, -2.57389600e-01, -3.50896313e-01,\n",
       "       -4.61001460e-01,  5.67544260e-01,  1.74774269e+00,  1.46560235e+00,\n",
       "        1.27513751e+00,  1.15288127e+00,  1.08403264e+00,  5.23232049e-01,\n",
       "       -7.81095934e-01, -1.14263561e+00, -1.02194454e+00,  3.89374201e-01,\n",
       "        1.81526488e+00,  2.35083135e+00,  2.84459451e+00, -3.67879293e-02,\n",
       "       -1.95862776e-01, -1.21066999e-01, -5.73814842e-02, -1.65011812e-02,\n",
       "       -4.08251693e-03, -1.77725461e-02, -4.25903581e-02, -8.45483059e-02,\n",
       "       -1.39840901e-01, -2.10456967e-01, -2.98941157e-01, -4.06334283e-01,\n",
       "       -5.35692497e-01, -4.87638789e-01,  6.45133270e-01,  1.22300572e+00,\n",
       "        3.96137476e-01,  1.20850552e-01, -6.83832018e-01, -1.03134049e+00,\n",
       "       -1.10751643e+00, -1.10213693e+00, -1.04574784e+00,  5.93016905e-01,\n",
       "        1.68374950e+00,  2.16975016e+00,  1.31163460e+00, -2.21231791e-01,\n",
       "       -1.95932295e-01, -1.20663590e-01, -5.62825413e-02, -1.49826201e-02,\n",
       "       -7.47297720e-03, -2.20057229e-02, -5.22862630e-02, -9.29880082e-02,\n",
       "       -1.50257985e-01, -2.25715481e-01, -3.22097970e-01, -4.41575297e-01,\n",
       "       -5.88273226e-01, -7.57324106e-01, -9.03002062e-01, -7.65254384e-01,\n",
       "       -9.95287990e-01, -9.46421222e-01, -9.07732371e-01, -9.14050764e-01,\n",
       "       -9.55077722e-01, -9.62268871e-01,  5.78647671e-01,  1.30844690e+00,\n",
       "        1.68888795e+00,  2.16910848e+00,  5.33401533e-02, -2.87010557e-01,\n",
       "       -1.80539810e-01, -1.04582887e-01, -4.86277586e-02, -1.60567320e-02,\n",
       "       -7.60752974e-03, -2.34110034e-02, -5.26109859e-02, -9.21632027e-02,\n",
       "       -1.47325493e-01, -2.25556802e-01, -3.30894919e-01, -4.62799908e-01,\n",
       "       -6.24044689e-01, -7.94455494e-01, -9.17190685e-01, -9.34405529e-01,\n",
       "       -8.65955308e-01, -7.93993757e-01, -7.71099856e-01, -8.03799815e-01,\n",
       "       -8.47370879e-01, -2.93179724e-01,  1.32197543e+00,  1.45474347e+00,\n",
       "        1.76198194e+00,  7.47535237e-01, -3.66857115e-01, -2.69828192e-01,\n",
       "       -1.59705533e-01, -8.09547504e-02, -3.86506738e-02, -1.41911091e-02,\n",
       "       -7.67874408e-03, -2.11634182e-02, -4.69024906e-02, -8.11960475e-02,\n",
       "       -1.36308928e-01, -2.23940848e-01, -3.37760038e-01, -4.85033310e-01,\n",
       "       -6.54849088e-01, -8.19627284e-01, -9.04127060e-01, -8.72198563e-01,\n",
       "       -7.80545201e-01, -7.30101763e-01, -6.62580395e-01, -5.78691872e-01,\n",
       "        7.70467726e-01,  1.31705697e+00,  1.33223447e+00,  1.48221182e+00,\n",
       "        5.17612164e-01, -4.98141586e-01, -3.69153275e-01, -2.57958766e-01,\n",
       "       -1.49776733e-01, -6.23958147e-02, -2.97200560e-02, -1.03202284e-02,\n",
       "       -5.30435130e-03, -1.66198616e-02, -3.61327783e-02, -6.85610288e-02,\n",
       "       -1.26871148e-01, -2.25612261e-01, -3.52368855e-01, -5.11054177e-01,\n",
       "       -6.86030244e-01, -8.35120837e-01, -8.83601556e-01, -4.52201100e-01,\n",
       "       -3.59821763e-01,  4.45481525e-01,  9.05846262e-01,  1.35958856e+00,\n",
       "        1.26952531e+00,  1.21461029e+00,  1.09066954e+00,  3.16086124e-01,\n",
       "       -6.15953956e-01, -4.70310994e-01, -3.56185263e-01, -2.56455127e-01,\n",
       "       -1.53967212e-01, -5.48843368e-02, -2.18341781e-02, -9.04411723e-03,\n",
       "       -4.08251693e-03, -1.11309596e-02, -2.53173907e-02, -5.60099176e-02,\n",
       "       -1.22990657e-01, -2.37356710e-01, -3.73433158e-01, -5.35642644e-01,\n",
       "       -7.06352730e-01, -1.56394509e-01,  7.44002430e-01,  1.49563422e+00,\n",
       "        1.56577128e+00,  1.43770558e+00,  1.24314620e+00,  1.15047115e+00,\n",
       "        1.11601192e+00,  1.07817253e+00, -4.65999465e-01, -7.74258099e-01,\n",
       "       -5.94658713e-01, -4.62128053e-01, -3.57276889e-01, -2.65316900e-01,\n",
       "       -1.64553670e-01, -5.96063333e-02, -2.26136286e-02, -6.21315822e-03,\n",
       "       -4.08251693e-03, -6.94445874e-03, -1.77191491e-02, -4.94993249e-02,\n",
       "       -1.28408617e-01, -2.56399988e-01, -3.94446018e-01, -5.51390527e-01,\n",
       "       -7.09886727e-01,  9.82583966e-01,  1.44156778e+00,  1.47525966e+00,\n",
       "        1.43877670e+00,  1.23165478e+00,  5.58249801e-01,  3.29617454e-01,\n",
       "        9.86961378e-01,  1.10749655e+00,  8.88991929e-01, -5.02123663e-01,\n",
       "       -5.96789229e-01, -4.73420060e-01, -3.69429786e-01, -2.74388108e-01,\n",
       "       -1.73340158e-01, -6.93012760e-02, -2.47298249e-02, -5.72279641e-03,\n",
       "       -4.77028006e-03, -4.08251693e-03, -1.81481992e-02, -5.15972725e-02,\n",
       "       -1.40183963e-01, -2.76608083e-01, -4.10992905e-01, -5.54189708e-01,\n",
       "       -6.92258120e-01,  3.45975885e-03,  1.45364096e+00,  9.76655026e-01,\n",
       "        3.08379573e-01, -7.32109197e-01, -1.11654818e+00, -1.27606676e+00,\n",
       "       -1.10581202e-02,  1.16350571e+00,  1.37832677e+00,  5.14188208e-01,\n",
       "       -6.10711065e-01, -4.88774847e-01, -3.81712706e-01, -2.78699551e-01,\n",
       "       -1.75155284e-01, -7.74366933e-02, -2.84628140e-02, -7.25837805e-03,\n",
       "       -4.08251693e-03, -6.45494116e-03, -2.20776250e-02, -5.94243192e-02,\n",
       "       -1.57059609e-01, -2.96298707e-01, -4.20499069e-01, -5.45359196e-01,\n",
       "       -6.58498331e-01, -7.38724304e-01, -5.78268702e-01, -7.39061368e-01,\n",
       "       -9.19841367e-01, -1.02832539e+00, -1.12391807e+00, -1.14764804e+00,\n",
       "       -9.83838543e-01,  1.23187008e+00,  1.44730765e+00,  1.22838347e+00,\n",
       "       -6.18856035e-01, -4.95759898e-01, -3.80766244e-01, -2.73361437e-01,\n",
       "       -1.72509838e-01, -8.31932434e-02, -3.35943836e-02, -9.16125527e-03,\n",
       "        0.00000000e+00, -6.70743628e-03, -2.50206232e-02, -7.19836336e-02,\n",
       "       -1.76442476e-01,  9.53807174e-02,  9.32628214e-01, -4.02015682e-01,\n",
       "       -5.91400317e-01, -6.83574485e-01, -7.23843676e-01, -7.65769545e-01,\n",
       "       -8.26449707e-01, -9.20112528e-01, -1.00588669e+00, -1.03461244e+00,\n",
       "       -1.01550533e+00,  7.94732460e-01,  1.46869005e+00,  1.21882633e+00,\n",
       "       -6.17549020e-01, -4.87646381e-01, -3.69002889e-01, -2.60965921e-01,\n",
       "       -1.66509416e-01, -8.69667709e-02, -3.43904653e-02, -1.12061039e-02,\n",
       "       -5.90596678e-03, -7.42766564e-03, -3.29908971e-02, -8.91072946e-02,\n",
       "       -1.96826436e-01,  2.15743395e+00,  2.74479278e+00,  2.26621366e+00,\n",
       "       -1.20817104e-01, -6.60852760e-01, -6.99963665e-01, -7.32888508e-01,\n",
       "       -7.81790435e-01, -8.71415310e-01, -9.58444649e-01, -1.01557471e+00,\n",
       "       -4.20055582e-01,  1.31241689e+00,  1.44769379e+00,  1.21872499e+00,\n",
       "       -5.99193206e-01, -4.65240536e-01, -3.49023398e-01, -2.45264832e-01,\n",
       "       -1.56309528e-01, -8.41606080e-02, -3.07841487e-02, -9.72754809e-03,\n",
       "       -4.08251693e-03, -8.89953171e-03, -3.85717502e-02, -1.02135815e-01,\n",
       "       -2.09610852e-01,  2.06882518e+00,  2.65429792e+00,  2.04335344e+00,\n",
       "       -2.49183436e-01, -6.96379858e-01, -7.42285124e-01, -7.75646147e-01,\n",
       "       -8.30685840e-01, -9.19682828e-01, -1.00993323e+00, -9.03951958e-01,\n",
       "        6.95025935e-01,  1.29894900e+00,  1.45868633e+00,  5.34527102e-01,\n",
       "       -5.59120378e-01, -4.28323068e-01, -3.16432528e-01, -2.19793736e-01,\n",
       "       -1.39690528e-01, -7.62337439e-02, -2.79613175e-02, -7.31750291e-03,\n",
       "        0.00000000e+00, -8.25395847e-03, -4.20415369e-02, -1.07797820e-01,\n",
       "        1.15732627e-01,  3.29702741e+00,  2.65401919e+00,  1.54720987e+00,\n",
       "       -5.55550260e-01, -7.61821174e-01, -8.32200604e-01, -8.90231095e-01,\n",
       "       -9.61679881e-01, -1.05268118e+00, -9.45700794e-01,  5.79481203e-01,\n",
       "        1.20077641e+00,  1.33725252e+00,  1.08689207e+00, -3.76094545e-01,\n",
       "       -4.89440470e-01, -3.68860477e-01, -2.68572867e-01, -1.85868861e-01,\n",
       "       -1.20585945e-01, -6.50096078e-02, -2.60637053e-02, -5.77331594e-03,\n",
       "        0.00000000e+00, -8.58080270e-03, -4.02409358e-02, -9.84497320e-02,\n",
       "        1.57414046e-01,  3.64946738e+00,  2.88472068e+00,  2.17637462e+00,\n",
       "        1.36388233e+00,  1.04466443e+00,  8.94973765e-01,  2.96668903e-01,\n",
       "        7.03438353e-01,  6.35316136e-01,  7.61088192e-01,  1.14342389e+00,\n",
       "        1.28204377e+00,  1.42668703e+00, -4.50810112e-01, -5.23908552e-01,\n",
       "       -3.98220895e-01, -2.94320504e-01, -2.11159609e-01, -1.46289309e-01,\n",
       "       -9.65229545e-02, -4.96987986e-02, -1.97507118e-02, -4.08251693e-03,\n",
       "        0.00000000e+00, -4.75457709e-03, -3.28054204e-02, -7.77453432e-02,\n",
       "       -1.46042778e-01,  2.20612815e+00,  3.56587247e+00,  2.55789270e+00,\n",
       "        1.96784793e+00,  1.60770965e+00,  1.37732261e+00,  1.23872509e+00,\n",
       "        1.15954174e+00,  1.13283348e+00,  1.17006301e+00,  1.29919138e+00,\n",
       "        1.12065628e+00,  2.47491502e-01, -5.25052212e-01, -4.02269551e-01,\n",
       "       -3.01339217e-01, -2.19162168e-01, -1.57139577e-01, -1.07594596e-01,\n",
       "       -6.96027191e-02, -3.62577757e-02, -1.18938094e-02, -4.08251693e-03,\n",
       "        0.00000000e+00,  0.00000000e+00, -2.20787609e-02, -5.11698529e-02,\n",
       "       -9.86021166e-02, -6.44263571e-02,  6.61879683e-01,  1.73495289e+00,\n",
       "        1.15942309e+00,  1.37387914e+00,  1.11025980e+00,  1.47933057e+00,\n",
       "        1.38660700e+00,  1.39204958e+00,  6.55888491e-01,  1.42717213e-01,\n",
       "       -5.10156878e-01, -4.93674121e-01, -3.81663800e-01, -2.88613283e-01,\n",
       "       -2.12933491e-01, -1.52390273e-01, -1.08722322e-01, -7.40493469e-02,\n",
       "       -4.30847232e-02, -2.08162693e-02, -9.59008913e-03,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.03418503e-02, -2.73742245e-02,\n",
       "       -5.69807217e-02, -9.39324590e-02, -1.51678654e-01, -2.21315300e-01,\n",
       "       -3.02316934e-01, -3.86568402e-01, -4.66732540e-01, -5.29795982e-01,\n",
       "       -5.64362898e-01, -5.62909503e-01, -5.29364030e-01, -4.71347831e-01,\n",
       "       -3.99717341e-01, -3.26588296e-01, -2.56353484e-01, -1.94113239e-01,\n",
       "       -1.44592724e-01, -9.99744113e-02, -7.07236692e-02, -4.70402864e-02,\n",
       "       -2.54629610e-02, -1.10841656e-02, -4.75287492e-03,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -6.66430111e-03, -1.04511297e-02,\n",
       "       -2.70527598e-02, -5.11124496e-02, -8.58974898e-02, -1.27538358e-01,\n",
       "       -1.74827545e-01, -2.21408956e-01, -2.63603623e-01, -2.92923806e-01,\n",
       "       -3.07547104e-01, -3.06628998e-01, -2.91446976e-01, -2.66081276e-01,\n",
       "       -2.35948607e-01, -2.01823778e-01, -1.63486210e-01, -1.27059048e-01,\n",
       "       -9.39941004e-02, -6.45519155e-02, -4.54819899e-02, -2.86212411e-02,\n",
       "       -1.60749137e-02, -6.84103301e-03, -4.08251693e-03,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -4.08251693e-03,\n",
       "       -1.43501210e-02, -3.09013524e-02, -5.30498050e-02, -7.86676963e-02,\n",
       "       -1.07117265e-01, -1.32745656e-01, -1.55427375e-01, -1.73507310e-01,\n",
       "       -1.82486710e-01, -1.80928762e-01, -1.71016991e-01, -1.53612849e-01,\n",
       "       -1.36141596e-01, -1.16943141e-01, -9.36390078e-02, -7.28429697e-02,\n",
       "       -5.29406764e-02, -3.62507756e-02, -2.25559996e-02, -1.32283832e-02,\n",
       "       -6.56230222e-03, -4.08251693e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -5.79016363e-03, -9.05384592e-03, -1.59824845e-02, -2.10995127e-02,\n",
       "       -2.53753360e-02, -3.14303159e-02, -4.30213607e-02, -4.63745995e-02,\n",
       "       -5.20677774e-02, -5.58672833e-02, -6.02065195e-02, -5.64740849e-02,\n",
       "       -5.10505218e-02, -4.22190647e-02, -3.39251729e-02, -2.42440267e-02,\n",
       "       -1.77681806e-02, -1.13708682e-02, -8.57437166e-03, -5.77039393e-03,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-23-de3595b3c639>\u001b[0m(100)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     99 \u001b[0;31m                \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 100 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    101 \u001b[0;31m                    \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> nn\n",
      "*** NameError: name 'nn' is not defined\n",
      "ipdb> \n",
      "*** NameError: name 'nn' is not defined\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-23-de3595b3c639>\u001b[0m(101)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    100 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 101 \u001b[0;31m                    \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m                \u001b[0mbatches_cost_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_curBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(50)\u001b[0;36mfeedForward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     49 \u001b[0;31m        \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 50 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     51 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(51)\u001b[0;36mfeedForward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     50 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 51 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     52 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(52)\u001b[0;36mfeedForward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     51 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 52 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     53 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(53)\u001b[0;36mfeedForward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     52 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 53 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     54 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "--Return--\n",
      "array([[ 0.  ... 0.        ]])\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(53)\u001b[0;36mfeedForward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     52 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 53 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     54 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-23-de3595b3c639>\u001b[0m(100)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     99 \u001b[0;31m                \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 100 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    101 \u001b[0;31m                    \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-23-de3595b3c639>\u001b[0m(101)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    100 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 101 \u001b[0;31m                    \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m                \u001b[0mbatches_cost_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_curBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(50)\u001b[0;36mfeedForward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     49 \u001b[0;31m        \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 50 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     51 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(51)\u001b[0;36mfeedForward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     50 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 51 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     52 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(52)\u001b[0;36mfeedForward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     51 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 52 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     53 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-d37b39fd691b>:22: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(Z) / sum(np.exp(Z))\n",
      "<ipython-input-22-d37b39fd691b>:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(Z) / sum(np.exp(Z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(53)\u001b[0;36mfeedForward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     52 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 53 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     54 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "--Return--\n",
      "array([[1.409...5618645e-24]])\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(53)\u001b[0;36mfeedForward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     52 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 53 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     54 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-23-de3595b3c639>\u001b[0m(100)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     99 \u001b[0;31m                \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 100 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    101 \u001b[0;31m                    \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-23-de3595b3c639>\u001b[0m(102)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    101 \u001b[0;31m                    \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 102 \u001b[0;31m                \u001b[0mbatches_cost_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_curBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    103 \u001b[0;31m                \u001b[0mdZ_Special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_curBatch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmultiClassProblem\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-23-de3595b3c639>\u001b[0m(103)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    102 \u001b[0;31m                \u001b[0mbatches_cost_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_curBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 103 \u001b[0;31m                \u001b[0mdZ_Special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_curBatch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmultiClassProblem\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    104 \u001b[0;31m                \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_curBatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# after the final output layer dA is found like this since A is just the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-23-de3595b3c639>\u001b[0m(104)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    103 \u001b[0;31m                \u001b[0mdZ_Special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_curBatch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmultiClassProblem\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 104 \u001b[0;31m                \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_curBatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# after the final output layer dA is found like this since A is just the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    105 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> dZ_SpecAL\n",
      "*** NameError: name 'dZ_SpecAL' is not defined\n",
      "ipdb> dZ_Special\n",
      "array([[ 1.40984253e-17,  2.96419901e-26,  3.94059706e-22, ...,\n",
      "         3.96229942e-14,  9.23817704e-23, -1.00000000e+00],\n",
      "       [ 5.26821808e-21,  2.02270967e-09,  2.86506831e-08, ...,\n",
      "         9.99350181e-01,  8.11145988e-03,  9.40322275e-36],\n",
      "       [ 3.22984002e-07,  1.21052963e-07,  2.53067693e-18, ...,\n",
      "         1.04026736e-07,  9.90964524e-01,  2.05969360e-24],\n",
      "       ...,\n",
      "       [ 2.80377185e-20, -1.00000000e+00, -1.00000000e+00, ...,\n",
      "         1.32008252e-11,  6.54543092e-10,  1.04019711e-15],\n",
      "       [ 3.94592038e-18,  1.86896969e-30,  6.09650240e-32, ...,\n",
      "         3.27001660e-16,  2.83344328e-23,  1.78252255e-21],\n",
      "       [ 3.86185633e-10,  3.03861201e-05,  9.83591805e-01, ...,\n",
      "         7.43888229e-07,  2.76672894e-36,  2.25618645e-24]])\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-23-de3595b3c639>\u001b[0m(105)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    104 \u001b[0;31m                \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_curBatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# after the final output layer dA is found like this since A is just the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 105 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    106 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-23-de3595b3c639>\u001b[0m(106)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    105 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 106 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    107 \u001b[0;31m                        \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdZ_Special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-23-de3595b3c639>\u001b[0m(107)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    106 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 107 \u001b[0;31m                        \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdZ_Special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    108 \u001b[0;31m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(63)\u001b[0;36mbackprop\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     62 \u001b[0;31m        \u001b[0;31m#elementt by element matrix multip, not a normal dot prod since both matrices have same shape (essentialyl scalar)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 63 \u001b[0;31m        \u001b[0mdZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdZ_Special\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdZ_Special\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(67)\u001b[0;36mbackprop\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     66 \u001b[0;31m        \u001b[0;31m# because it is actually a sum of weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 67 \u001b[0;31m        \u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> dZ == dZ_Special\n",
      "array([[ True,  True,  True, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       ...,\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True]])\n",
      "ipdb> dZ.shape\n",
      "(10, 60000)\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(72)\u001b[0;36mbackprop\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     71 \u001b[0;31m        \u001b[0;31m# and divide by total num of smamples)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 72 \u001b[0;31m        \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     73 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(74)\u001b[0;36mbackprop\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     73 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 74 \u001b[0;31m        \u001b[0mdA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     75 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(76)\u001b[0;36mbackprop\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     75 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 76 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     77 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(77)\u001b[0;36mbackprop\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     76 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 77 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     78 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mdA_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-22-d37b39fd691b>\u001b[0m(78)\u001b[0;36mbackprop\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     77 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 78 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mdA_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     79 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> self.W\n",
      "array([[ 2.88906020e-01,  5.16329901e-02, -3.11968422e-01,\n",
      "         1.81035753e-01,  5.11857451e-01,  3.91143732e-01,\n",
      "         1.81941557e-01, -2.07599711e-01, -4.17999056e-01,\n",
      "         4.03459505e-01, -5.24403964e-02,  2.01979134e-01,\n",
      "        -4.60108725e-01, -2.18222093e-01, -1.08532689e-01,\n",
      "         3.00874919e-01, -2.29885781e-01,  6.10396109e-02,\n",
      "         4.98564017e-02, -1.51243231e-02,  1.13736606e-01,\n",
      "         7.54499898e-02,  2.47085753e-01, -1.22425114e-02,\n",
      "         7.90693112e-02, -1.34005421e-02,  5.91518552e-01,\n",
      "        -3.71937682e-01, -2.66547340e-01, -8.63122410e-02,\n",
      "        -4.24973283e-01, -2.35219248e-01,  5.49487282e-01,\n",
      "        -1.38640068e-01,  6.12707506e-01, -1.35455167e-01,\n",
      "        -3.79172054e-01,  1.20022788e-01, -1.50744001e-01,\n",
      "         5.16861327e-01, -2.94076283e-01, -5.02786061e-02,\n",
      "        -2.02865106e-01, -1.84632154e-02,  4.77240588e-01,\n",
      "         4.62172286e-01,  3.02948069e-02, -3.13730739e-02,\n",
      "        -3.14586229e-01, -2.58836139e-01,  3.30549744e-01,\n",
      "         2.86436584e-02,  3.68066600e-01, -2.57821352e-01,\n",
      "         4.75922585e-01,  2.22997276e-01,  2.33706921e-03,\n",
      "         4.81031093e-01, -1.99305172e-01,  6.80619625e-01,\n",
      "         6.02572115e-01, -6.70275762e-02, -3.67436885e-02,\n",
      "        -1.16605407e-01],\n",
      "       [            nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan],\n",
      "       [            nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan],\n",
      "       [ 3.28723139e-01, -3.76991529e-01,  4.40206709e-01,\n",
      "         1.73161868e-01, -3.27619089e-01, -1.74385163e-01,\n",
      "         3.04878484e-01,  1.34515118e-01,  5.37299696e-02,\n",
      "        -3.67516187e-01, -7.61492312e-02,  5.17269754e-01,\n",
      "         5.28093869e-01, -5.70252703e-02,  2.94172244e-01,\n",
      "        -6.63921536e-02,  9.33968245e-02,  3.65123763e-01,\n",
      "        -1.14469069e-01, -1.53525604e-01, -2.30288010e-01,\n",
      "         4.30722847e-01,  3.13845849e-01,  2.66682110e-01,\n",
      "         2.27381671e-01,  7.67214624e-02,  2.67946675e-01,\n",
      "         3.88522572e-01, -1.14300699e-01,  1.05615150e-01,\n",
      "        -1.49739274e-01,  4.63333634e-01, -4.06081682e-01,\n",
      "        -3.15194645e-01,  4.32473287e-01,  2.88215693e-02,\n",
      "        -1.71326783e-02, -3.04353892e-01, -3.53383279e-01,\n",
      "        -1.07615051e-01,  2.80562011e-01, -1.71803457e-01,\n",
      "        -1.18398279e-01,  3.70422277e-02, -3.67098962e-01,\n",
      "         2.92453810e-03, -1.54881464e-02, -1.81871171e-01,\n",
      "        -3.00298533e-01,  1.34962848e-01, -1.14828741e-01,\n",
      "        -2.63960594e-01,  3.10138366e-01,  7.96099242e-02,\n",
      "        -8.83301922e-03,  2.76375549e-01,  4.06570283e-01,\n",
      "         5.17295052e-01,  4.96753759e-01, -1.99227669e-01,\n",
      "        -2.34070474e-01,  3.87176293e-02,  2.20168040e-01,\n",
      "         1.51151688e-01],\n",
      "       [            nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan],\n",
      "       [            nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan],\n",
      "       [            nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan],\n",
      "       [            nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan,             nan,             nan,\n",
      "                    nan],\n",
      "       [-2.60072905e-01,  1.25221916e-01, -2.31117996e-01,\n",
      "         5.13568713e-01,  9.67250844e-02, -3.87315740e-01,\n",
      "        -2.90896232e-01,  5.25824767e-01, -3.12180087e-01,\n",
      "        -2.90670209e-01, -3.19079267e-04,  1.59992191e-01,\n",
      "         5.53831716e-01,  5.14586122e-02,  3.43751501e-01,\n",
      "         8.95202962e-02, -2.15685488e-01, -2.16452883e-01,\n",
      "         5.79012855e-01, -3.40218175e-01, -1.23348634e-01,\n",
      "        -2.25935614e-01, -7.31774216e-02,  2.79346877e-01,\n",
      "         4.63821310e-01, -1.26210898e-01,  1.01610298e-01,\n",
      "         1.29950192e-02, -4.12113631e-01,  7.82866141e-02,\n",
      "         2.61347009e-01,  4.12474946e-01, -2.41743640e-01,\n",
      "         3.97690589e-01, -3.58828076e-01,  1.29262702e-01,\n",
      "        -1.71056764e-01,  3.13287096e-01, -4.04873467e-01,\n",
      "         5.46643497e-01,  1.98495860e-01,  6.64361346e-02,\n",
      "         4.08850132e-01,  9.82004631e-02, -3.32299532e-01,\n",
      "         4.10217103e-01, -4.11501117e-01, -2.53848722e-01,\n",
      "         1.18091859e-01,  4.14096177e-01, -2.04355146e-01,\n",
      "         3.11331843e-01, -4.00865983e-01, -3.59135740e-02,\n",
      "         4.25791216e-02,  3.31276641e-01, -1.53946091e-01,\n",
      "         2.03086093e-01, -1.49509336e-01, -1.71608332e-01,\n",
      "        -2.49764205e-01,  1.74388743e-02,  3.82853898e-01,\n",
      "        -3.04841246e-01],\n",
      "       [ 2.27095922e-01,  3.16688642e-01,  4.14005763e-01,\n",
      "         3.48417797e-01, -1.24837608e-01, -5.22252854e-02,\n",
      "        -2.99008949e-01,  4.01981447e-01,  3.60046400e-01,\n",
      "        -2.01262726e-01,  2.38963906e-01, -1.53714412e-02,\n",
      "        -2.99207173e-01, -4.14911659e-01, -3.31471788e-01,\n",
      "        -8.14877176e-02,  4.20832513e-01, -2.76060830e-01,\n",
      "         4.53970022e-01, -2.00380910e-01,  2.51767884e-01,\n",
      "         3.09583452e-01,  2.51385176e-01, -4.10950696e-01,\n",
      "         3.87134478e-01, -2.58083048e-01,  3.35089634e-01,\n",
      "        -1.34830674e-01, -1.00163585e-01,  7.84073182e-02,\n",
      "         2.37072654e-01,  4.91381816e-01, -3.58100040e-01,\n",
      "         3.75589599e-01, -3.82951679e-01, -4.21094967e-01,\n",
      "         1.62128456e-01, -1.86058682e-01, -3.13709338e-01,\n",
      "        -4.70377192e-01, -1.78339384e-01, -1.10803095e-02,\n",
      "        -4.64439975e-01, -2.47609419e-01, -4.50791407e-01,\n",
      "        -4.28744951e-01,  3.98059582e-01,  3.96070493e-01,\n",
      "        -4.83693025e-02,  4.05074744e-01, -7.80564160e-02,\n",
      "         2.51245226e-01,  1.98284073e-01, -1.72249995e-01,\n",
      "        -4.48088321e-01, -4.69170851e-01,  3.52023975e-01,\n",
      "         3.91981792e-01,  3.46060338e-01, -4.72237414e-01,\n",
      "        -4.21133101e-01, -3.75636358e-01, -4.43926140e-02,\n",
      "         1.11493174e-01]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> self.W.shape\n",
      "(10, 64)\n"
     ]
    }
   ],
   "source": [
    "mnist_net = NeuralNet('multi_logloss')\n",
    "mnist_net.addLayer(64, 'reLu')\n",
    "mnist_net.addLayer(10, 'softmax')\n",
    "costs = mnist_net.fit(X_train, y_train, 100, 60000)\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e3ba3ae7e706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m array([ 0.        ,  0.        ,  0.        , 12.34557301,  0.        ,\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;36m1.44547623\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.\u001b[0m        \u001b[0;34m,\u001b[0m  \u001b[0;36m0.\u001b[0m        \u001b[0;34m,\u001b[0m  \u001b[0;36m0.\u001b[0m        \u001b[0;34m,\u001b[0m  \u001b[0;36m0.\u001b[0m        \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;36m0.\u001b[0m        \u001b[0;34m,\u001b[0m  \u001b[0;36m0.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m14.42673622\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11.38719467\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.\u001b[0m        \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;36m5.75124653\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m27.30509425\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14.13349396\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16.0829925\u001b[0m \u001b[0;34m,\u001b[0m  \u001b[0;36m0.\u001b[0m        \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;36m0.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m12.09050004\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.24301809\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.\u001b[0m        \u001b[0;34m,\u001b[0m  \u001b[0;36m0.81315813\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'array' is not defined"
     ]
    }
   ],
   "source": [
    "array([ 0.        ,  0.        ,  0.        , 12.34557301,  0.        ,\n",
    "        1.44547623,  0.        ,  0.        ,  0.        ,  0.        ,\n",
    "        0.        ,  0.        , 14.42673622, 11.38719467,  0.        ,\n",
    "        5.75124653, 27.30509425, 14.13349396, 16.0829925 ,  0.        ,\n",
    "        0.        , 12.09050004,  0.24301809,  0.        ,  0.81315813,\n",
    "       36.25892928,  3.02591285,  0.        ,  7.69811406,  0.        ,\n",
    "        0.        ,  0.        , 23.42250571,  6.57030016,  2.73966946,\n",
    "        0.        ,  0.        ,  0.        , 13.62185096,  7.91879562,\n",
    "       22.05083927,  0.        , 29.15894322, 15.4927778 ,  0.        ,\n",
    "        0.        , 16.55078204, 13.3898415 ,  0.        ,  0.        ,\n",
    "        0.        , 19.41925836,  0.        ,  0.        ,  0.        ,\n",
    "       15.12313668,  8.86435797, 14.11965046,  0.        ,  0.        ,\n",
    "        0.        ,  0.37141094,  3.19106955, 27.12674025])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
