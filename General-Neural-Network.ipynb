{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipdb\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    #Activation Functions\n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "    def d_tanh(self, x):\n",
    "        return 1 - np.square(np.tanh(x))\n",
    "    def sigmoid(self, x):\n",
    "#         return 1/(1+ np.exp(-x))\n",
    "        return expit(x)\n",
    "    def d_sigmoid(self, x):\n",
    "        return (1 - self.sigmoid(x)) * self.sigmoid(x)\n",
    "    def ReLu(self, z):\n",
    "        return np.maximum(0, z)\n",
    "    def d_ReLu(self, Z):\n",
    "        return Z > 0\n",
    "    \n",
    "    #For output layer, useful for multiclass classification\n",
    "    def softmax(self, Z):\n",
    "#         expZ = np.exp(Z - np.max(Z))\n",
    "#         return expZ / expZ.sum(axis=0, keepdims=True)\n",
    "         return np.exp(Z) / sum(np.exp(Z))\n",
    "    def d_softmax(self, Z):\n",
    "        pass\n",
    "    \n",
    "    activationFunctions = {\n",
    "        'tanh': (tanh, d_tanh),\n",
    "        'sigmoid': (sigmoid, d_sigmoid),\n",
    "        'reLu': (ReLu, d_ReLu),\n",
    "        'softmax': (softmax, d_softmax)\n",
    "    }\n",
    "    \n",
    "    #Input -> num of neurons in prev layer, Neurons --> num neurons in cur layer, Activation -> activation fxn to use\n",
    "    def __init__(self, inputs, neurons, activation):\n",
    "        self.neurons = neurons\n",
    "        self.W = np.random.rand(neurons, inputs) - 0.5\n",
    "        self.b = np.random.rand(neurons, 1) - 0.5\n",
    "        self.Z = None\n",
    "        self.A_prev = None\n",
    "        self.act, self.d_act = self.activationFunctions.get(activation)\n",
    "        \n",
    "    def initializeWeights(self, inputs, neurons):\n",
    "        self.W = np.random.rand(neurons, inputs) - 0.5\n",
    "        \n",
    "    def getNeuronCount(self):\n",
    "        return self.neurons\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self.W;\n",
    "    \n",
    "    def setWeight(self, weight):\n",
    "        self.W = weight;\n",
    "        \n",
    "    def feedForward(self, A_prev):\n",
    "        #ipdb.set_trace()\n",
    "        self.A_prev = A_prev\n",
    "        self.Z = self.W.dot(self.A_prev) + self.b\n",
    "        self.A = self.act(self, self.Z)\n",
    "        return self.A\n",
    "    \n",
    "    #All derivatives are wrt to cost\n",
    "    #Expects dA of cur layer\n",
    "    #Special case where doing multi class classification with mutli class logloss, you can get the dZ wrt dC directly without having to first get dA\n",
    "    def backprop(self, dA, learning_rate, dZ_Special):\n",
    "        \n",
    "        #ipdb.set_trace()\n",
    "        \n",
    "        #elementt by element matrix multip, not a normal dot prod since both matrices have same shape (essentialyl scalar)\n",
    "        dZ = np.multiply(self.d_act(self, self.Z), dA) if dZ_Special.any() == None else dZ_Special\n",
    "        \n",
    "         # need to normalize weights and divide by number of samples\n",
    "        # because it is actually a sum of weights\n",
    "        dW = 1/dZ.shape[1] * np.dot(dZ, self.A_prev.T)\n",
    "        \n",
    "        # this is to match shape since biases is supposed to be a col vector with 1 col but dZ has m cols\n",
    "        # w/ m being num of samples, we want to take avg of all samples in dZ (i.e on a row by row basis, sum of cols\n",
    "        # and divide by total num of smamples)\n",
    "        db = 1 / dZ.shape[1] * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        \n",
    "        dA_prev = np.dot(self.W.T, dZ)\n",
    "        \n",
    "        self.W = self.W - learning_rate * dW\n",
    "        self.b = self.b - learning_rate * db\n",
    "        return dA_prev\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    \n",
    "    #Loss Functions, mse for regression, logloss for classification\n",
    "    def mse(self, a, target):\n",
    "        return np.square(a-target)\n",
    "    \n",
    "    def d_mse(self, a, target):\n",
    "        return 2*(a-target)\n",
    "    \n",
    "    def binary_logloss(self, a, target):\n",
    "        return -(target*np.log(a) + (1-target)*np.log(1-a))\n",
    "    \n",
    "    def d_binary_logloss(self, a, target):\n",
    "        return (a - target)/(a*(1 - a))\n",
    "    \n",
    "    #Source - https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/discussion/2644\n",
    "    def multi_logloss(self, a, target, eps=1e-15):\n",
    "        predictions = np.clip(a, eps, 1 - eps)\n",
    "\n",
    "        # normalize row sums to 1\n",
    "        predictions /= predictions.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        return -np.sum(target * np.log(predictions))/predictions.shape[0]\n",
    "    \n",
    "    def d_multi_logloss(self, a, target):\n",
    "        return np.zeros(a.shape) # kinda just a placeholder\n",
    "    \n",
    "    lossFunctions = {\n",
    "        'mse': (mse, d_mse),\n",
    "        'binary_logloss': (binary_logloss, d_binary_logloss),\n",
    "        'multi_logloss': (multi_logloss, d_multi_logloss)\n",
    "    }\n",
    "        \n",
    "    #LossFunction is either mse of logloss\n",
    "    def __init__(self, lossFunction):\n",
    "        self.layers = []\n",
    "        self.learning_rate = 0.1\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 10\n",
    "        self.classification = False if lossFunction == 'mse' else True\n",
    "        self.lossFunction = lossFunction\n",
    "        self.loss, self.d_loss = self.lossFunctions.get(lossFunction)\n",
    "    \n",
    "    #Units is 1-n and activationFunction is 'ReLu', 'sigmoid', 'tanh', or 'softmax'\n",
    "    def addLayer(self, units, activationFunction):\n",
    "        prevLayerNeuronCount = self.layers[-1].getNeuronCount() if len(self.layers) > 0 else 0\n",
    "        self.layers.append(Layer(prevLayerNeuronCount, units, activationFunction))\n",
    "        \n",
    "    def getNumBatches(self, num_samples, batch_size):\n",
    "        if (num_samples == batch_size):\n",
    "            return 1\n",
    "        elif (num_samples > batch_size):\n",
    "            if (num_samples % batch_size == 0):\n",
    "                return num_samples // batch_size\n",
    "            else:\n",
    "                return (num_samples // batch_size) + 1\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    def oneHot(self, x):\n",
    "        one_hot_X = np.zeros((x.max() + 1, x.size)) #making a matrix of 10 x m\n",
    "        one_hot_X[x, np.arange(x.size)] = 1 #going through all cols and setting the row w/ index corresponding to the y to 1, its very easy to iterate over numpy arays like this apparently\n",
    "        return one_hot_X\n",
    "    \n",
    "    #Convert one hot encoded 2d array to original array of 1d\n",
    "    def rev_one_hot(self, target):\n",
    "        rev_one_hot = np.argmax(target, 0)\n",
    "        return rev_one_hot\n",
    "    #Compare two 1d arrays\n",
    "    def get_accuracy(self, target, Y, accuracy_buffer):\n",
    "        #ipdb.set_trace()\n",
    "        return np.sum(abs(target-Y)<accuracy_buffer) / Y.size\n",
    "    \n",
    "    def get_layer_weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights.append(layer.getWeights())\n",
    "        return weights\n",
    "\n",
    "    # Pass weights array, num of elemtns in weights array has to match up w/ layers and num of neurons in layers\n",
    "    def set_weights(self, weights):\n",
    "        if (len(weights) != len(self.layers)):\n",
    "            raise ValueError(\"Num of layers and num of weihts must match\")\n",
    "        for count, weight in enumerate(weights):\n",
    "                if (weight.shape[0] != self.layers[count].getNeuronCount()):\n",
    "                    raise ValueError(\"Num of rows in weights at index \" + count + \" does not match num of neurons in layer \" + count)\n",
    "        for count, weight in enumerate(weights):\n",
    "            self.layers[count].setWeight(weight)\n",
    "        \n",
    "    def fit(self, X, y, epochs = None, batch_size = None, learning_rate = None, accuracy_buffer = 0.1):\n",
    "        self.learning_rate = learning_rate if learning_rate != None else self.learning_rate\n",
    "        self.epochs = epochs if epochs != None else self.epochs\n",
    "        self.batch_size = batch_size if batch_size != None else self.batch_size\n",
    "        \n",
    "        #Need at min one layer\n",
    "        if (len(self.layers) == 0):\n",
    "            raise ValueError('No layers have been added. Need at least one layer. Please add a layer') \n",
    "        \n",
    "        #multi class classificaiton problem need y to be one hot encoded and must use multi log loss\n",
    "        multiClassProblem = self.classification and (y.max() - y.min() > 1)\n",
    "        if (multiClassProblem):\n",
    "            y = self.oneHot(y)\n",
    "            if (self.lossFunction != 'multi_logloss'):\n",
    "                raise ValueError('Loss Function Must be multi_logloss for multi class classification')\n",
    "        \n",
    "        epoch_costs = []\n",
    "        batches_cost_sum = 0\n",
    "        num_batches = self.getNumBatches(X.shape[1], self.batch_size)\n",
    "        \n",
    "        #Initializing weights of the first layer \n",
    "        #Need to do it right now because shape of input isnt known until now\n",
    "        self.layers[0].initializeWeights(X.shape[0], self.layers[0].getNeuronCount())\n",
    "        \n",
    "        ###-----Epoch iterations, training occurs here-----###\n",
    "        for epoch in range(self.epochs):\n",
    "            batches_cost_sum = 0\n",
    "            for batch in range(num_batches):\n",
    "                \n",
    "                ###-----Obtaining appropriate batch data-----###\n",
    "                A = X[:, batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "                \n",
    "                if (multiClassProblem): \n",
    "                    y_curBatch = y[:, batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "                else:\n",
    "                    y_curBatch = y[batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "            \n",
    "                ###-----Performing forward prop and backprop-----###\n",
    "                for layer in self.layers:\n",
    "                    A = layer.feedForward(A)\n",
    "                batches_cost_sum += 1/self.batch_size * np.sum(self.loss(self, A, y_curBatch))\n",
    "                \n",
    "                #For multi class classiifcaiton problems (class > 2) and using softmax, deriv of softmax w.r.t to Zfinal is just actual - pred\n",
    "                dZ_Special = A - y_curBatch if multiClassProblem else np.array([None])\n",
    "                \n",
    "                #After the final output layer dA is found like this since A is just the output\n",
    "                dA = self.d_loss(self, A, y_curBatch)\n",
    "                \n",
    "                #Only final layer does the special dZ matter and only if multi class\n",
    "                for layer in reversed(self.layers):\n",
    "                    if (layer == self.layers[-1]):\n",
    "                        dA = layer.backprop(dA, self.learning_rate, dZ_Special)\n",
    "                    else:\n",
    "                        dA = layer.backprop(dA, self.learning_rate, np.array([None]))\n",
    "                \n",
    "                ###-----Logging Metrics-----###\n",
    "                if (epoch % 10 == 0 and batch == 0):\n",
    "                    print(\"-----Epoch: \", epoch, \"-----\")\n",
    "                    if (multiClassProblem):\n",
    "                        A = self.rev_one_hot(A)\n",
    "                        y_curBatch = self.rev_one_hot(y_curBatch)\n",
    "                    print(\"Accuracy:\", self.get_accuracy(A, y_curBatch, accuracy_buffer))\n",
    "                    print(\"Cost:\", batches_cost_sum)\n",
    "            epoch_costs.append(batches_cost_sum) \n",
    "        return epoch_costs, self.get_layer_weights()\n",
    "        \n",
    "    def predict(self, X):\n",
    "        A = X\n",
    "        for layer in self.layers:\n",
    "            A = layer.feedForward(A)\n",
    "        return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  0 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27775313912922256\n",
      "-----Epoch:  10 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2771941378637723\n",
      "-----Epoch:  20 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27677247709562547\n",
      "-----Epoch:  30 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2764155690326839\n",
      "-----Epoch:  40 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2760868926951613\n",
      "-----Epoch:  50 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27576677985726344\n",
      "-----Epoch:  60 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27544340862647626\n",
      "-----Epoch:  70 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2751085449115362\n",
      "-----Epoch:  80 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2747554963250674\n",
      "-----Epoch:  90 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2743780997269874\n",
      "-----Epoch:  100 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2739701934965037\n",
      "-----Epoch:  110 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2735253184722441\n",
      "-----Epoch:  120 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27303652798661543\n",
      "-----Epoch:  130 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27249625121541243\n",
      "-----Epoch:  140 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27189618390563014\n",
      "-----Epoch:  150 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.271227194382396\n",
      "-----Epoch:  160 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.27047923892492465\n",
      "-----Epoch:  170 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2696412831072256\n",
      "-----Epoch:  180 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.26870122653035455\n",
      "-----Epoch:  190 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.26764582871315284\n",
      "-----Epoch:  200 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2664606346176932\n",
      "-----Epoch:  210 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.26512990007016995\n",
      "-----Epoch:  220 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.26363652073693755\n",
      "-----Epoch:  230 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2619619735987349\n",
      "-----Epoch:  240 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2600862869187261\n",
      "-----Epoch:  250 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.25798806295012405\n",
      "-----Epoch:  260 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2556445860444447\n",
      "-----Epoch:  270 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2530320559569501\n",
      "-----Epoch:  280 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.25012599021173504\n",
      "-----Epoch:  290 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.24690183833029342\n",
      "-----Epoch:  300 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.24333584237111816\n",
      "-----Epoch:  310 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.23940616060733141\n",
      "-----Epoch:  320 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.23509424312929253\n",
      "-----Epoch:  330 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.23038641022158332\n",
      "-----Epoch:  340 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2252755396212284\n",
      "-----Epoch:  350 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.21976272336391345\n",
      "-----Epoch:  360 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.21385871768855133\n",
      "-----Epoch:  370 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.20758499045028347\n",
      "-----Epoch:  380 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.2009741787018542\n",
      "-----Epoch:  390 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.19406980996378273\n",
      "-----Epoch:  400 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.18692521376667526\n",
      "-----Epoch:  410 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.1796016475114009\n",
      "-----Epoch:  420 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.17216576735798728\n",
      "-----Epoch:  430 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.1646866703323215\n",
      "-----Epoch:  440 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.1572327972712634\n",
      "-----Epoch:  450 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.14986900248777887\n",
      "-----Epoch:  460 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.1426540610662424\n",
      "-----Epoch:  470 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.13563880737649653\n",
      "-----Epoch:  480 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.12886499778631597\n",
      "-----Epoch:  490 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.12236488953723096\n",
      "-----Epoch:  500 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.116161445889056\n",
      "-----Epoch:  510 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.11026902623579125\n",
      "-----Epoch:  520 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.1046944007827339\n",
      "-----Epoch:  530 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.09943793698957076\n",
      "-----Epoch:  540 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.09449483002897846\n",
      "-----Epoch:  550 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.08985628242346988\n",
      "-----Epoch:  560 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.08551057122428657\n",
      "-----Epoch:  570 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.08144396982194341\n",
      "-----Epoch:  580 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.07764151358387038\n",
      "-----Epoch:  590 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.07408761376507725\n",
      "-----Epoch:  600 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.07076653341023918\n",
      "-----Epoch:  610 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.06766274360080779\n",
      "-----Epoch:  620 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.06476117977511045\n",
      "-----Epoch:  630 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.06204741714865576\n",
      "-----Epoch:  640 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.05950778239873505\n",
      "-----Epoch:  650 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.05712941639452891\n",
      "-----Epoch:  660 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.054900300267160244\n",
      "-----Epoch:  670 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.05280925476767624\n",
      "-----Epoch:  680 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.05084592077902054\n",
      "-----Epoch:  690 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.049000727076965046\n",
      "-----Epoch:  700 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.04726484997421491\n",
      "-----Epoch:  710 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.04563016830571616\n",
      "-----Epoch:  720 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.04408921628449413\n",
      "-----Epoch:  730 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.042635136036194794\n",
      "-----Epoch:  740 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.041261631068801125\n",
      "-----Epoch:  750 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.039962921517845175\n",
      "-----Epoch:  760 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.03873370169792784\n",
      "-----Epoch:  770 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.03756910026460181\n",
      "-----Epoch:  780 -----\n",
      "Accuracy: 0.75\n",
      "Cost: 0.03646464312735549\n",
      "-----Epoch:  790 -----\n",
      "Accuracy: 0.75\n",
      "Cost: 0.03541621913922102\n",
      "-----Epoch:  800 -----\n",
      "Accuracy: 0.75\n",
      "Cost: 0.03442004850940135\n",
      "-----Epoch:  810 -----\n",
      "Accuracy: 0.75\n",
      "Cost: 0.033472653832964834\n",
      "-----Epoch:  820 -----\n",
      "Accuracy: 0.75\n",
      "Cost: 0.032570833598958314\n",
      "-----Epoch:  830 -----\n",
      "Accuracy: 0.75\n",
      "Cost: 0.03171163801981474\n",
      "-----Epoch:  840 -----\n",
      "Accuracy: 0.75\n",
      "Cost: 0.03089234701659704\n",
      "-----Epoch:  850 -----\n",
      "Accuracy: 0.75\n",
      "Cost: 0.03011045019336467\n",
      "-----Epoch:  860 -----\n",
      "Accuracy: 0.75\n",
      "Cost: 0.029363628637509877\n",
      "-----Epoch:  870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.02864973838962369\n",
      "-----Epoch:  880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.027966795435102\n",
      "-----Epoch:  890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.027312962079426385\n",
      "-----Epoch:  900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.026686534579232236\n",
      "-----Epoch:  910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.026085931911487593\n",
      "-----Epoch:  920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.02550968557305853\n",
      "-----Epoch:  930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.024956430312450213\n",
      "-----Epoch:  940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.024424895704468666\n",
      "-----Epoch:  950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.023913898486894236\n",
      "-----Epoch:  960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.023422335585964307\n",
      "-----Epoch:  970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.022949177764534985\n",
      "-----Epoch:  980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.022493463833249287\n",
      "-----Epoch:  990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.022054295370909086\n",
      "-----Epoch:  1000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.021630831905569595\n",
      "-----Epoch:  1010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.021222286512684232\n",
      "-----Epoch:  1020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.02082792179096837\n",
      "-----Epoch:  1030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.020447046180558676\n",
      "-----Epoch:  1040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.02007901059156219\n",
      "-----Epoch:  1050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.019723205314251608\n",
      "-----Epoch:  1060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.019379057185002393\n",
      "-----Epoch:  1070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.019046026984619116\n",
      "-----Epoch:  1080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01872360704798772\n",
      "-----Epoch:  1090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.018411319066046063\n",
      "-----Epoch:  1100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01810871206291047\n",
      "-----Epoch:  1110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.017815360532653573\n",
      "-----Epoch:  1120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.017530862721714897\n",
      "-----Epoch:  1130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.017254839044264985\n",
      "-----Epoch:  1140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01698693061904307\n",
      "-----Epoch:  1150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01672679791726959\n",
      "-----Epoch:  1160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.016474119512206366\n",
      "-----Epoch:  1170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.016228590921811704\n",
      "-----Epoch:  1180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01598992353672558\n",
      "-----Epoch:  1190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.015757843626529856\n",
      "-----Epoch:  1200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.015532091417867802\n",
      "-----Epoch:  1210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.015312420238586305\n",
      "-----Epoch:  1220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.015098595722583359\n",
      "-----Epoch:  1230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.014890395070517072\n",
      "-----Epoch:  1240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.014687606361955763\n",
      "-----Epoch:  1250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.014490027914937004\n",
      "-----Epoch:  1260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.014297467689249539\n",
      "-----Epoch:  1270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01410974273007104\n",
      "-----Epoch:  1280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.013926678648879191\n",
      "-----Epoch:  1290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.013748109138815452\n",
      "-----Epoch:  1300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01357387552191643\n",
      "-----Epoch:  1310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.013403826325842139\n",
      "-----Epoch:  1320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01323781688792754\n",
      "-----Epoch:  1330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.013075708984558827\n",
      "-----Epoch:  1340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.012917370484040937\n",
      "-----Epoch:  1350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.012762675021267636\n",
      "-----Epoch:  1360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.012611501692641925\n",
      "-----Epoch:  1370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.012463734769816862\n",
      "-----Epoch:  1380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.012319263430938773\n",
      "-----Epoch:  1390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.012177981508178075\n",
      "-----Epoch:  1400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01203978725042659\n",
      "-----Epoch:  1410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.011904583100125838\n",
      "-----Epoch:  1420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.011772275483269548\n",
      "-----Epoch:  1430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01164277461169693\n",
      "-----Epoch:  1440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.011515994296857133\n",
      "-----Epoch:  1450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.011391851774288343\n",
      "-----Epoch:  1460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0112702675381097\n",
      "-----Epoch:  1470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.011151165184875026\n",
      "-----Epoch:  1480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.011034471266185938\n",
      "-----Epoch:  1490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010920115149503765\n",
      "-----Epoch:  1500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010808028886640961\n",
      "-----Epoch:  1510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010698147089448327\n",
      "-----Epoch:  1520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010590406812249799\n",
      "-----Epoch:  1530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01048474744060603\n",
      "-----Epoch:  1540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010381110586019022\n",
      "-----Epoch:  1550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.01027943998621459\n",
      "-----Epoch:  1560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010179681410666233\n",
      "-----Epoch:  1570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.010081782571045195\n",
      "-----Epoch:  1580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00998569303630356\n",
      "-----Epoch:  1590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009891364152116335\n",
      "-----Epoch:  1600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009798748964427097\n",
      "-----Epoch:  1610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009707802146858062\n",
      "-----Epoch:  1620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00961847993176113\n",
      "-----Epoch:  1630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009530740044701353\n",
      "-----Epoch:  1640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009444541642177196\n",
      "-----Epoch:  1650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009359845252394606\n",
      "-----Epoch:  1660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009276612718923672\n",
      "-----Epoch:  1670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009194807147077199\n",
      "-----Epoch:  1680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00911439285286078\n",
      "-----Epoch:  1690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.009035335314352853\n",
      "-----Epoch:  1700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008957601125382885\n",
      "-----Epoch:  1710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008881157951382506\n",
      "-----Epoch:  1720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008805974487293441\n",
      "-----Epoch:  1730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008732020417422038\n",
      "-----Epoch:  1740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008659266377137672\n",
      "-----Epoch:  1750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0085876839163172\n",
      "-----Epoch:  1760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008517245464445216\n",
      "-----Epoch:  1770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008447924297283157\n",
      "-----Epoch:  1780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008379694505027022\n",
      "-----Epoch:  1790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008312530961877158\n",
      "-----Epoch:  1800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008246409296948433\n",
      "-----Epoch:  1810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00818130586645288\n",
      "-----Epoch:  1820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008117197727091054\n",
      "-----Epoch:  1830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.008054062610591954\n",
      "-----Epoch:  1840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007991878899344195\n",
      "-----Epoch:  1850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007930625603065287\n",
      "-----Epoch:  1860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007870282336457857\n",
      "-----Epoch:  1870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0078108292978048225\n",
      "-----Epoch:  1880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007752247248458616\n",
      "-----Epoch:  1890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007694517493181102\n",
      "-----Epoch:  1900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00763762186129404\n",
      "-----Epoch:  1910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007581542688601359\n",
      "-----Epoch:  1920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007526262800047221\n",
      "-----Epoch:  1930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007471765493075225\n",
      "-----Epoch:  1940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007418034521656414\n",
      "-----Epoch:  1950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007365054080954864\n",
      "-----Epoch:  1960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007312808792601983\n",
      "-----Epoch:  1970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007261283690551482\n",
      "-----Epoch:  1980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007210464207488581\n",
      "-----Epoch:  1990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007160336161768874\n",
      "-----Epoch:  2000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007110885744862844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  2010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007062099509283375\n",
      "-----Epoch:  2020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.007013964356975264\n",
      "-----Epoch:  2030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006966467528146053\n",
      "-----Epoch:  2040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006919596590519145\n",
      "-----Epoch:  2050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00687333942899055\n",
      "-----Epoch:  2060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006827684235672081\n",
      "-----Epoch:  2070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006782619500304298\n",
      "-----Epoch:  2080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006738134001023227\n",
      "-----Epoch:  2090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006694216795466057\n",
      "-----Epoch:  2100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006650857212201328\n",
      "-----Epoch:  2110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006608044842470281\n",
      "-----Epoch:  2120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006565769532225811\n",
      "-----Epoch:  2130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006524021374457158\n",
      "-----Epoch:  2140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006482790701788205\n",
      "-----Epoch:  2150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0064420680793387365\n",
      "-----Epoch:  2160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0064018442978367954\n",
      "-----Epoch:  2170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006362110366973076\n",
      "-----Epoch:  2180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006322857508987191\n",
      "-----Epoch:  2190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006284077152475961\n",
      "-----Epoch:  2200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006245760926415738\n",
      "-----Epoch:  2210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00620790065438951\n",
      "-----Epoch:  2220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006170488349011253\n",
      "-----Epoch:  2230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006133516206539412\n",
      "-----Epoch:  2240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006096976601672148\n",
      "-----Epoch:  2250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006060862082517326\n",
      "-----Epoch:  2260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.006025165365730855\n",
      "-----Epoch:  2270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005989879331816034\n",
      "-----Epoch:  2280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005954997020578603\n",
      "-----Epoch:  2290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005920511626731121\n",
      "-----Epoch:  2300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005886416495640934\n",
      "-----Epoch:  2310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005852705119216906\n",
      "-----Epoch:  2320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005819371131928665\n",
      "-----Epoch:  2330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005786408306954665\n",
      "-----Epoch:  2340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005753810552453226\n",
      "-----Epoch:  2350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005721571907952518\n",
      "-----Epoch:  2360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005689686540855155\n",
      "-----Epoch:  2370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005658148743053026\n",
      "-----Epoch:  2380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005626952927648229\n",
      "-----Epoch:  2390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005596093625776723\n",
      "-----Epoch:  2400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005565565483530448\n",
      "-----Epoch:  2410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005535363258974855\n",
      "-----Epoch:  2420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005505481819258093\n",
      "-----Epoch:  2430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005475916137808717\n",
      "-----Epoch:  2440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005446661291618918\n",
      "-----Epoch:  2450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005417712458610143\n",
      "-----Epoch:  2460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0053890649150780115\n",
      "-----Epoch:  2470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005360714033214207\n",
      "-----Epoch:  2480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005332655278702534\n",
      "-----Epoch:  2490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005304884208386076\n",
      "-----Epoch:  2500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005277396468003969\n",
      "-----Epoch:  2510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0052501877899943945\n",
      "-----Epoch:  2520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005223253991362323\n",
      "-----Epoch:  2530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005196590971609457\n",
      "-----Epoch:  2540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005170194710724216\n",
      "-----Epoch:  2550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005144061267229882\n",
      "-----Epoch:  2560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005118186776289124\n",
      "-----Epoch:  2570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005092567447862558\n",
      "-----Epoch:  2580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005067199564920171\n",
      "-----Epoch:  2590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00504207948170312\n",
      "-----Epoch:  2600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.005017203622034972\n",
      "-----Epoch:  2610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004992568477680605\n",
      "-----Epoch:  2620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0049681706067505535\n",
      "-----Epoch:  2630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0049440066321503025\n",
      "-----Epoch:  2640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004920073240072632\n",
      "-----Epoch:  2650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00489636717853123\n",
      "-----Epoch:  2660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004872885255935194\n",
      "-----Epoch:  2670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004849624339702133\n",
      "-----Epoch:  2680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004826581354909373\n",
      "-----Epoch:  2690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004803753282981781\n",
      "-----Epoch:  2700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0047811371604148546\n",
      "-----Epoch:  2710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004758730077532465\n",
      "-----Epoch:  2720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004736529177277633\n",
      "-----Epoch:  2730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004714531654035857\n",
      "-----Epoch:  2740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00469273475248946\n",
      "-----Epoch:  2750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004671135766502495\n",
      "-----Epoch:  2760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0046497320380347535\n",
      "-----Epoch:  2770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004628520956084549\n",
      "-----Epoch:  2780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00460749995565892\n",
      "-----Epoch:  2790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004586666516770781\n",
      "-----Epoch:  2800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004566018163461904\n",
      "-----Epoch:  2810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0045455524628512855\n",
      "-----Epoch:  2820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004525267024207766\n",
      "-----Epoch:  2830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00450515949804659\n",
      "-----Epoch:  2840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004485227575248825\n",
      "-----Epoch:  2850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004465468986203246\n",
      "-----Epoch:  2860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004445881499969739\n",
      "-----Epoch:  2870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004426462923464131\n",
      "-----Epoch:  2880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004407211100662904\n",
      "-----Epoch:  2890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004388123911828332\n",
      "-----Epoch:  2900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004369199272752517\n",
      "-----Epoch:  2910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004350435134020233\n",
      "-----Epoch:  2920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0043318294802901615\n",
      "-----Epoch:  2930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0043133803295934\n",
      "-----Epoch:  2940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004295085732649574\n",
      "-----Epoch:  2950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004276943772199296\n",
      "-----Epoch:  2960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004258952562352947\n",
      "-----Epoch:  2970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004241110247955342\n",
      "-----Epoch:  2980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004223415003965358\n",
      "-----Epoch:  2990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004205865034850985\n",
      "-----Epoch:  3000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004188458573998242\n",
      "-----Epoch:  3010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004171193883134654\n",
      "-----Epoch:  3020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004154069251766117\n",
      "-----Epoch:  3030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004137082996627211\n",
      "-----Epoch:  3040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004120233461144456\n",
      "-----Epoch:  3050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004103519014912051\n",
      "-----Epoch:  3060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004086938053179954\n",
      "-----Epoch:  3070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004070488996353906\n",
      "-----Epoch:  3080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004054170289506913\n",
      "-----Epoch:  3090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004037980401902226\n",
      "-----Epoch:  3100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004021917826527002\n",
      "-----Epoch:  3110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.004005981079637145\n",
      "-----Epoch:  3120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003990168700311817\n",
      "-----Epoch:  3130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003974479250018995\n",
      "-----Epoch:  3140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003958911312189896\n",
      "-----Epoch:  3150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003943463491803941\n",
      "-----Epoch:  3160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003928134414982528\n",
      "-----Epoch:  3170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003912922728591793\n",
      "-----Epoch:  3180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0038978270998549255\n",
      "-----Epoch:  3190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0038828462159723564\n",
      "-----Epoch:  3200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003867978783750777\n",
      "-----Epoch:  3210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003853223529240381\n",
      "-----Epoch:  3220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0038385791973799092\n",
      "-----Epoch:  3230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003824044551649684\n",
      "-----Epoch:  3240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003809618373732006\n",
      "-----Epoch:  3250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003795299463179222\n",
      "-----Epoch:  3260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003781086637088689\n",
      "-----Epoch:  3270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003766978729785162\n",
      "-----Epoch:  3280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0037529745925096985\n",
      "-----Epoch:  3290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003739073093115321\n",
      "-----Epoch:  3300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003725273115769409\n",
      "-----Epoch:  3310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003711573560662126\n",
      "-----Epoch:  3320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0036979733437212552\n",
      "-----Epoch:  3330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0036844713963330973\n",
      "-----Epoch:  3340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0036710666650691622\n",
      "-----Epoch:  3350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003657758111418557\n",
      "-----Epoch:  3360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0036445447115262515\n",
      "-----Epoch:  3370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003631425455936488\n",
      "-----Epoch:  3380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0036183993493418493\n",
      "-----Epoch:  3390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0036054654103372095\n",
      "-----Epoch:  3400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003592622671179213\n",
      "-----Epoch:  3410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0035798701775501575\n",
      "-----Epoch:  3420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003567206988327253\n",
      "-----Epoch:  3430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00355463217535634\n",
      "-----Epoch:  3440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0035421448232301755\n",
      "-----Epoch:  3450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0035297440290715134\n",
      "-----Epoch:  3460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003517428902320287\n",
      "-----Epoch:  3470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0035051985645252488\n",
      "-----Epoch:  3480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0034930521491397582\n",
      "-----Epoch:  3490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003480988801321744\n",
      "-----Epoch:  3500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0034690076777375736\n",
      "-----Epoch:  3510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0034571079463699204\n",
      "-----Epoch:  3520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003445288786329376\n",
      "-----Epoch:  3530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003433549387669852\n",
      "-----Epoch:  3540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003421888951207696\n",
      "-----Epoch:  3550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0034103066883442376\n",
      "-----Epoch:  3560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0033988018208917763\n",
      "-----Epoch:  3570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0033873735809032985\n",
      "-----Epoch:  3580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0033760212105050807\n",
      "-----Epoch:  3590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003364743961732951\n",
      "-----Epoch:  3600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0033535410963713625\n",
      "-----Epoch:  3610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003342411885795943\n",
      "-----Epoch:  3620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003331355610818692\n",
      "-----Epoch:  3630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0033203715615365763\n",
      "-----Epoch:  3640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003309459037182585\n",
      "-----Epoch:  3650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032986173459799914\n",
      "-----Epoch:  3660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003287845804999183\n",
      "-----Epoch:  3670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032771437400172265\n",
      "-----Epoch:  3680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032665104853803434\n",
      "-----Epoch:  3690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032559453838683777\n",
      "-----Epoch:  3700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032454477865625875\n",
      "-----Epoch:  3710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032350170527153084\n",
      "-----Epoch:  3720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003224652549622276\n",
      "-----Epoch:  3730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0032143536524974516\n",
      "-----Epoch:  3740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003204119744349919\n",
      "-----Epoch:  3750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00319395021586318\n",
      "-----Epoch:  3760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003183844465276803\n",
      "-----Epoch:  3770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003173801898269961\n",
      "-----Epoch:  3780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003163821927847414\n",
      "-----Epoch:  3790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0031539039742273936\n",
      "-----Epoch:  3800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003144047464731485\n",
      "-----Epoch:  3810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003134251833676778\n",
      "-----Epoch:  3820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0031245165222696493\n",
      "-----Epoch:  3830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003114840978501636\n",
      "-----Epoch:  3840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0031052246570472865\n",
      "-----Epoch:  3850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0030956670191636115\n",
      "-----Epoch:  3860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0030861675325913433\n",
      "-----Epoch:  3870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0030767256714583423\n",
      "-----Epoch:  3880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00306734091618427\n",
      "-----Epoch:  3890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0030580127533870725\n",
      "-----Epoch:  3900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003048740675791462\n",
      "-----Epoch:  3910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0030395241821383236\n",
      "-----Epoch:  3920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003030362777096466\n",
      "-----Epoch:  3930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0030212559711754977\n",
      "-----Epoch:  3940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003012203280640217\n",
      "-----Epoch:  3950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.003003204227426705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  3960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002994258339059721\n",
      "-----Epoch:  3970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029853651485715633\n",
      "-----Epoch:  3980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029765241944224087\n",
      "-----Epoch:  3990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002967735020421937\n",
      "-----Epoch:  4000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002958997175652368\n",
      "-----Epoch:  4010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029503102143926675\n",
      "-----Epoch:  4020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029416736960443846\n",
      "-----Epoch:  4030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002933087185058343\n",
      "-----Epoch:  4040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029245502508629603\n",
      "-----Epoch:  4050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029160624677933597\n",
      "-----Epoch:  4060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0029076234150222026\n",
      "-----Epoch:  4070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028992326764913433\n",
      "-----Epoch:  4080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002890889840844443\n",
      "-----Epoch:  4090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028825945013613865\n",
      "-----Epoch:  4100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002874346255893062\n",
      "-----Epoch:  4110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028661447067977854\n",
      "-----Epoch:  4120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028579894608783026\n",
      "-----Epoch:  4130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002849880129320377\n",
      "-----Epoch:  4140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002841816327631872\n",
      "-----Epoch:  4150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028337976755831934\n",
      "-----Epoch:  4160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002825823797148602\n",
      "-----Epoch:  4170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028178943204483376\n",
      "-----Epoch:  4180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028100088776920372\n",
      "-----Epoch:  4190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0028021671051227407\n",
      "-----Epoch:  4200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027943686429619664\n",
      "-----Epoch:  4210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002786613135355702\n",
      "-----Epoch:  4220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027789002303211657\n",
      "-----Epoch:  4230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027712295796945684\n",
      "-----Epoch:  4240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002763600839079557\n",
      "-----Epoch:  4250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002756013667796582\n",
      "-----Epoch:  4260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002748467728833123\n",
      "-----Epoch:  4270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027409626887945973\n",
      "-----Epoch:  4280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00273349821785608\n",
      "-----Epoch:  4290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002726073989714922\n",
      "-----Epoch:  4300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027186896815439097\n",
      "-----Epoch:  4310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027113449739453663\n",
      "-----Epoch:  4320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0027040395509057703\n",
      "-----Epoch:  4330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002696773099751295\n",
      "-----Epoch:  4340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026895453111039505\n",
      "-----Epoch:  4350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026823558788383484\n",
      "-----Epoch:  4360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002675204500039348\n",
      "-----Epoch:  4370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026680908749599584\n",
      "-----Epoch:  4380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002661014706980599\n",
      "-----Epoch:  4390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026539757025680387\n",
      "-----Epoch:  4400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026469735712359474\n",
      "-----Epoch:  4410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026400080255052673\n",
      "-----Epoch:  4420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002633078780865687\n",
      "-----Epoch:  4430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026261855557375706\n",
      "-----Epoch:  4440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026193280714342836\n",
      "-----Epoch:  4450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002612506052125422\n",
      "-----Epoch:  4460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0026057192248003804\n",
      "-----Epoch:  4470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002598967319232398\n",
      "-----Epoch:  4480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002592250067943492\n",
      "-----Epoch:  4490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025855672061696564\n",
      "-----Epoch:  4500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025789184718264524\n",
      "-----Epoch:  4510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025723036054754707\n",
      "-----Epoch:  4520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002565722350291243\n",
      "-----Epoch:  4530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002559174452028179\n",
      "-----Epoch:  4540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025526596589887534\n",
      "-----Epoch:  4550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002546177721991503\n",
      "-----Epoch:  4560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002539728394339809\n",
      "-----Epoch:  4570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025333114317911513\n",
      "-----Epoch:  4580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002526926592526778\n",
      "-----Epoch:  4590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002520573637121769\n",
      "-----Epoch:  4600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002514252328515509\n",
      "-----Epoch:  4610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025079624319828543\n",
      "-----Epoch:  4620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0025017037151054025\n",
      "-----Epoch:  4630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002495475947743216\n",
      "-----Epoch:  4640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024892789020072906\n",
      "-----Epoch:  4650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024831123522320235\n",
      "-----Epoch:  4660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024769760749483363\n",
      "-----Epoch:  4670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024708698488569362\n",
      "-----Epoch:  4680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024647934548023775\n",
      "-----Epoch:  4690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024587466757470277\n",
      "-----Epoch:  4700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002452729296745757\n",
      "-----Epoch:  4710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002446741104920694\n",
      "-----Epoch:  4720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002440781889436764\n",
      "-----Epoch:  4730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024348514414771205\n",
      "-----Epoch:  4740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024289495542191343\n",
      "-----Epoch:  4750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024230760228107725\n",
      "-----Epoch:  4760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024172306443473097\n",
      "-----Epoch:  4770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024114132178481664\n",
      "-----Epoch:  4780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0024056235442343112\n",
      "-----Epoch:  4790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002399861426305953\n",
      "-----Epoch:  4800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023941266687203472\n",
      "-----Epoch:  4810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023884190779701014\n",
      "-----Epoch:  4820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002382738462361876\n",
      "-----Epoch:  4830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023770846319949154\n",
      "-----Epoch:  4840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002371457398740609\n",
      "-----Epoch:  4850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023658565762215812\n",
      "-----Epoch:  4860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023602819797916307\n",
      "-----Epoch:  4870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023547334265155914\n",
      "-----Epoch:  4880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002349210735149855\n",
      "-----Epoch:  4890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002343713726122597\n",
      "-----Epoch:  4900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023382422215147774\n",
      "-----Epoch:  4910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023327960450412973\n",
      "-----Epoch:  4920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002327375022032232\n",
      "-----Epoch:  4930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023219789794144056\n",
      "-----Epoch:  4940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002316607745693219\n",
      "-----Epoch:  4950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002311261150934962\n",
      "-----Epoch:  4960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0023059390267488908\n",
      "-----Epoch:  4970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002300641206269932\n",
      "-----Epoch:  4980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002295367524141418\n",
      "-----Epoch:  4990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022901178164982557\n",
      "-----Epoch:  5000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022848919209500496\n",
      "-----Epoch:  5010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002279689676564739\n",
      "-----Epoch:  5020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002274510923852085\n",
      "-----Epoch:  5030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022693555047478865\n",
      "-----Epoch:  5040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002264223262597925\n",
      "-----Epoch:  5050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002259114042142415\n",
      "-----Epoch:  5060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022540276895005327\n",
      "-----Epoch:  5070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002248964052155176\n",
      "-----Epoch:  5080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022439229789378854\n",
      "-----Epoch:  5090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002238904320014154\n",
      "-----Epoch:  5100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022339079268686654\n",
      "-----Epoch:  5110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002228933652290867\n",
      "-----Epoch:  5120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002223981350360773\n",
      "-----Epoch:  5130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022190508764347826\n",
      "-----Epoch:  5140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022141420871318773\n",
      "-----Epoch:  5150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0022092548403199247\n",
      "-----Epoch:  5160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002204388995102098\n",
      "-----Epoch:  5170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021995444118035313\n",
      "-----Epoch:  5180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00219472095195808\n",
      "-----Epoch:  5190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021899184782954574\n",
      "-----Epoch:  5200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021851368547282693\n",
      "-----Epoch:  5210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002180375946339383\n",
      "-----Epoch:  5220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002175635619369367\n",
      "-----Epoch:  5230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021709157412041088\n",
      "-----Epoch:  5240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00216621618036279\n",
      "-----Epoch:  5250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002161536806485613\n",
      "-----Epoch:  5260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002156877490322015\n",
      "-----Epoch:  5270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021522381037189678\n",
      "-----Epoch:  5280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021476185196093005\n",
      "-----Epoch:  5290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002143018612000294\n",
      "-----Epoch:  5300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002138438255962378\n",
      "-----Epoch:  5310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002133877327617949\n",
      "-----Epoch:  5320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021293357041304345\n",
      "-----Epoch:  5330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021248132636931955\n",
      "-----Epoch:  5340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021203098855191137\n",
      "-----Epoch:  5350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021158254498296605\n",
      "-----Epoch:  5360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002111359837844576\n",
      "-----Epoch:  5370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021069129317714667\n",
      "-----Epoch:  5380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0021024846147956913\n",
      "-----Epoch:  5390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002098074771070074\n",
      "-----Epoch:  5400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020936832857051182\n",
      "-----Epoch:  5410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002089310044759036\n",
      "-----Epoch:  5420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020849549352280785\n",
      "-----Epoch:  5430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020806178450368715\n",
      "-----Epoch:  5440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020762986630290152\n",
      "-----Epoch:  5450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020719972789576724\n",
      "-----Epoch:  5460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002067713583476172\n",
      "-----Epoch:  5470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002063447468129143\n",
      "-----Epoch:  5480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020591988253432524\n",
      "-----Epoch:  5490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020549675484182596\n",
      "-----Epoch:  5500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020507535315184614\n",
      "-----Epoch:  5510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002046556669663641\n",
      "-----Epoch:  5520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020423768587206695\n",
      "-----Epoch:  5530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002038213995394941\n",
      "-----Epoch:  5540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020340679772220325\n",
      "-----Epoch:  5550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020299387025592775\n",
      "-----Epoch:  5560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002025826070577682\n",
      "-----Epoch:  5570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020217299812537617\n",
      "-----Epoch:  5580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002017650335361462\n",
      "-----Epoch:  5590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020135870344645196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  5600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0020095399809082534\n",
      "-----Epoch:  5610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002005509077812175\n",
      "-----Epoch:  5620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.002001494229062095\n",
      "-----Epoch:  5630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001997495339302804\n",
      "-----Epoch:  5640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001993512313930446\n",
      "-----Epoch:  5650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00198954505908523\n",
      "-----Epoch:  5660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019855934816441164\n",
      "-----Epoch:  5670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019816574892136635\n",
      "-----Epoch:  5680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019777369901228434\n",
      "-----Epoch:  5690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019738318934161315\n",
      "-----Epoch:  5700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019699421088463084\n",
      "-----Epoch:  5710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001966067546867982\n",
      "-----Epoch:  5720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019622081186303855\n",
      "-----Epoch:  5730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001958363735971\n",
      "-----Epoch:  5740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019545343114086653\n",
      "-----Epoch:  5750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019507197581372\n",
      "-----Epoch:  5760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001946919990018877\n",
      "-----Epoch:  5770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019431349215780045\n",
      "-----Epoch:  5780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001939364467994514\n",
      "-----Epoch:  5790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019356085450978559\n",
      "-----Epoch:  5800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019318670693607163\n",
      "-----Epoch:  5810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019281399578928299\n",
      "-----Epoch:  5820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00192442712843513\n",
      "-----Epoch:  5830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001920728499353593\n",
      "-----Epoch:  5840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019170439896333893\n",
      "-----Epoch:  5850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019133735188729926\n",
      "-----Epoch:  5860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019097170072785272\n",
      "-----Epoch:  5870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019060743756579045\n",
      "-----Epoch:  5880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0019024455454152182\n",
      "-----Epoch:  5890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018988304385451926\n",
      "-----Epoch:  5900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018952289776276812\n",
      "-----Epoch:  5910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001891641085822119\n",
      "-----Epoch:  5920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018880666868621764\n",
      "-----Epoch:  5930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001884505705050346\n",
      "-----Epoch:  5940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018809580652527594\n",
      "-----Epoch:  5950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018774236928939857\n",
      "-----Epoch:  5960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018739025139517245\n",
      "-----Epoch:  5970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018703944549517773\n",
      "-----Epoch:  5980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018668994429630306\n",
      "-----Epoch:  5990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018634174055924071\n",
      "-----Epoch:  6000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018599482709799288\n",
      "-----Epoch:  6010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018564919677938358\n",
      "-----Epoch:  6020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018530484252257872\n",
      "-----Epoch:  6030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001849617572986047\n",
      "-----Epoch:  6040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018461993412987204\n",
      "-----Epoch:  6050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018427936608971301\n",
      "-----Epoch:  6060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018394004630192117\n",
      "-----Epoch:  6070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001836019679402859\n",
      "-----Epoch:  6080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018326512422814504\n",
      "-----Epoch:  6090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001829295084379401\n",
      "-----Epoch:  6100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018259511389076104\n",
      "-----Epoch:  6110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001822619339559263\n",
      "-----Epoch:  6120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001819299620505309\n",
      "-----Epoch:  6130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00181599191639032\n",
      "-----Epoch:  6140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018126961623281563\n",
      "-----Epoch:  6150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001809412293897864\n",
      "-----Epoch:  6160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0018061402471394091\n",
      "-----Epoch:  6170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001802879958549602\n",
      "-----Epoch:  6180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017996313650781534\n",
      "-----Epoch:  6190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017963944041235018\n",
      "-----Epoch:  6200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017931690135289053\n",
      "-----Epoch:  6210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017899551315784538\n",
      "-----Epoch:  6220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017867526969933248\n",
      "-----Epoch:  6230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017835616489276958\n",
      "-----Epoch:  6240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017803819269651853\n",
      "-----Epoch:  6250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001777213471114862\n",
      "-----Epoch:  6260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017740562218076174\n",
      "-----Epoch:  6270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001770910119892566\n",
      "-----Epoch:  6280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017677751066331297\n",
      "-----Epoch:  6290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001764651123703752\n",
      "-----Epoch:  6300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017615381131859597\n",
      "-----Epoch:  6310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017584360175651682\n",
      "-----Epoch:  6320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017553447797269144\n",
      "-----Epoch:  6330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017522643429536237\n",
      "-----Epoch:  6340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017491946509208694\n",
      "-----Epoch:  6350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017461356476943448\n",
      "-----Epoch:  6360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017430872777261166\n",
      "-----Epoch:  6370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017400494858516935\n",
      "-----Epoch:  6380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001737022217286344\n",
      "-----Epoch:  6390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017340054176221886\n",
      "-----Epoch:  6400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001730999032824733\n",
      "-----Epoch:  6410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017280030092296896\n",
      "-----Epoch:  6420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017250172935400834\n",
      "-----Epoch:  6430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017220418328227063\n",
      "-----Epoch:  6440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017190765745054009\n",
      "-----Epoch:  6450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017161214663737713\n",
      "-----Epoch:  6460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017131764565681596\n",
      "-----Epoch:  6470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017102414935808116\n",
      "-----Epoch:  6480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001707316526252776\n",
      "-----Epoch:  6490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001704401503770893\n",
      "-----Epoch:  6500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0017014963756650189\n",
      "-----Epoch:  6510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016986010918051153\n",
      "-----Epoch:  6520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016957156023983848\n",
      "-----Epoch:  6530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016928398579863495\n",
      "-----Epoch:  6540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016899738094422667\n",
      "-----Epoch:  6550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016871174079680865\n",
      "-----Epoch:  6560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016842706050919456\n",
      "-----Epoch:  6570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016814333526654034\n",
      "-----Epoch:  6580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016786056028605932\n",
      "-----Epoch:  6590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001675787308167813\n",
      "-----Epoch:  6600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016729784213927016\n",
      "-----Epoch:  6610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016701788956536645\n",
      "-----Epoch:  6620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016673886843793799\n",
      "-----Epoch:  6630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016646077413061415\n",
      "-----Epoch:  6640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001661836020475363\n",
      "-----Epoch:  6650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001659073476231178\n",
      "-----Epoch:  6660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001656320063217689\n",
      "-----Epoch:  6670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016535757363768347\n",
      "-----Epoch:  6680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016508404509456864\n",
      "-----Epoch:  6690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016481141624542124\n",
      "-----Epoch:  6700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016453968267228136\n",
      "-----Epoch:  6710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001642688399860028\n",
      "-----Epoch:  6720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016399888382600464\n",
      "-----Epoch:  6730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016372980986005996\n",
      "-----Epoch:  6740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016346161378404237\n",
      "-----Epoch:  6750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001631942913217264\n",
      "-----Epoch:  6760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016292783822454055\n",
      "-----Epoch:  6770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016266225027135013\n",
      "-----Epoch:  6780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016239752326824804\n",
      "-----Epoch:  6790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016213365304830864\n",
      "-----Epoch:  6800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016187063547140465\n",
      "-----Epoch:  6810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016160846642397282\n",
      "-----Epoch:  6820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016134714181880669\n",
      "-----Epoch:  6830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016108665759484442\n",
      "-----Epoch:  6840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016082700971696074\n",
      "-----Epoch:  6850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016056819417575455\n",
      "-----Epoch:  6860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016031020698736992\n",
      "-----Epoch:  6870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0016005304419326079\n",
      "-----Epoch:  6880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015979670185999912\n",
      "-----Epoch:  6890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015954117607910234\n",
      "-----Epoch:  6900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015928646296680166\n",
      "-----Epoch:  6910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015903255866385906\n",
      "-----Epoch:  6920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015877945933538734\n",
      "-----Epoch:  6930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015852716117064252\n",
      "-----Epoch:  6940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015827566038284263\n",
      "-----Epoch:  6950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015802495320897374\n",
      "-----Epoch:  6960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001577750359096121\n",
      "-----Epoch:  6970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015752590476873802\n",
      "-----Epoch:  6980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015727755609354342\n",
      "-----Epoch:  6990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015702998621426496\n",
      "-----Epoch:  7000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015678319148400158\n",
      "-----Epoch:  7010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015653716827852733\n",
      "-----Epoch:  7020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015629191299612614\n",
      "-----Epoch:  7030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015604742205741892\n",
      "-----Epoch:  7040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015580369190517816\n",
      "-----Epoch:  7050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015556071900417333\n",
      "-----Epoch:  7060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015531849984099064\n",
      "-----Epoch:  7070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015507703092386656\n",
      "-----Epoch:  7080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015483630878252528\n",
      "-----Epoch:  7090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001545963299680112\n",
      "-----Epoch:  7100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001543570910525342\n",
      "-----Epoch:  7110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015411858862928438\n",
      "-----Epoch:  7120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00153880819312302\n",
      "-----Epoch:  7130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015364377973629412\n",
      "-----Epoch:  7140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015340746655650274\n",
      "-----Epoch:  7150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015317187644852022\n",
      "-----Epoch:  7160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015293700610814734\n",
      "-----Epoch:  7170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001527028522512546\n",
      "-----Epoch:  7180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015246941161360785\n",
      "-----Epoch:  7190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015223668095072863\n",
      "-----Epoch:  7200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001520046570377443\n",
      "-----Epoch:  7210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015177333666924172\n",
      "-----Epoch:  7220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001515427166591219\n",
      "-----Epoch:  7230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001513127938404437\n",
      "-----Epoch:  7240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001510835650653018\n",
      "-----Epoch:  7250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015085502720465944\n",
      "-----Epoch:  7260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015062717714822852\n",
      "-----Epoch:  7270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015040001180431702\n",
      "-----Epoch:  7280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0015017352809969116\n",
      "-----Epoch:  7290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014994772297944733\n",
      "-----Epoch:  7300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014972259340687005\n",
      "-----Epoch:  7310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014949813636329261\n",
      "-----Epoch:  7320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014927434884796616\n",
      "-----Epoch:  7330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001490512278779338\n",
      "-----Epoch:  7340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014882877048788988\n",
      "-----Epoch:  7350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014860697373005936\n",
      "-----Epoch:  7360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014838583467405063\n",
      "-----Epoch:  7370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014816535040676055\n",
      "-----Epoch:  7380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014794551803220713\n",
      "-----Epoch:  7390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001477263346714369\n",
      "-----Epoch:  7400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014750779746238434\n",
      "-----Epoch:  7410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014728990355974822\n",
      "-----Epoch:  7420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014707265013487636\n",
      "-----Epoch:  7430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001468560343756422\n",
      "-----Epoch:  7440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001466400534863175\n",
      "-----Epoch:  7450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014642470468745972\n",
      "-----Epoch:  7460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014620998521579836\n",
      "-----Epoch:  7470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001459958923241011\n",
      "-----Epoch:  7480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014578242328108471\n",
      "-----Epoch:  7490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014556957537126564\n",
      "-----Epoch:  7500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014535734589487426\n",
      "-----Epoch:  7510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014514573216773555\n",
      "-----Epoch:  7520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001449347315211432\n",
      "-----Epoch:  7530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014472434130176283\n",
      "-----Epoch:  7540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014451455887151145\n",
      "-----Epoch:  7550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014430538160746628\n",
      "-----Epoch:  7560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014409680690172994\n",
      "-----Epoch:  7570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001438888321613469\n",
      "-----Epoch:  7580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001436814548081822\n",
      "-----Epoch:  7590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001434746722788166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  7600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014326848202445668\n",
      "-----Epoch:  7610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014306288151080548\n",
      "-----Epoch:  7620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014285786821799024\n",
      "-----Epoch:  7630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001426534396404322\n",
      "-----Epoch:  7640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014244959328675753\n",
      "-----Epoch:  7650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014224632667970733\n",
      "-----Epoch:  7660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001420436373560173\n",
      "-----Epoch:  7670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014184152286633442\n",
      "-----Epoch:  7680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001416399807751113\n",
      "-----Epoch:  7690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014143900866051152\n",
      "-----Epoch:  7700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001412386041143231\n",
      "-----Epoch:  7710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014103876474184267\n",
      "-----Epoch:  7720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014083948816179437\n",
      "-----Epoch:  7730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014064077200623762\n",
      "-----Epoch:  7740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014044261392047162\n",
      "-----Epoch:  7750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014024501156292835\n",
      "-----Epoch:  7760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0014004796260511513\n",
      "-----Epoch:  7770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013985146473149445\n",
      "-----Epoch:  7780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001396555156393895\n",
      "-----Epoch:  7790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001394601130389344\n",
      "-----Epoch:  7800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013926525465293618\n",
      "-----Epoch:  7810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013907093821682722\n",
      "-----Epoch:  7820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013887716147854856\n",
      "-----Epoch:  7830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013868392219848898\n",
      "-----Epoch:  7840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013849121814938047\n",
      "-----Epoch:  7850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013829904711621394\n",
      "-----Epoch:  7860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001381074068961771\n",
      "-----Epoch:  7870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00137916295298539\n",
      "-----Epoch:  7880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013772571014459686\n",
      "-----Epoch:  7890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013753564926756489\n",
      "-----Epoch:  7900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013734611051252359\n",
      "-----Epoch:  7910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013715709173631975\n",
      "-----Epoch:  7920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013696859080748092\n",
      "-----Epoch:  7930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013678060560615478\n",
      "-----Epoch:  7940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013659313402402007\n",
      "-----Epoch:  7950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013640617396420479\n",
      "-----Epoch:  7960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013621972334122185\n",
      "-----Epoch:  7970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013603378008087042\n",
      "-----Epoch:  7980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013584834212017598\n",
      "-----Epoch:  7990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013566340740732417\n",
      "-----Epoch:  8000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013547897390156073\n",
      "-----Epoch:  8010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013529503957312847\n",
      "-----Epoch:  8020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013511160240319764\n",
      "-----Epoch:  8030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013492866038378932\n",
      "-----Epoch:  8040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001347462115176969\n",
      "-----Epoch:  8050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013456425381843532\n",
      "-----Epoch:  8060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013438278531013102\n",
      "-----Epoch:  8070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013420180402749487\n",
      "-----Epoch:  8080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013402130801571093\n",
      "-----Epoch:  8090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013384129533040492\n",
      "-----Epoch:  8100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013366176403754749\n",
      "-----Epoch:  8110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013348271221338588\n",
      "-----Epoch:  8120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013330413794440201\n",
      "-----Epoch:  8130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001331260393272159\n",
      "-----Epoch:  8140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013294841446853526\n",
      "-----Epoch:  8150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001327712614850721\n",
      "-----Epoch:  8160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013259457850350348\n",
      "-----Epoch:  8170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013241836366038374\n",
      "-----Epoch:  8180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013224261510207946\n",
      "-----Epoch:  8190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013206733098472215\n",
      "-----Epoch:  8200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013189250947413056\n",
      "-----Epoch:  8210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013171814874574916\n",
      "-----Epoch:  8220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001315442469845894\n",
      "-----Epoch:  8230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013137080238515692\n",
      "-----Epoch:  8240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013119781315140964\n",
      "-----Epoch:  8250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001310252774966682\n",
      "-----Epoch:  8260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013085319364358862\n",
      "-----Epoch:  8270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001306815598240638\n",
      "-----Epoch:  8280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013051037427920065\n",
      "-----Epoch:  8290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013033963525923263\n",
      "-----Epoch:  8300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0013016934102346592\n",
      "-----Epoch:  8310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012999948984024415\n",
      "-----Epoch:  8320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001298300799868557\n",
      "-----Epoch:  8330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012966110974949614\n",
      "-----Epoch:  8340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001294925774232067\n",
      "-----Epoch:  8350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012932448131182017\n",
      "-----Epoch:  8360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012915681972790246\n",
      "-----Epoch:  8370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012898959099268321\n",
      "-----Epoch:  8380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012882279343602726\n",
      "-----Epoch:  8390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001286564253963597\n",
      "-----Epoch:  8400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012849048522061508\n",
      "-----Epoch:  8410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001283249712641826\n",
      "-----Epoch:  8420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012815988189086198\n",
      "-----Epoch:  8430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012799521547279293\n",
      "-----Epoch:  8440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001278309703904146\n",
      "-----Epoch:  8450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00127667145032406\n",
      "-----Epoch:  8460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012750373779564107\n",
      "-----Epoch:  8470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012734074708513699\n",
      "-----Epoch:  8480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012717817131398573\n",
      "-----Epoch:  8490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012701600890332367\n",
      "-----Epoch:  8500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012685425828226967\n",
      "-----Epoch:  8510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012669291788788258\n",
      "-----Epoch:  8520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012653198616510155\n",
      "-----Epoch:  8530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012637146156670453\n",
      "-----Epoch:  8540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012621134255325324\n",
      "-----Epoch:  8550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012605162759304926\n",
      "-----Epoch:  8560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012589231516207688\n",
      "-----Epoch:  8570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012573340374397374\n",
      "-----Epoch:  8580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012557489182996125\n",
      "-----Epoch:  8590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012541677791880195\n",
      "-----Epoch:  8600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001252590605167747\n",
      "-----Epoch:  8610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001251017381375916\n",
      "-----Epoch:  8620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001249448093023834\n",
      "-----Epoch:  8630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00124788272539631\n",
      "-----Epoch:  8640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001246321263851372\n",
      "-----Epoch:  8650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012447636938197086\n",
      "-----Epoch:  8660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012432100008042163\n",
      "-----Epoch:  8670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001241660170379608\n",
      "-----Epoch:  8680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012401141881919755\n",
      "-----Epoch:  8690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012385720399582596\n",
      "-----Epoch:  8700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012370337114658823\n",
      "-----Epoch:  8710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012354991885723619\n",
      "-----Epoch:  8720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012339684572047645\n",
      "-----Epoch:  8730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012324415033593335\n",
      "-----Epoch:  8740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012309183131010953\n",
      "-----Epoch:  8750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012293988725634445\n",
      "-----Epoch:  8760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012278831679476269\n",
      "-----Epoch:  8770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00122637118552237\n",
      "-----Epoch:  8780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012248629116236337\n",
      "-----Epoch:  8790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012233583326539165\n",
      "-----Epoch:  8800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012218574350820518\n",
      "-----Epoch:  8810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012203602054427364\n",
      "-----Epoch:  8820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012188666303361605\n",
      "-----Epoch:  8830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012173766964275916\n",
      "-----Epoch:  8840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012158903904469478\n",
      "-----Epoch:  8850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012144076991884396\n",
      "-----Epoch:  8860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012129286095102308\n",
      "-----Epoch:  8870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012114531083339914\n",
      "-----Epoch:  8880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012099811826444475\n",
      "-----Epoch:  8890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012085128194891676\n",
      "-----Epoch:  8900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012070480059781145\n",
      "-----Epoch:  8910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012055867292831623\n",
      "-----Epoch:  8920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012041289766379255\n",
      "-----Epoch:  8930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0012026747353371461\n",
      "-----Epoch:  8940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001201223992736611\n",
      "-----Epoch:  8950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011997767362525913\n",
      "-----Epoch:  8960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011983329533614183\n",
      "-----Epoch:  8970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011968926315994017\n",
      "-----Epoch:  8980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011954557585621682\n",
      "-----Epoch:  8990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00119402232190455\n",
      "-----Epoch:  9000 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001192592309340123\n",
      "-----Epoch:  9010 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001191165708640805\n",
      "-----Epoch:  9020 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001189742507636606\n",
      "-----Epoch:  9030 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011883226942152032\n",
      "-----Epoch:  9040 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011869062563217613\n",
      "-----Epoch:  9050 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011854931819583589\n",
      "-----Epoch:  9060 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011840834591838323\n",
      "-----Epoch:  9070 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011826770761133379\n",
      "-----Epoch:  9080 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001181274020918127\n",
      "-----Epoch:  9090 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011798742818250742\n",
      "-----Epoch:  9100 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011784778471165313\n",
      "-----Epoch:  9110 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011770847051297902\n",
      "-----Epoch:  9120 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011756948442569462\n",
      "-----Epoch:  9130 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011743082529444382\n",
      "-----Epoch:  9140 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011729249196928697\n",
      "-----Epoch:  9150 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011715448330565819\n",
      "-----Epoch:  9160 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011701679816433618\n",
      "-----Epoch:  9170 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011687943541141175\n",
      "-----Epoch:  9180 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011674239391827183\n",
      "-----Epoch:  9190 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011660567256154154\n",
      "-----Epoch:  9200 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001164692702230815\n",
      "-----Epoch:  9210 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011633318578993213\n",
      "-----Epoch:  9220 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001161974181543065\n",
      "-----Epoch:  9230 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011606196621354909\n",
      "-----Epoch:  9240 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001159268288701053\n",
      "-----Epoch:  9250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011579200503148816\n",
      "-----Epoch:  9260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011565749361026646\n",
      "-----Epoch:  9270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011552329352401594\n",
      "-----Epoch:  9280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001153894036953011\n",
      "-----Epoch:  9290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011525582305164487\n",
      "-----Epoch:  9300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011512255052549727\n",
      "-----Epoch:  9310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011498958505420955\n",
      "-----Epoch:  9320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011485692558001394\n",
      "-----Epoch:  9330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011472457104997444\n",
      "-----Epoch:  9340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011459252041598103\n",
      "-----Epoch:  9350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011446077263471165\n",
      "-----Epoch:  9360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001143293266676084\n",
      "-----Epoch:  9370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001141981814808443\n",
      "-----Epoch:  9380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011406733604530706\n",
      "-----Epoch:  9390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011393678933656246\n",
      "-----Epoch:  9400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011380654033483395\n",
      "-----Epoch:  9410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011367658802497128\n",
      "-----Epoch:  9420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00113546931396427\n",
      "-----Epoch:  9430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011341756944322936\n",
      "-----Epoch:  9440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001132885011639656\n",
      "-----Epoch:  9450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011315972556173823\n",
      "-----Epoch:  9460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011303124164415478\n",
      "-----Epoch:  9470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011290304842329877\n",
      "-----Epoch:  9480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011277514491569271\n",
      "-----Epoch:  9490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011264753014229559\n",
      "-----Epoch:  9500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011252020312846165\n",
      "-----Epoch:  9510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011239316290391672\n",
      "-----Epoch:  9520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011226640850273803\n",
      "-----Epoch:  9530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011213993896333507\n",
      "-----Epoch:  9540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001120137533284126\n",
      "-----Epoch:  9550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011188785064494954\n",
      "-----Epoch:  9560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011176222996418955\n",
      "-----Epoch:  9570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001116368903415977\n",
      "-----Epoch:  9580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001115118308368535\n",
      "-----Epoch:  9590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001113870505138106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  9600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011126254844049115\n",
      "-----Epoch:  9610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.00111138323689051\n",
      "-----Epoch:  9620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001110143753357552\n",
      "-----Epoch:  9630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011089070246096983\n",
      "-----Epoch:  9640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011076730414912629\n",
      "-----Epoch:  9650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011064417948870003\n",
      "-----Epoch:  9660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001105213275721925\n",
      "-----Epoch:  9670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011039874749610094\n",
      "-----Epoch:  9680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011027643836092045\n",
      "-----Epoch:  9690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0011015439927108143\n",
      "-----Epoch:  9700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001100326293349696\n",
      "-----Epoch:  9710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010991112766486997\n",
      "-----Epoch:  9720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010978989337697236\n",
      "-----Epoch:  9730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010966892559133227\n",
      "-----Epoch:  9740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010954822343186518\n",
      "-----Epoch:  9750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010942778602630065\n",
      "-----Epoch:  9760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001093076125061945\n",
      "-----Epoch:  9770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010918770200687518\n",
      "-----Epoch:  9780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001090680536674537\n",
      "-----Epoch:  9790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010894866663077429\n",
      "-----Epoch:  9800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010882954004342125\n",
      "-----Epoch:  9810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010871067305567729\n",
      "-----Epoch:  9820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010859206482151025\n",
      "-----Epoch:  9830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001084737144985628\n",
      "-----Epoch:  9840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010835562124811668\n",
      "-----Epoch:  9850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010823778423508154\n",
      "-----Epoch:  9860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001081202026279813\n",
      "-----Epoch:  9870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010800287559892064\n",
      "-----Epoch:  9880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010788580232357712\n",
      "-----Epoch:  9890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010776898198117761\n",
      "-----Epoch:  9900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001076524137544759\n",
      "-----Epoch:  9910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001075360968297436\n",
      "-----Epoch:  9920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010742003039674118\n",
      "-----Epoch:  9930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001073042136486988\n",
      "-----Epoch:  9940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010718864578231396\n",
      "-----Epoch:  9950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010707332599770912\n",
      "-----Epoch:  9960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010695825349843486\n",
      "-----Epoch:  9970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.001068434274914375\n",
      "-----Epoch:  9980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010672884718704995\n",
      "-----Epoch:  9990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.0010661451179895722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbb826cc7c0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TRAINING THE XOR FUNCTION\n",
    "\n",
    "x_train = np.array([[0, 0, 1, 1], \n",
    "                    [0, 1, 0, 1]]) # 2 inputs and 4 samples, i.e 2x4\n",
    "y_train = np.array([0, 1, 1, 0]) #1 x num of samples\n",
    "Xor_net = NeuralNet('binary_logloss')\n",
    "Xor_net.addLayer(3, 'tanh')\n",
    "Xor_net.addLayer(1, 'sigmoid')\n",
    "costs, weights = Xor_net.fit(x_train, y_train, 10000)\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the XOR b/w 1 and 0 is: 1\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[1], [0]])\n",
    "pred = 1 if Xor_net.predict(test) else 0\n",
    "print(\"The result of the XOR b/w 1 and 0 is:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  0 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.5772546711774026\n",
      "-----Epoch:  10 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.5064167488078243\n",
      "-----Epoch:  20 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.4917029514150847\n",
      "-----Epoch:  30 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.47855196314403803\n",
      "-----Epoch:  40 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.46660286813585083\n",
      "-----Epoch:  50 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.45570163003566677\n",
      "-----Epoch:  60 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.44571594405906495\n",
      "-----Epoch:  70 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.43653216611131773\n",
      "-----Epoch:  80 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.42805280669845464\n",
      "-----Epoch:  90 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.4201942474782794\n",
      "-----Epoch:  100 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.41288471335523175\n",
      "-----Epoch:  110 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.4060625047765052\n",
      "-----Epoch:  120 -----\n",
      "Accuracy: 0.0\n",
      "Cost: 0.39967447675632434\n",
      "-----Epoch:  130 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3936747419178984\n",
      "-----Epoch:  140 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.38802357127114795\n",
      "-----Epoch:  150 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.38268646623094843\n",
      "-----Epoch:  160 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3776333770005719\n",
      "-----Epoch:  170 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.37283804493675565\n",
      "-----Epoch:  180 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3682774492979583\n",
      "-----Epoch:  190 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3639313415277083\n",
      "-----Epoch:  200 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.35978185276993024\n",
      "-----Epoch:  210 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.35581316257787665\n",
      "-----Epoch:  220 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3520112187434208\n",
      "-----Epoch:  230 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.34836349984995774\n",
      "-----Epoch:  240 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.344858813565845\n",
      "-----Epoch:  250 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3414871248779083\n",
      "-----Epoch:  260 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.33823940944842645\n",
      "-----Epoch:  270 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.33510752809468025\n",
      "-----Epoch:  280 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3320841190648727\n",
      "-----Epoch:  290 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3291625053417316\n",
      "-----Epoch:  300 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.32633661466561026\n",
      "-----Epoch:  310 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.32360091034936966\n",
      "-----Epoch:  320 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3209503312719459\n",
      "-----Epoch:  330 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.31838023969793006\n",
      "-----Epoch:  340 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.31588637578640394\n",
      "-----Epoch:  350 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.31346481783154573\n",
      "-----Epoch:  360 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.31111194742667525\n",
      "-----Epoch:  370 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.30882441886772005\n",
      "-----Epoch:  380 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.30659913221592827\n",
      "-----Epoch:  390 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.3044332095265698\n",
      "-----Epoch:  400 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.30232397382328274\n",
      "-----Epoch:  410 -----\n",
      "Accuracy: 0.125\n",
      "Cost: 0.30026893045902425\n",
      "-----Epoch:  420 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2982657505562425\n",
      "-----Epoch:  430 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2963122562625043\n",
      "-----Epoch:  440 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.29440640759474546\n",
      "-----Epoch:  450 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.29254629067662724\n",
      "-----Epoch:  460 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.29073010720011405\n",
      "-----Epoch:  470 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2889561649650814\n",
      "-----Epoch:  480 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.28722286937013347\n",
      "-----Epoch:  490 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2855287157443948\n",
      "-----Epoch:  500 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2838722824242543\n",
      "-----Epoch:  510 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.28225222449126147\n",
      "-----Epoch:  520 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2806672680978945\n",
      "-----Epoch:  530 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2791162053169947\n",
      "-----Epoch:  540 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2775978894585119\n",
      "-----Epoch:  550 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2761112308040022\n",
      "-----Epoch:  560 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.27465519271521777\n",
      "-----Epoch:  570 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2732287880782572\n",
      "-----Epoch:  580 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.27183107604921275\n",
      "-----Epoch:  590 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.27046115907114826\n",
      "-----Epoch:  600 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2691181801356516\n",
      "-----Epoch:  610 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.26780132026518516\n",
      "-----Epoch:  620 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.26650979619508036\n",
      "-----Epoch:  630 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.26524285823631666\n",
      "-----Epoch:  640 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2639997883022539\n",
      "-----Epoch:  650 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.26277989808426566\n",
      "-----Epoch:  660 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.26158252736280135\n",
      "-----Epoch:  670 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.26040704244179214\n",
      "-----Epoch:  680 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2592528346955514\n",
      "-----Epoch:  690 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2581193192184134\n",
      "-----Epoch:  700 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2570059335683247\n",
      "-----Epoch:  710 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.25591213659646456\n",
      "-----Epoch:  720 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.25483740735574467\n",
      "-----Epoch:  730 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.25378124408171726\n",
      "-----Epoch:  740 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.25274316324004004\n",
      "-----Epoch:  750 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.25172269863519015\n",
      "-----Epoch:  760 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.250719400575611\n",
      "-----Epoch:  770 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24973283509091504\n",
      "-----Epoch:  780 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24876258319716263\n",
      "-----Epoch:  790 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24780824020658773\n",
      "-----Epoch:  800 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2468694150784641\n",
      "-----Epoch:  810 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24594572980809304\n",
      "-----Epoch:  820 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24503681885115045\n",
      "-----Epoch:  830 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.244142328580869\n",
      "-----Epoch:  840 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2432619167757399\n",
      "-----Epoch:  850 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24239525213561383\n",
      "-----Epoch:  860 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.24154201382425067\n",
      "-----Epoch:  870 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2407018910365297\n",
      "-----Epoch:  880 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2398745825886707\n",
      "-----Epoch:  890 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23905979652994952\n",
      "-----Epoch:  900 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2382572497745105\n",
      "-----Epoch:  910 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2374666677519838\n",
      "-----Epoch:  920 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23668778407571459\n",
      "-----Epoch:  930 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23592034022750435\n",
      "-----Epoch:  940 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23516408525784138\n",
      "-----Epoch:  950 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23441877550067716\n",
      "-----Epoch:  960 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23368417430187105\n",
      "-----Epoch:  970 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2329600517604906\n",
      "-----Epoch:  980 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23224618448221357\n",
      "-----Epoch:  990 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23154235534412512\n",
      "-----Epoch:  1000 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2308483532702621\n",
      "-----Epoch:  1010 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.23016397301729158\n",
      "-----Epoch:  1020 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22948901496975838\n",
      "-----Epoch:  1030 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22882328494437215\n",
      "-----Epoch:  1040 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22816659400283934\n",
      "-----Epoch:  1050 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22751875827277976\n",
      "-----Epoch:  1060 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2268795987762943\n",
      "-----Epoch:  1070 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22624894126578138\n",
      "-----Epoch:  1080 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22562661606662365\n",
      "-----Epoch:  1090 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22501245792638935\n",
      "-----Epoch:  1100 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22440630587021715\n",
      "-----Epoch:  1110 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22380800306207183\n",
      "-----Epoch:  1120 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2232173966715772\n",
      "-----Epoch:  1130 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22263433774615163\n",
      "-----Epoch:  1140 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22205868108818666\n",
      "-----Epoch:  1150 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22149028513702473\n",
      "-----Epoch:  1160 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.22092901185550606\n",
      "-----Epoch:  1170 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2203747266208696\n",
      "-----Epoch:  1180 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2198272981198015\n",
      "-----Epoch:  1190 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.2192865982474418\n",
      "-----Epoch:  1200 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.21875250201016333\n",
      "-----Epoch:  1210 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.21822488743195573\n",
      "-----Epoch:  1220 -----\n",
      "Accuracy: 0.25\n",
      "Cost: 0.21770363546424779\n",
      "-----Epoch:  1230 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2171886298990177\n",
      "-----Epoch:  1240 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2166797572850445\n",
      "-----Epoch:  1250 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2161769068471623\n",
      "-----Epoch:  1260 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.215679970408389\n",
      "-----Epoch:  1270 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21518884231480417\n",
      "-----Epoch:  1280 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2147034193630588\n",
      "-----Epoch:  1290 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21422360073040658\n",
      "-----Epoch:  1300 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21374928790715142\n",
      "-----Epoch:  1310 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2132803846314083\n",
      "-----Epoch:  1320 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2128167968260859\n",
      "-----Epoch:  1330 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2123584325379965\n",
      "-----Epoch:  1340 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21190520187901063\n",
      "-----Epoch:  1350 -----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.375\n",
      "Cost: 0.21145701696917027\n",
      "-----Epoch:  1360 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2110137918816867\n",
      "-----Epoch:  1370 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21057544258974523\n",
      "-----Epoch:  1380 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.21014188691504754\n",
      "-----Epoch:  1390 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20971304447802389\n",
      "-----Epoch:  1400 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20928883664964945\n",
      "-----Epoch:  1410 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20886918650480557\n",
      "-----Epoch:  1420 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20845401877712427\n",
      "-----Epoch:  1430 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20804325981526253\n",
      "-----Epoch:  1440 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20763683754055118\n",
      "-----Epoch:  1450 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20723468140596732\n",
      "-----Epoch:  1460 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20683672235638242\n",
      "-----Epoch:  1470 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20644289279003775\n",
      "-----Epoch:  1480 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20605312652120303\n",
      "-----Epoch:  1490 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20566735874397601\n",
      "-----Epoch:  1500 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.205285525997181\n",
      "-----Epoch:  1510 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20490756613032737\n",
      "-----Epoch:  1520 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20453341827059052\n",
      "-----Epoch:  1530 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20416302279077905\n",
      "-----Epoch:  1540 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20379632127825342\n",
      "-----Epoch:  1550 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20343325650476385\n",
      "-----Epoch:  1560 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2030737723971735\n",
      "-----Epoch:  1570 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20271781400903965\n",
      "-----Epoch:  1580 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20236532749301986\n",
      "-----Epoch:  1590 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20201626007407808\n",
      "-----Epoch:  1600 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20167056002346218\n",
      "-----Epoch:  1610 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20132817663342692\n",
      "-----Epoch:  1620 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20098906019267773\n",
      "-----Epoch:  1630 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.2006531619625124\n",
      "-----Epoch:  1640 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.20032043415363462\n",
      "-----Epoch:  1650 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19999082990362094\n",
      "-----Epoch:  1660 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1996643032550175\n",
      "-----Epoch:  1670 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19934080913404625\n",
      "-----Epoch:  1680 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19902030332990178\n",
      "-----Epoch:  1690 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19870274247461872\n",
      "-----Epoch:  1700 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19838808402349312\n",
      "-----Epoch:  1710 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1980762862360372\n",
      "-----Epoch:  1720 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19776730815745458\n",
      "-----Epoch:  1730 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19746110960061555\n",
      "-----Epoch:  1740 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19715765112852\n",
      "-----Epoch:  1750 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19685689403722992\n",
      "-----Epoch:  1760 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19655880033926001\n",
      "-----Epoch:  1770 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19626333274740893\n",
      "-----Epoch:  1780 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19597045465902027\n",
      "-----Epoch:  1790 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19568013014065877\n",
      "-----Epoch:  1800 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1953923239131892\n",
      "-----Epoch:  1810 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19510700133724646\n",
      "-----Epoch:  1820 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19482412839908383\n",
      "-----Epoch:  1830 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19454367169678938\n",
      "-----Epoch:  1840 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19426559842685842\n",
      "-----Epoch:  1850 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19398987637111206\n",
      "-----Epoch:  1860 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19371647388395097\n",
      "-----Epoch:  1870 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1934453598799356\n",
      "-----Epoch:  1880 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19317650382168192\n",
      "-----Epoch:  1890 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1929098757080638\n",
      "-----Epoch:  1900 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19264544606271428\n",
      "-----Epoch:  1910 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1923831859228154\n",
      "-----Epoch:  1920 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1921230668281685\n",
      "-----Epoch:  1930 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1918650608105386\n",
      "-----Epoch:  1940 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19160914038326285\n",
      "-----Epoch:  1950 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19135527853111664\n",
      "-----Epoch:  1960 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1911034487004299\n",
      "-----Epoch:  1970 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19085362478944623\n",
      "-----Epoch:  1980 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1906057811389188\n",
      "-----Epoch:  1990 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19035989252293495\n",
      "-----Epoch:  2000 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.19011593413996442\n",
      "-----Epoch:  2010 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.18987388160412438\n",
      "-----Epoch:  2020 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.18963371093665582\n",
      "-----Epoch:  2030 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.1893953985576033\n",
      "-----Epoch:  2040 -----\n",
      "Accuracy: 0.375\n",
      "Cost: 0.18915892127769685\n",
      "-----Epoch:  2050 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18892425629042467\n",
      "-----Epoch:  2060 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1886913811642976\n",
      "-----Epoch:  2070 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18846027383529376\n",
      "-----Epoch:  2080 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18823091259948468\n",
      "-----Epoch:  2090 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18800327610583312\n",
      "-----Epoch:  2100 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18777734334916094\n",
      "-----Epoch:  2110 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18755309366328038\n",
      "-----Epoch:  2120 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1873305067142867\n",
      "-----Epoch:  2130 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18710956249400545\n",
      "-----Epoch:  2140 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18689024131359205\n",
      "-----Epoch:  2150 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18667252379727856\n",
      "-----Epoch:  2160 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1864563908762645\n",
      "-----Epoch:  2170 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18624182378274745\n",
      "-----Epoch:  2180 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18602880404408986\n",
      "-----Epoch:  2190 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18581731347711916\n",
      "-----Epoch:  2200 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18560733418255593\n",
      "-----Epoch:  2210 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18539884853956926\n",
      "-----Epoch:  2220 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.185191839200454\n",
      "-----Epoch:  2230 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18498628908542794\n",
      "-----Epoch:  2240 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18478218137754512\n",
      "-----Epoch:  2250 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1845794995177224\n",
      "-----Epoch:  2260 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1843782271998776\n",
      "-----Epoch:  2270 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18417834836617406\n",
      "-----Epoch:  2280 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18397984720237104\n",
      "-----Epoch:  2290 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1837827081332764\n",
      "-----Epoch:  2300 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18358691581829892\n",
      "-----Epoch:  2310 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18339245514709776\n",
      "-----Epoch:  2320 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1831993112353275\n",
      "-----Epoch:  2330 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18300746942047447\n",
      "-----Epoch:  2340 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18281691525778443\n",
      "-----Epoch:  2350 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1826276345162776\n",
      "-----Epoch:  2360 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18243961317484958\n",
      "-----Epoch:  2370 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.182252837418456\n",
      "-----Epoch:  2380 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18206729363437887\n",
      "-----Epoch:  2390 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18188296840857232\n",
      "-----Epoch:  2400 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18169984852208604\n",
      "-----Epoch:  2410 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18151792094756497\n",
      "-----Epoch:  2420 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18133717284582274\n",
      "-----Epoch:  2430 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18115759156248634\n",
      "-----Epoch:  2440 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18097916462471286\n",
      "-----Epoch:  2450 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.180801879737974\n",
      "-----Epoch:  2460 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1806257247829074\n",
      "-----Epoch:  2470 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.1804506878122348\n",
      "-----Epoch:  2480 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18027675704774215\n",
      "-----Epoch:  2490 -----\n",
      "Accuracy: 0.5\n",
      "Cost: 0.18010392087732396\n",
      "-----Epoch:  2500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1799321678520877\n",
      "-----Epoch:  2510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17976148668351788\n",
      "-----Epoch:  2520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17959186624069826\n",
      "-----Epoch:  2530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17942329554759018\n",
      "-----Epoch:  2540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17925576378036834\n",
      "-----Epoch:  2550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17908926026480765\n",
      "-----Epoch:  2560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17892377447372562\n",
      "-----Epoch:  2570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17875929602447496\n",
      "-----Epoch:  2580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17859581467648722\n",
      "-----Epoch:  2590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1784333203288651\n",
      "-----Epoch:  2600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17827180301802384\n",
      "-----Epoch:  2610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1781112529153789\n",
      "-----Epoch:  2620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1779516603250799\n",
      "-----Epoch:  2630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17779301568178918\n",
      "-----Epoch:  2640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1776353095485056\n",
      "-----Epoch:  2650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17747853261442878\n",
      "-----Epoch:  2660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17732267569286772\n",
      "-----Epoch:  2670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17716772971918915\n",
      "-----Epoch:  2680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17701368574880616\n",
      "-----Epoch:  2690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17686053495520612\n",
      "-----Epoch:  2700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17670826862801708\n",
      "-----Epoch:  2710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17655687817111135\n",
      "-----Epoch:  2720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1764063551007452\n",
      "-----Epoch:  2730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17625669104373648\n",
      "-----Epoch:  2740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17610787773567405\n",
      "-----Epoch:  2750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1759599070191642\n",
      "-----Epoch:  2760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17581277084210883\n",
      "-----Epoch:  2770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17566646125601826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  2780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17552097041435355\n",
      "-----Epoch:  2790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17537629057090245\n",
      "-----Epoch:  2800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17523241407818513\n",
      "-----Epoch:  2810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1750893333858893\n",
      "-----Epoch:  2820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1749470410393362\n",
      "-----Epoch:  2830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17480552967797347\n",
      "-----Epoch:  2840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1746647920338978\n",
      "-----Epoch:  2850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1745248209304041\n",
      "-----Epoch:  2860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1743856092805622\n",
      "-----Epoch:  2870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1742471500858193\n",
      "-----Epoch:  2880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17410943643462803\n",
      "-----Epoch:  2890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17397246150110113\n",
      "-----Epoch:  2900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17383621854368966\n",
      "-----Epoch:  2910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17370070090388473\n",
      "-----Epoch:  2920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17356590200494537\n",
      "-----Epoch:  2930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17343181535064667\n",
      "-----Epoch:  2940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17329843452405272\n",
      "-----Epoch:  2950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17316575318631133\n",
      "-----Epoch:  2960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17303376507546878\n",
      "-----Epoch:  2970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17290246400530915\n",
      "-----Epoch:  2980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17277184386421163\n",
      "-----Epoch:  2990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1726418986140291\n",
      "-----Epoch:  3000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17251262228898823\n",
      "-----Epoch:  3010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17238400899460643\n",
      "-----Epoch:  3020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17225605290663018\n",
      "-----Epoch:  3030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17212874826999158\n",
      "-----Epoch:  3040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17200208939778344\n",
      "-----Epoch:  3050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1718760706702513\n",
      "-----Epoch:  3060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17175068653380482\n",
      "-----Epoch:  3070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17162593150004557\n",
      "-----Epoch:  3080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17150180014481187\n",
      "-----Epoch:  3090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17137828710724043\n",
      "-----Epoch:  3100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17125538708884433\n",
      "-----Epoch:  3110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1711330948526063\n",
      "-----Epoch:  3120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1710114052220896\n",
      "-----Epoch:  3130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17089031308056116\n",
      "-----Epoch:  3140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17076981337013275\n",
      "-----Epoch:  3150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17064990109091507\n",
      "-----Epoch:  3160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17053057130018742\n",
      "-----Epoch:  3170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1704118191115802\n",
      "-----Epoch:  3180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17029363969427247\n",
      "-----Epoch:  3190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17017602827220318\n",
      "-----Epoch:  3200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.17005898012329462\n",
      "-----Epoch:  3210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16994249057869026\n",
      "-----Epoch:  3220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1698265550220041\n",
      "-----Epoch:  3230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1697111688885845\n",
      "-----Epoch:  3240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16959632766478794\n",
      "-----Epoch:  3250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1694820268872668\n",
      "-----Epoch:  3260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16936826214226858\n",
      "-----Epoch:  3270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.169255029064946\n",
      "-----Epoch:  3280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1691423233386797\n",
      "-----Epoch:  3290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1690301406944104\n",
      "-----Epoch:  3300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1689184769099848\n",
      "-----Epoch:  3310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1688073278095093\n",
      "-----Epoch:  3320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16869668926271597\n",
      "-----Epoch:  3330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1685865571843389\n",
      "-----Epoch:  3340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16847692753349985\n",
      "-----Epoch:  3350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16836779631310508\n",
      "-----Epoch:  3360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16825915956925067\n",
      "-----Epoch:  3370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1681510133906384\n",
      "-----Epoch:  3380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16804335390800076\n",
      "-----Epoch:  3390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16793617729353547\n",
      "-----Epoch:  3400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1678294797603481\n",
      "-----Epoch:  3410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16772325756190543\n",
      "-----Epoch:  3420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16761750699149588\n",
      "-----Epoch:  3430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16751222438169877\n",
      "-----Epoch:  3440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16740740610386323\n",
      "-----Epoch:  3450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16730304856759443\n",
      "-----Epoch:  3460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16719914822024728\n",
      "-----Epoch:  3470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16709570154642997\n",
      "-----Epoch:  3480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16699270506751326\n",
      "-----Epoch:  3490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16689015534114923\n",
      "-----Epoch:  3500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16678804896079666\n",
      "-----Epoch:  3510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1666863825552537\n",
      "-----Epoch:  3520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16658515278819838\n",
      "-----Epoch:  3530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16648435635773587\n",
      "-----Epoch:  3540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16638398999595308\n",
      "-----Epoch:  3550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16628405046847972\n",
      "-----Epoch:  3560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16618453457405621\n",
      "-----Epoch:  3570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.166085439144109\n",
      "-----Epoch:  3580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16598676104233157\n",
      "-----Epoch:  3590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16588849716427176\n",
      "-----Epoch:  3600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1657906444369261\n",
      "-----Epoch:  3610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16569319981834\n",
      "-----Epoch:  3620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16559616029721388\n",
      "-----Epoch:  3630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1654995228925151\n",
      "-----Epoch:  3640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16540328465309675\n",
      "-----Epoch:  3650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1653074426573208\n",
      "-----Epoch:  3660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16521199401268802\n",
      "-----Epoch:  3670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1651169358554731\n",
      "-----Epoch:  3680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16502226535036485\n",
      "-----Epoch:  3690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16492797969011241\n",
      "-----Epoch:  3700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16483407609517653\n",
      "-----Epoch:  3710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16474055181338576\n",
      "-----Epoch:  3720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16464740411959813\n",
      "-----Epoch:  3730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16455463031536718\n",
      "-----Epoch:  3740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16446222772861444\n",
      "-----Epoch:  3750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16437019371330472\n",
      "-----Epoch:  3760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16427852564912726\n",
      "-----Epoch:  3770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16418722094118215\n",
      "-----Epoch:  3780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1640962770196701\n",
      "-----Epoch:  3790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1640056913395872\n",
      "-----Epoch:  3800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16391546138042448\n",
      "-----Epoch:  3810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16382558464587166\n",
      "-----Epoch:  3820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1637360586635246\n",
      "-----Epoch:  3830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16364688098459818\n",
      "-----Epoch:  3840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16355804918364172\n",
      "-----Epoch:  3850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16346956085826075\n",
      "-----Epoch:  3860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16338141362883954\n",
      "-----Epoch:  3870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1632936051382714\n",
      "-----Epoch:  3880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16320613305168985\n",
      "-----Epoch:  3890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16311899505620459\n",
      "-----Epoch:  3900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16303218886064214\n",
      "-----Epoch:  3910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16294571219528875\n",
      "-----Epoch:  3920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16285956281163727\n",
      "-----Epoch:  3930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1627737384821391\n",
      "-----Epoch:  3940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16268823699995674\n",
      "-----Epoch:  3950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16260305617872314\n",
      "-----Epoch:  3960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16251819385230154\n",
      "-----Epoch:  3970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16243364787455045\n",
      "-----Epoch:  3980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1623494161190916\n",
      "-----Epoch:  3990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16226549647908045\n",
      "-----Epoch:  4000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16218188686698054\n",
      "-----Epoch:  4010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16209858521434073\n",
      "-----Epoch:  4020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16201558947157563\n",
      "-----Epoch:  4030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16193289760774895\n",
      "-----Epoch:  4040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16185050761035996\n",
      "-----Epoch:  4050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1617684174851327\n",
      "-----Epoch:  4060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16168662525580818\n",
      "-----Epoch:  4070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1616051289639397\n",
      "-----Epoch:  4080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1615239266686903\n",
      "-----Epoch:  4090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16144301644663342\n",
      "-----Epoch:  4100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16136239639155656\n",
      "-----Epoch:  4110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1612820646142672\n",
      "-----Epoch:  4120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16120201924240085\n",
      "-----Epoch:  4130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1611222584202329\n",
      "-----Epoch:  4140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16104278030849214\n",
      "-----Epoch:  4150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1609635830841765\n",
      "-----Epoch:  4160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16088466494037282\n",
      "-----Epoch:  4170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16080602408607714\n",
      "-----Epoch:  4180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16072765874601827\n",
      "-----Epoch:  4190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16064956716048387\n",
      "-----Epoch:  4200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16057174758514892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  4210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1604941982909053\n",
      "-----Epoch:  4220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16041691756369547\n",
      "-----Epoch:  4230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16033990370434678\n",
      "-----Epoch:  4240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1602631550284086\n",
      "-----Epoch:  4250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16018666986599223\n",
      "-----Epoch:  4260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16011044656161097\n",
      "-----Epoch:  4270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.16003448347402496\n",
      "-----Epoch:  4280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15995877897608515\n",
      "-----Epoch:  4290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15988333145458233\n",
      "-----Epoch:  4300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15980813931009552\n",
      "-----Epoch:  4310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15973320095684343\n",
      "-----Epoch:  4320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15965851482253862\n",
      "-----Epoch:  4330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15958407934824184\n",
      "-----Epoch:  4340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1595098929882195\n",
      "-----Epoch:  4350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1594359542098026\n",
      "-----Epoch:  4360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15936226149324742\n",
      "-----Epoch:  4370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15928881333159806\n",
      "-----Epoch:  4380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15921560823055117\n",
      "-----Epoch:  4390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15914264470832107\n",
      "-----Epoch:  4400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15906992129550804\n",
      "-----Epoch:  4410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.158997436534968\n",
      "-----Epoch:  4420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15892518898168279\n",
      "-----Epoch:  4430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1588531772026338\n",
      "-----Epoch:  4440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15878139977667538\n",
      "-----Epoch:  4450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1587098552944115\n",
      "-----Epoch:  4460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15863854235807237\n",
      "-----Epoch:  4470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1585674595813942\n",
      "-----Epoch:  4480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15849660558949952\n",
      "-----Epoch:  4490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15842597901877853\n",
      "-----Epoch:  4500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15835557851677368\n",
      "-----Epoch:  4510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15828540274206346\n",
      "-----Epoch:  4520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15821545036414975\n",
      "-----Epoch:  4530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15814572006334437\n",
      "-----Epoch:  4540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15807621053065965\n",
      "-----Epoch:  4550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15800692046769765\n",
      "-----Epoch:  4560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1579378485865428\n",
      "-----Epoch:  4570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15786899360965478\n",
      "-----Epoch:  4580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15780035426976308\n",
      "-----Epoch:  4590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15773192930976276\n",
      "-----Epoch:  4600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15766371748261165\n",
      "-----Epoch:  4610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15759571755122828\n",
      "-----Epoch:  4620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1575279282883918\n",
      "-----Epoch:  4630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15746034847664248\n",
      "-----Epoch:  4640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15739297690818385\n",
      "-----Epoch:  4650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1573258123847861\n",
      "-----Epoch:  4660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15725885371768966\n",
      "-----Epoch:  4670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15719209972751141\n",
      "-----Epoch:  4680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15712554924415068\n",
      "-----Epoch:  4690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15705920110669758\n",
      "-----Epoch:  4700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15699305416334133\n",
      "-----Epoch:  4710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15692710727128056\n",
      "-----Epoch:  4720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1568613592966341\n",
      "-----Epoch:  4730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.156795809114353\n",
      "-----Epoch:  4740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15673045560813348\n",
      "-----Epoch:  4750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15666529767033147\n",
      "-----Epoch:  4760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15660033420187747\n",
      "-----Epoch:  4770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1565355641121928\n",
      "-----Epoch:  4780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15647098631910678\n",
      "-----Epoch:  4790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15640659974877424\n",
      "-----Epoch:  4800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15634240333559585\n",
      "-----Epoch:  4810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1562783960221366\n",
      "-----Epoch:  4820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15621457675904782\n",
      "-----Epoch:  4830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15615094450498868\n",
      "-----Epoch:  4840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1560874982265492\n",
      "-----Epoch:  4850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15602423689817344\n",
      "-----Epoch:  4860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15596115950208445\n",
      "-----Epoch:  4870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15589826502820944\n",
      "-----Epoch:  4880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1558355524741067\n",
      "-----Epoch:  4890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15577302084489153\n",
      "-----Epoch:  4900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1557106691531656\n",
      "-----Epoch:  4910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.155648496418945\n",
      "-----Epoch:  4920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15558650166958932\n",
      "-----Epoch:  4930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15552468393973357\n",
      "-----Epoch:  4940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1554630422712182\n",
      "-----Epoch:  4950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15540157571302127\n",
      "-----Epoch:  4960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15534028332119149\n",
      "-----Epoch:  4970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15527916415878196\n",
      "-----Epoch:  4980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1552182172957838\n",
      "-----Epoch:  4990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15515744180906169\n",
      "-----Epoch:  5000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15509683678228964\n",
      "-----Epoch:  5010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1550364013058872\n",
      "-----Epoch:  5020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15497613447695666\n",
      "-----Epoch:  5030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1549160353992212\n",
      "-----Epoch:  5040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1548561031829638\n",
      "-----Epoch:  5050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15479633694496542\n",
      "-----Epoch:  5060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15473673580844627\n",
      "-----Epoch:  5070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1546772989030054\n",
      "-----Epoch:  5080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15461802536456273\n",
      "-----Epoch:  5090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15455891433530053\n",
      "-----Epoch:  5100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15449996496360627\n",
      "-----Epoch:  5110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15444117640401578\n",
      "-----Epoch:  5120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15438254781715696\n",
      "-----Epoch:  5130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15432407836969447\n",
      "-----Epoch:  5140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15426576723427454\n",
      "-----Epoch:  5150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15420761358947102\n",
      "-----Epoch:  5160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15414961661973128\n",
      "-----Epoch:  5170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15409177551532324\n",
      "-----Epoch:  5180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1540340894722828\n",
      "-----Epoch:  5190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15397655769236207\n",
      "-----Epoch:  5200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1539191793829772\n",
      "-----Epoch:  5210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1538619537571586\n",
      "-----Epoch:  5220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15380488003349987\n",
      "-----Epoch:  5230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15374795743610803\n",
      "-----Epoch:  5240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1536911851945547\n",
      "-----Epoch:  5250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15363456254382712\n",
      "-----Epoch:  5260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15357808872428014\n",
      "-----Epoch:  5270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15352176298158826\n",
      "-----Epoch:  5280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15346558456669876\n",
      "-----Epoch:  5290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15340955273578488\n",
      "-----Epoch:  5300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15335366675019976\n",
      "-----Epoch:  5310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15329792587643098\n",
      "-----Epoch:  5320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1532423293860549\n",
      "-----Epoch:  5330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1531868765556923\n",
      "-----Epoch:  5340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15313156666696393\n",
      "-----Epoch:  5350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15307639900644732\n",
      "-----Epoch:  5360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1530213728656329\n",
      "-----Epoch:  5370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15296648754088113\n",
      "-----Epoch:  5380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15291174233338053\n",
      "-----Epoch:  5390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15285713654910552\n",
      "-----Epoch:  5400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15280266949877508\n",
      "-----Epoch:  5410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1527483404978112\n",
      "-----Epoch:  5420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1526941488662988\n",
      "-----Epoch:  5430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1526400939289453\n",
      "-----Epoch:  5440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1525861750150409\n",
      "-----Epoch:  5450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15253239145841885\n",
      "-----Epoch:  5460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15247874259741692\n",
      "-----Epoch:  5470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15242522777483858\n",
      "-----Epoch:  5480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15237184633791523\n",
      "-----Epoch:  5490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1523185976382674\n",
      "-----Epoch:  5500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15226548103186877\n",
      "-----Epoch:  5510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15221249587900793\n",
      "-----Epoch:  5520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1521596415442526\n",
      "-----Epoch:  5530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15210691739641272\n",
      "-----Epoch:  5540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15205432280850534\n",
      "-----Epoch:  5550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15200185715771808\n",
      "-----Epoch:  5560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15194951982537494\n",
      "-----Epoch:  5570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15189731019690136\n",
      "-----Epoch:  5580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15184522766178865\n",
      "-----Epoch:  5590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15179327161356176\n",
      "-----Epoch:  5600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15174144144974405\n",
      "-----Epoch:  5610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15168973657182439\n",
      "-----Epoch:  5620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15163815638522415\n",
      "-----Epoch:  5630 -----\n",
      "Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.15158670029926466\n",
      "-----Epoch:  5640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15153536772713405\n",
      "-----Epoch:  5650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.151484158085856\n",
      "-----Epoch:  5660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15143307079625756\n",
      "-----Epoch:  5670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15138210528293755\n",
      "-----Epoch:  5680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1513312609742363\n",
      "-----Epoch:  5690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15128053730220326\n",
      "-----Epoch:  5700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1512299337025681\n",
      "-----Epoch:  5710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15117944961470975\n",
      "-----Epoch:  5720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15112908448162626\n",
      "-----Epoch:  5730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15107883774990558\n",
      "-----Epoch:  5740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15102870886969627\n",
      "-----Epoch:  5750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15097869729467805\n",
      "-----Epoch:  5760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15092880248203372\n",
      "-----Epoch:  5770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15087902389241975\n",
      "-----Epoch:  5780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1508293609899392\n",
      "-----Epoch:  5790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15077981324211295\n",
      "-----Epoch:  5800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1507303801198525\n",
      "-----Epoch:  5810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1506810610974322\n",
      "-----Epoch:  5820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15063185565246273\n",
      "-----Epoch:  5830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15058276326586373\n",
      "-----Epoch:  5840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15053378342183762\n",
      "-----Epoch:  5850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1504849156078427\n",
      "-----Epoch:  5860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1504361593145682\n",
      "-----Epoch:  5870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15038751403590714\n",
      "-----Epoch:  5880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15033897926893147\n",
      "-----Epoch:  5890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1502905545138669\n",
      "-----Epoch:  5900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1502422392740675\n",
      "-----Epoch:  5910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15019403305599066\n",
      "-----Epoch:  5920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1501459353691733\n",
      "-----Epoch:  5930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1500979457262067\n",
      "-----Epoch:  5940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15005006364271256\n",
      "-----Epoch:  5950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.15000228863731938\n",
      "-----Epoch:  5960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1499546202316388\n",
      "-----Epoch:  5970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1499070579502417\n",
      "-----Epoch:  5980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14985960132063533\n",
      "-----Epoch:  5990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14981224987324043\n",
      "-----Epoch:  6000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14976500314136795\n",
      "-----Epoch:  6010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1497178606611969\n",
      "-----Epoch:  6020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14967082197175213\n",
      "-----Epoch:  6030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14962388661488166\n",
      "-----Epoch:  6040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14957705413523503\n",
      "-----Epoch:  6050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14953032408024192\n",
      "-----Epoch:  6060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14948369600008965\n",
      "-----Epoch:  6070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14943716944770277\n",
      "-----Epoch:  6080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14939074397872204\n",
      "-----Epoch:  6090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14934441915148225\n",
      "-----Epoch:  6100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1492981945269931\n",
      "-----Epoch:  6110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1492520696689177\n",
      "-----Epoch:  6120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14920604414355196\n",
      "-----Epoch:  6130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1491601175198052\n",
      "-----Epoch:  6140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14911428936918006\n",
      "-----Epoch:  6150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1490685592657522\n",
      "-----Epoch:  6160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14902292678615098\n",
      "-----Epoch:  6170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1489773915095401\n",
      "-----Epoch:  6180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1489319530175981\n",
      "-----Epoch:  6190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14888661089450023\n",
      "-----Epoch:  6200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14884136472689763\n",
      "-----Epoch:  6210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14879621410390045\n",
      "-----Epoch:  6220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14875115861705895\n",
      "-----Epoch:  6230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1487061978603437\n",
      "-----Epoch:  6240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14866133143012958\n",
      "-----Epoch:  6250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14861655892517575\n",
      "-----Epoch:  6260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14857187994660934\n",
      "-----Epoch:  6270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14852729409790608\n",
      "-----Epoch:  6280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14848280098487435\n",
      "-----Epoch:  6290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14843840021563678\n",
      "-----Epoch:  6300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14839409140061352\n",
      "-----Epoch:  6310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14834987415250436\n",
      "-----Epoch:  6320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14830574808627298\n",
      "-----Epoch:  6330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14826171281912895\n",
      "-----Epoch:  6340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1482177679705122\n",
      "-----Epoch:  6350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14817391316207554\n",
      "-----Epoch:  6360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14813014801766874\n",
      "-----Epoch:  6370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14808647216332288\n",
      "-----Epoch:  6380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14804288522723316\n",
      "-----Epoch:  6390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1479993868397441\n",
      "-----Epoch:  6400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14795597663333276\n",
      "-----Epoch:  6410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14791265424259412\n",
      "-----Epoch:  6420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14786941930422495\n",
      "-----Epoch:  6430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14782627145700836\n",
      "-----Epoch:  6440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14778321034179923\n",
      "-----Epoch:  6450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14774023560150823\n",
      "-----Epoch:  6460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14769734688108802\n",
      "-----Epoch:  6470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14765454382751728\n",
      "-----Epoch:  6480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14761182608978662\n",
      "-----Epoch:  6490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14756919331888393\n",
      "-----Epoch:  6500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14752664516778005\n",
      "-----Epoch:  6510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14748418129141427\n",
      "-----Epoch:  6520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14744180134668033\n",
      "-----Epoch:  6530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14739950499241206\n",
      "-----Epoch:  6540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14735729188936975\n",
      "-----Epoch:  6550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14731516170022627\n",
      "-----Epoch:  6560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1472731140895532\n",
      "-----Epoch:  6570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14723114872380766\n",
      "-----Epoch:  6580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14718926527131845\n",
      "-----Epoch:  6590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14714746340227286\n",
      "-----Epoch:  6600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14710574278870311\n",
      "-----Epoch:  6610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14706410310447401\n",
      "-----Epoch:  6620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14702254402526935\n",
      "-----Epoch:  6630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14698106522857915\n",
      "-----Epoch:  6640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1469396663936866\n",
      "-----Epoch:  6650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1468983472016563\n",
      "-----Epoch:  6660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14685710733532029\n",
      "-----Epoch:  6670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1468159464792672\n",
      "-----Epoch:  6680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14677486431982864\n",
      "-----Epoch:  6690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14673386054506732\n",
      "-----Epoch:  6700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14669293484476525\n",
      "-----Epoch:  6710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14665208691041115\n",
      "-----Epoch:  6720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14661131643518913\n",
      "-----Epoch:  6730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14657062311396646\n",
      "-----Epoch:  6740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14653000664328195\n",
      "-----Epoch:  6750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14648946672133392\n",
      "-----Epoch:  6760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1464490030479694\n",
      "-----Epoch:  6770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1464086153246725\n",
      "-----Epoch:  6780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14636830325455216\n",
      "-----Epoch:  6790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1463280665423324\n",
      "-----Epoch:  6800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14628790489433982\n",
      "-----Epoch:  6810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14624781801849368\n",
      "-----Epoch:  6820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1462078056242937\n",
      "-----Epoch:  6830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14616786742281035\n",
      "-----Epoch:  6840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14612800312667334\n",
      "-----Epoch:  6850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1460882124500612\n",
      "-----Epoch:  6860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14604849510869053\n",
      "-----Epoch:  6870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14600885081980572\n",
      "-----Epoch:  6880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14596927930216813\n",
      "-----Epoch:  6890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1459297802760462\n",
      "-----Epoch:  6900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14589035346320484\n",
      "-----Epoch:  6910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1458509985868954\n",
      "-----Epoch:  6920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14581171537184565\n",
      "-----Epoch:  6930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14577250354424923\n",
      "-----Epoch:  6940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14573336283175706\n",
      "-----Epoch:  6950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14569429296346545\n",
      "-----Epoch:  6960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14565529366990831\n",
      "-----Epoch:  6970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14561636468304662\n",
      "-----Epoch:  6980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14557750573625808\n",
      "-----Epoch:  6990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14553871656432926\n",
      "-----Epoch:  7000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1454999969034445\n",
      "-----Epoch:  7010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14546134649117776\n",
      "-----Epoch:  7020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14542276506648272\n",
      "-----Epoch:  7030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14538425236968325\n",
      "-----Epoch:  7040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14534580814246503\n",
      "-----Epoch:  7050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14530743212786626\n",
      "-----Epoch:  7060 -----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.625\n",
      "Cost: 0.1452691240702682\n",
      "-----Epoch:  7070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14523088371538653\n",
      "-----Epoch:  7080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14519271081026275\n",
      "-----Epoch:  7090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14515460510325498\n",
      "-----Epoch:  7100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14511656634402967\n",
      "-----Epoch:  7110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1450785942835522\n",
      "-----Epoch:  7120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14504068867407935\n",
      "-----Epoch:  7130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1450028492691498\n",
      "-----Epoch:  7140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1449650758235766\n",
      "-----Epoch:  7150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14492736809343787\n",
      "-----Epoch:  7160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14488972583606935\n",
      "-----Epoch:  7170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1448521488100555\n",
      "-----Epoch:  7180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14481463677522163\n",
      "-----Epoch:  7190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14477718949262586\n",
      "-----Epoch:  7200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1447398067245511\n",
      "-----Epoch:  7210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14470248823449666\n",
      "-----Epoch:  7220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14466523378717056\n",
      "-----Epoch:  7230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14462804314848188\n",
      "-----Epoch:  7240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14459091608553282\n",
      "-----Epoch:  7250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14455385236661103\n",
      "-----Epoch:  7260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14451685176118154\n",
      "-----Epoch:  7270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1444799140398799\n",
      "-----Epoch:  7280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14444303897450358\n",
      "-----Epoch:  7290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1444062263380058\n",
      "-----Epoch:  7300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14436947590448673\n",
      "-----Epoch:  7310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1443327874491872\n",
      "-----Epoch:  7320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14429616074848084\n",
      "-----Epoch:  7330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14425959557986665\n",
      "-----Epoch:  7340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14422309172196252\n",
      "-----Epoch:  7350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14418664895449715\n",
      "-----Epoch:  7360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1441502670583038\n",
      "-----Epoch:  7370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14411394581531273\n",
      "-----Epoch:  7380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14407768500854404\n",
      "-----Epoch:  7390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14404148442210168\n",
      "-----Epoch:  7400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14400534384116526\n",
      "-----Epoch:  7410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14396926305198463\n",
      "-----Epoch:  7420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14393324184187165\n",
      "-----Epoch:  7430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14389727999919452\n",
      "-----Epoch:  7440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14386137731337104\n",
      "-----Epoch:  7450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14382553357486133\n",
      "-----Epoch:  7460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14378974857516177\n",
      "-----Epoch:  7470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14375402210679847\n",
      "-----Epoch:  7480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14371835396332094\n",
      "-----Epoch:  7490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14368274393929467\n",
      "-----Epoch:  7500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14364719183029648\n",
      "-----Epoch:  7510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1436116974329064\n",
      "-----Epoch:  7520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14357626054470293\n",
      "-----Epoch:  7530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14354088096425566\n",
      "-----Epoch:  7540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14350555849111982\n",
      "-----Epoch:  7550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14347029292582955\n",
      "-----Epoch:  7560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1434350840698925\n",
      "-----Epoch:  7570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14339993172578333\n",
      "-----Epoch:  7580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14336483569693764\n",
      "-----Epoch:  7590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14332979578774618\n",
      "-----Epoch:  7600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14329481180354942\n",
      "-----Epoch:  7610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1432598835506308\n",
      "-----Epoch:  7620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1432250108362112\n",
      "-----Epoch:  7630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14319019346844353\n",
      "-----Epoch:  7640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1431554312564071\n",
      "-----Epoch:  7650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14312072401010079\n",
      "-----Epoch:  7660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1430860715404389\n",
      "-----Epoch:  7670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14305147365924467\n",
      "-----Epoch:  7680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14301693017924472\n",
      "-----Epoch:  7690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14298244091406379\n",
      "-----Epoch:  7700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14294800567821944\n",
      "-----Epoch:  7710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.142913624287116\n",
      "-----Epoch:  7720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14287929655703963\n",
      "-----Epoch:  7730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14284502230515303\n",
      "-----Epoch:  7740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1428108013494895\n",
      "-----Epoch:  7750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1427766335089485\n",
      "-----Epoch:  7760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14274251860329001\n",
      "-----Epoch:  7770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14270845645312905\n",
      "-----Epoch:  7780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1426744468799308\n",
      "-----Epoch:  7790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1426404897060057\n",
      "-----Epoch:  7800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14260658475450402\n",
      "-----Epoch:  7810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14257273184941074\n",
      "-----Epoch:  7820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14253893081554067\n",
      "-----Epoch:  7830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14250518147853397\n",
      "-----Epoch:  7840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14247148366484996\n",
      "-----Epoch:  7850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14243783720176367\n",
      "-----Epoch:  7860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14240424191735976\n",
      "-----Epoch:  7870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1423706976405287\n",
      "-----Epoch:  7880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14233720420096083\n",
      "-----Epoch:  7890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1423037614291429\n",
      "-----Epoch:  7900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14227036915635208\n",
      "-----Epoch:  7910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14223702721465217\n",
      "-----Epoch:  7920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14220373543688875\n",
      "-----Epoch:  7930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1421704936566838\n",
      "-----Epoch:  7940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14213730170843228\n",
      "-----Epoch:  7950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.142104159427297\n",
      "-----Epoch:  7960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14207106664920363\n",
      "-----Epoch:  7970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14203802321083692\n",
      "-----Epoch:  7980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14200502894963607\n",
      "-----Epoch:  7990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14197208370378991\n",
      "-----Epoch:  8000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14193918731223296\n",
      "-----Epoch:  8010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14190633961464083\n",
      "-----Epoch:  8020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14187354045142603\n",
      "-----Epoch:  8030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14184078966373306\n",
      "-----Epoch:  8040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14180808709343515\n",
      "-----Epoch:  8050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14177543258312944\n",
      "-----Epoch:  8060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14174282597613239\n",
      "-----Epoch:  8070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14171026711647625\n",
      "-----Epoch:  8080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14167775584890463\n",
      "-----Epoch:  8090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14164529201886836\n",
      "-----Epoch:  8100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14161287547252147\n",
      "-----Epoch:  8110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14158050605671682\n",
      "-----Epoch:  8120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14154818361900254\n",
      "-----Epoch:  8130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14151590800761757\n",
      "-----Epoch:  8140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.141483679071488\n",
      "-----Epoch:  8150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.141451496660223\n",
      "-----Epoch:  8160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14141936062411056\n",
      "-----Epoch:  8170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14138727081411426\n",
      "-----Epoch:  8180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14135522708186882\n",
      "-----Epoch:  8190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14132322927967625\n",
      "-----Epoch:  8200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14129127726050267\n",
      "-----Epoch:  8210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1412593708779736\n",
      "-----Epoch:  8220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14122750998637087\n",
      "-----Epoch:  8230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1411956944406287\n",
      "-----Epoch:  8240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1411639240963299\n",
      "-----Epoch:  8250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14113219880970215\n",
      "-----Epoch:  8260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1411005184376144\n",
      "-----Epoch:  8270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.141068882837573\n",
      "-----Epoch:  8280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1410372918677187\n",
      "-----Epoch:  8290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1410057453868226\n",
      "-----Epoch:  8300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14097424325428212\n",
      "-----Epoch:  8310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14094278533011875\n",
      "-----Epoch:  8320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14091137147497315\n",
      "-----Epoch:  8330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14088000155010258\n",
      "-----Epoch:  8340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14084867541737686\n",
      "-----Epoch:  8350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14081739293927523\n",
      "-----Epoch:  8360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14078615397888308\n",
      "-----Epoch:  8370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14075495839988825\n",
      "-----Epoch:  8380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14072380606657742\n",
      "-----Epoch:  8390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1406926968438336\n",
      "-----Epoch:  8400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14066163059713163\n",
      "-----Epoch:  8410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1406306071925362\n",
      "-----Epoch:  8420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1405996264966974\n",
      "-----Epoch:  8430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14056868837684802\n",
      "-----Epoch:  8440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1405377927008004\n",
      "-----Epoch:  8450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14050693933694275\n",
      "-----Epoch:  8460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14047612815423627\n",
      "-----Epoch:  8470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1404453590222122\n",
      "-----Epoch:  8480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14041463181096803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  8490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14038394639116505\n",
      "-----Epoch:  8500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1403533026340246\n",
      "-----Epoch:  8510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1403227004113255\n",
      "-----Epoch:  8520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14029213959540085\n",
      "-----Epoch:  8530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14026162005913453\n",
      "-----Epoch:  8540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14023114167595882\n",
      "-----Epoch:  8550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14020070431985113\n",
      "-----Epoch:  8560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.140170307865331\n",
      "-----Epoch:  8570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14013995218745676\n",
      "-----Epoch:  8580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.14010963716182312\n",
      "-----Epoch:  8590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1400793626645582\n",
      "-----Epoch:  8600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1400491285723205\n",
      "-----Epoch:  8610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1400189347622956\n",
      "-----Epoch:  8620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13998878111219418\n",
      "-----Epoch:  8630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1399586675002481\n",
      "-----Epoch:  8640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13992859380520822\n",
      "-----Epoch:  8650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.139898559906342\n",
      "-----Epoch:  8660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13986856568342945\n",
      "-----Epoch:  8670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1398386110167617\n",
      "-----Epoch:  8680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.139808695787137\n",
      "-----Epoch:  8690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13977881987585908\n",
      "-----Epoch:  8700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13974898316473347\n",
      "-----Epoch:  8710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13971918553606594\n",
      "-----Epoch:  8720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13968942687265826\n",
      "-----Epoch:  8730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13965970705780714\n",
      "-----Epoch:  8740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13963002597530025\n",
      "-----Epoch:  8750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1396003835094146\n",
      "-----Epoch:  8760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13957077954491312\n",
      "-----Epoch:  8770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13954121396704286\n",
      "-----Epoch:  8780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1395116866615311\n",
      "-----Epoch:  8790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1394821975145847\n",
      "-----Epoch:  8800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13945274641288571\n",
      "-----Epoch:  8810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13942333324358988\n",
      "-----Epoch:  8820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13939395789432402\n",
      "-----Epoch:  8830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1393646202531829\n",
      "-----Epoch:  8840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1393353202087275\n",
      "-----Epoch:  8850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13930605764998225\n",
      "-----Epoch:  8860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13927683246643238\n",
      "-----Epoch:  8870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13924764454802196\n",
      "-----Epoch:  8880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13921849378515092\n",
      "-----Epoch:  8890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13918938006867274\n",
      "-----Epoch:  8900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13916030328989276\n",
      "-----Epoch:  8910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13913126334056475\n",
      "-----Epoch:  8920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13910226011288934\n",
      "-----Epoch:  8930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13907329349951114\n",
      "-----Epoch:  8940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13904436339351703\n",
      "-----Epoch:  8950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13901546968843284\n",
      "-----Epoch:  8960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13898661227822237\n",
      "-----Epoch:  8970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13895779105728384\n",
      "-----Epoch:  8980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13892900592044863\n",
      "-----Epoch:  8990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13890025676297812\n",
      "-----Epoch:  9000 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1388715434805623\n",
      "-----Epoch:  9010 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13884286596931675\n",
      "-----Epoch:  9020 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13881422412578137\n",
      "-----Epoch:  9030 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13878561784691687\n",
      "-----Epoch:  9040 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13875704703010378\n",
      "-----Epoch:  9050 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1387285115731398\n",
      "-----Epoch:  9060 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13870001137423765\n",
      "-----Epoch:  9070 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1386715463320227\n",
      "-----Epoch:  9080 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13864311634553106\n",
      "-----Epoch:  9090 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13861472131420793\n",
      "-----Epoch:  9100 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13858636113790465\n",
      "-----Epoch:  9110 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13855803571687703\n",
      "-----Epoch:  9120 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1385297449517829\n",
      "-----Epoch:  9130 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1385014887436811\n",
      "-----Epoch:  9140 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1384732669940281\n",
      "-----Epoch:  9150 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13844507960467653\n",
      "-----Epoch:  9160 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13841692647787354\n",
      "-----Epoch:  9170 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1383888075162581\n",
      "-----Epoch:  9180 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13836072262285934\n",
      "-----Epoch:  9190 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13833267170109464\n",
      "-----Epoch:  9200 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13830465465476735\n",
      "-----Epoch:  9210 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13827667138806507\n",
      "-----Epoch:  9220 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13824872180555778\n",
      "-----Epoch:  9230 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1382208058121954\n",
      "-----Epoch:  9240 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13819292331330651\n",
      "-----Epoch:  9250 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13816507421459587\n",
      "-----Epoch:  9260 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13813725842214294\n",
      "-----Epoch:  9270 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13810947584239971\n",
      "-----Epoch:  9280 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13808172638218905\n",
      "-----Epoch:  9290 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13805400994870237\n",
      "-----Epoch:  9300 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13802632644949833\n",
      "-----Epoch:  9310 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13799867579250089\n",
      "-----Epoch:  9320 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13797105788599703\n",
      "-----Epoch:  9330 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1379434726386351\n",
      "-----Epoch:  9340 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13791591995942343\n",
      "-----Epoch:  9350 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1378883997577285\n",
      "-----Epoch:  9360 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13786091194327194\n",
      "-----Epoch:  9370 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1378334564261306\n",
      "-----Epoch:  9380 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13780603311673334\n",
      "-----Epoch:  9390 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13777864192585973\n",
      "-----Epoch:  9400 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13775128276463885\n",
      "-----Epoch:  9410 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13772395554454628\n",
      "-----Epoch:  9420 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13769666017740376\n",
      "-----Epoch:  9430 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1376693965753766\n",
      "-----Epoch:  9440 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13764216465097237\n",
      "-----Epoch:  9450 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13761496431703876\n",
      "-----Epoch:  9460 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13758779548676228\n",
      "-----Epoch:  9470 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13756065807366671\n",
      "-----Epoch:  9480 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13753355199161094\n",
      "-----Epoch:  9490 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1375064771547876\n",
      "-----Epoch:  9500 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13747943347772149\n",
      "-----Epoch:  9510 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13745242087526802\n",
      "-----Epoch:  9520 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1374254392626108\n",
      "-----Epoch:  9530 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13739848855526113\n",
      "-----Epoch:  9540 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13737156866905573\n",
      "-----Epoch:  9550 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13734467952015536\n",
      "-----Epoch:  9560 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13731782102504306\n",
      "-----Epoch:  9570 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1372909931005227\n",
      "-----Epoch:  9580 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13726419566371736\n",
      "-----Epoch:  9590 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13723742863206786\n",
      "-----Epoch:  9600 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1372106919233312\n",
      "-----Epoch:  9610 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13718398545557853\n",
      "-----Epoch:  9620 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13715730914719487\n",
      "-----Epoch:  9630 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13713066291687567\n",
      "-----Epoch:  9640 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13710404668362733\n",
      "-----Epoch:  9650 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13707746036676427\n",
      "-----Epoch:  9660 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.137050903885908\n",
      "-----Epoch:  9670 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13702437716098548\n",
      "-----Epoch:  9680 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13699788011222777\n",
      "-----Epoch:  9690 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13697141266016838\n",
      "-----Epoch:  9700 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13694497472564227\n",
      "-----Epoch:  9710 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13691856622978332\n",
      "-----Epoch:  9720 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13689218709402445\n",
      "-----Epoch:  9730 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13686583724009463\n",
      "-----Epoch:  9740 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13683951659001867\n",
      "-----Epoch:  9750 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1368132250661148\n",
      "-----Epoch:  9760 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13678696259099407\n",
      "-----Epoch:  9770 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13676072908755868\n",
      "-----Epoch:  9780 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13673452447900022\n",
      "-----Epoch:  9790 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13670834868879875\n",
      "-----Epoch:  9800 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13668220164072123\n",
      "-----Epoch:  9810 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13665608325882034\n",
      "-----Epoch:  9820 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1366299934674326\n",
      "-----Epoch:  9830 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13660393219117759\n",
      "-----Epoch:  9840 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13657789935495643\n",
      "-----Epoch:  9850 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13655189488395034\n",
      "-----Epoch:  9860 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13652591870361896\n",
      "-----Epoch:  9870 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13649997073970008\n",
      "-----Epoch:  9880 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13647405091820716\n",
      "-----Epoch:  9890 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1364481591654288\n",
      "-----Epoch:  9900 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13642229540792714\n",
      "-----Epoch:  9910 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13639645957253624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  9920 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13637065158636164\n",
      "-----Epoch:  9930 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13634487137677823\n",
      "-----Epoch:  9940 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13631911887142953\n",
      "-----Epoch:  9950 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.1362933939982259\n",
      "-----Epoch:  9960 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.136267696685344\n",
      "-----Epoch:  9970 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13624202686122486\n",
      "-----Epoch:  9980 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13621638445457324\n",
      "-----Epoch:  9990 -----\n",
      "Accuracy: 0.625\n",
      "Cost: 0.13619076939435565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbb8262aac0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TRAINING ON FLOWER PROBLEM (petal length and age --> color)\n",
    "\n",
    "X_train = np.array([[3, 2, 4, 3, 3.5, 2, 5.5, 1],\n",
    "                    [1.5, 1, 1.5, 1, 0.5, 0.5, 1, 1]])\n",
    "y_train = np.array([1, 0, 1, 0, 1, 0, 1, 0])\n",
    "\n",
    "Flower_net = NeuralNet('binary_logloss')\n",
    "Flower_net.addLayer(1, 'sigmoid')\n",
    "costs, weights = Flower_net.fit(X_train, y_train, 10000)\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing Flower problem\n",
    "\n",
    "def vis_data():\n",
    "    plt.axis([0, 6, 0 ,3])\n",
    "    plt.grid()\n",
    "    for i in range(X_train.shape[1]):\n",
    "        point  = X_train[:, i]\n",
    "        color = 'r'\n",
    "        if y_train[i] == 0:\n",
    "            color = 'b'\n",
    "        plt.scatter(point[0], point[1], c=color)\n",
    "    \n",
    "# check out the networks predictions in the x,y plane\n",
    "for x in np.linspace(0, 6, 30):\n",
    "    for y in np.linspace(0, 3, 30):\n",
    "        test = np.array([[x],[y]])\n",
    "        pred = Flower_net.predict(test)\n",
    "        c = 'b'\n",
    "        if pred > .5:\n",
    "            c = 'r'\n",
    "        plt.scatter([x],[y],c=c, alpha=.2)\n",
    "\n",
    "vis_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING ON MNIST w/ no batches\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation].astype(np.int)\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=60000, test_size=10000)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).T\n",
    "X_test = scaler.transform(X_test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  0 -----\n",
      "Accuracy: 0.10171666666666666\n",
      "Cost: 2.4244888305818577\n",
      "-----Epoch:  10 -----\n",
      "Accuracy: 0.5815166666666667\n",
      "Cost: 1.1747133859980408\n",
      "-----Epoch:  20 -----\n",
      "Accuracy: 0.6961833333333334\n",
      "Cost: 1.0641489237800632\n",
      "-----Epoch:  30 -----\n",
      "Accuracy: 0.7446833333333334\n",
      "Cost: 1.0204024640644833\n",
      "-----Epoch:  40 -----\n",
      "Accuracy: 0.7731833333333333\n",
      "Cost: 0.9956950291591151\n",
      "-----Epoch:  50 -----\n",
      "Accuracy: 0.7911166666666667\n",
      "Cost: 0.9794411109233166\n",
      "-----Epoch:  60 -----\n",
      "Accuracy: 0.80445\n",
      "Cost: 0.9678006472324164\n",
      "-----Epoch:  70 -----\n",
      "Accuracy: 0.81475\n",
      "Cost: 0.9590225533408805\n",
      "-----Epoch:  80 -----\n",
      "Accuracy: 0.8235666666666667\n",
      "Cost: 0.952130347931301\n",
      "-----Epoch:  90 -----\n",
      "Accuracy: 0.8304833333333334\n",
      "Cost: 0.9465725276291027\n",
      "-----Epoch:  100 -----\n",
      "Accuracy: 0.8357\n",
      "Cost: 0.9419139668666761\n",
      "-----Epoch:  110 -----\n",
      "Accuracy: 0.8404833333333334\n",
      "Cost: 0.9379783773250077\n",
      "-----Epoch:  120 -----\n",
      "Accuracy: 0.8450333333333333\n",
      "Cost: 0.9346569679233618\n",
      "-----Epoch:  130 -----\n",
      "Accuracy: 0.8488\n",
      "Cost: 0.9318282320415135\n",
      "-----Epoch:  140 -----\n",
      "Accuracy: 0.8517833333333333\n",
      "Cost: 0.9293997070549813\n",
      "-----Epoch:  150 -----\n",
      "Accuracy: 0.8552833333333333\n",
      "Cost: 0.9272787718627993\n",
      "-----Epoch:  160 -----\n",
      "Accuracy: 0.8583166666666666\n",
      "Cost: 0.9254011573482865\n",
      "-----Epoch:  170 -----\n",
      "Accuracy: 0.8608333333333333\n",
      "Cost: 0.9237246531435629\n",
      "-----Epoch:  180 -----\n",
      "Accuracy: 0.86355\n",
      "Cost: 0.922226265862826\n",
      "-----Epoch:  190 -----\n",
      "Accuracy: 0.86555\n",
      "Cost: 0.9208843250692365\n",
      "-----Epoch:  200 -----\n",
      "Accuracy: 0.8672666666666666\n",
      "Cost: 0.9196760768889601\n",
      "-----Epoch:  210 -----\n",
      "Accuracy: 0.8692166666666666\n",
      "Cost: 0.9185783142590694\n",
      "-----Epoch:  220 -----\n",
      "Accuracy: 0.8712333333333333\n",
      "Cost: 0.9175766846724082\n",
      "-----Epoch:  230 -----\n",
      "Accuracy: 0.8725333333333334\n",
      "Cost: 0.9167061264562438\n",
      "-----Epoch:  240 -----\n",
      "Accuracy: 0.8702\n",
      "Cost: 0.9166756992797448\n",
      "-----Epoch:  250 -----\n",
      "Accuracy: 0.8596333333333334\n",
      "Cost: 0.9181821697222358\n",
      "-----Epoch:  260 -----\n",
      "Accuracy: 0.87395\n",
      "Cost: 0.9152738168396809\n",
      "-----Epoch:  270 -----\n",
      "Accuracy: 0.8773166666666666\n",
      "Cost: 0.9141191034238159\n",
      "-----Epoch:  280 -----\n",
      "Accuracy: 0.87825\n",
      "Cost: 0.9135132676446891\n",
      "-----Epoch:  290 -----\n",
      "Accuracy: 0.878\n",
      "Cost: 0.9132594369913177\n",
      "-----Epoch:  300 -----\n",
      "Accuracy: 0.8761166666666667\n",
      "Cost: 0.9132979904874752\n",
      "-----Epoch:  310 -----\n",
      "Accuracy: 0.8776666666666667\n",
      "Cost: 0.9127548069572384\n",
      "-----Epoch:  320 -----\n",
      "Accuracy: 0.88085\n",
      "Cost: 0.9117960067017283\n",
      "-----Epoch:  330 -----\n",
      "Accuracy: 0.8832333333333333\n",
      "Cost: 0.911125394449537\n",
      "-----Epoch:  340 -----\n",
      "Accuracy: 0.8840666666666667\n",
      "Cost: 0.9107112245986763\n",
      "-----Epoch:  350 -----\n",
      "Accuracy: 0.8838833333333334\n",
      "Cost: 0.9105237437516038\n",
      "-----Epoch:  360 -----\n",
      "Accuracy: 0.8837833333333334\n",
      "Cost: 0.9104393829092351\n",
      "-----Epoch:  370 -----\n",
      "Accuracy: 0.88475\n",
      "Cost: 0.9100519688832461\n",
      "-----Epoch:  380 -----\n",
      "Accuracy: 0.88725\n",
      "Cost: 0.9093198479622848\n",
      "-----Epoch:  390 -----\n",
      "Accuracy: 0.88955\n",
      "Cost: 0.9087514057887447\n",
      "-----Epoch:  400 -----\n",
      "Accuracy: 0.8904166666666666\n",
      "Cost: 0.9083833905587645\n",
      "-----Epoch:  410 -----\n",
      "Accuracy: 0.89065\n",
      "Cost: 0.908174336379307\n",
      "-----Epoch:  420 -----\n",
      "Accuracy: 0.8896\n",
      "Cost: 0.9082131509896497\n",
      "-----Epoch:  430 -----\n",
      "Accuracy: 0.8887\n",
      "Cost: 0.9082661924794025\n",
      "-----Epoch:  440 -----\n",
      "Accuracy: 0.8916333333333334\n",
      "Cost: 0.9075898647456214\n",
      "-----Epoch:  450 -----\n",
      "Accuracy: 0.8944666666666666\n",
      "Cost: 0.9068601091688684\n",
      "-----Epoch:  460 -----\n",
      "Accuracy: 0.8955666666666666\n",
      "Cost: 0.9064689771052846\n",
      "-----Epoch:  470 -----\n",
      "Accuracy: 0.8963\n",
      "Cost: 0.906193211333996\n",
      "-----Epoch:  480 -----\n",
      "Accuracy: 0.89675\n",
      "Cost: 0.9059908283193813\n",
      "-----Epoch:  490 -----\n",
      "Accuracy: 0.89635\n",
      "Cost: 0.9059506390473527\n",
      "-----Epoch:  500 -----\n",
      "Accuracy: 0.8942\n",
      "Cost: 0.9061955865167307\n",
      "-----Epoch:  510 -----\n",
      "Accuracy: 0.8943833333333333\n",
      "Cost: 0.9060137140055762\n",
      "-----Epoch:  520 -----\n",
      "Accuracy: 0.8983333333333333\n",
      "Cost: 0.905215118533325\n",
      "-----Epoch:  530 -----\n",
      "Accuracy: 0.89985\n",
      "Cost: 0.9047335611875431\n",
      "-----Epoch:  540 -----\n",
      "Accuracy: 0.90095\n",
      "Cost: 0.9044534755148795\n",
      "-----Epoch:  550 -----\n",
      "Accuracy: 0.9013666666666666\n",
      "Cost: 0.9042280544535966\n",
      "-----Epoch:  560 -----\n",
      "Accuracy: 0.9018\n",
      "Cost: 0.9040368569269596\n",
      "-----Epoch:  570 -----\n",
      "Accuracy: 0.9018666666666667\n",
      "Cost: 0.9038934053481016\n",
      "-----Epoch:  580 -----\n",
      "Accuracy: 0.9016666666666666\n",
      "Cost: 0.9038334074849111\n",
      "-----Epoch:  590 -----\n",
      "Accuracy: 0.9014166666666666\n",
      "Cost: 0.9038664507530595\n",
      "-----Epoch:  600 -----\n",
      "Accuracy: 0.9014\n",
      "Cost: 0.9037668513879407\n",
      "-----Epoch:  610 -----\n",
      "Accuracy: 0.9034\n",
      "Cost: 0.9033465187192402\n",
      "-----Epoch:  620 -----\n",
      "Accuracy: 0.9046833333333333\n",
      "Cost: 0.902960140058434\n",
      "-----Epoch:  630 -----\n",
      "Accuracy: 0.9058\n",
      "Cost: 0.9027024033206842\n",
      "-----Epoch:  640 -----\n",
      "Accuracy: 0.9064833333333333\n",
      "Cost: 0.9025051549595277\n",
      "-----Epoch:  650 -----\n",
      "Accuracy: 0.90705\n",
      "Cost: 0.9023334653711736\n",
      "-----Epoch:  660 -----\n",
      "Accuracy: 0.9075166666666666\n",
      "Cost: 0.902177534392615\n",
      "-----Epoch:  670 -----\n",
      "Accuracy: 0.90765\n",
      "Cost: 0.902034620719883\n",
      "-----Epoch:  680 -----\n",
      "Accuracy: 0.90765\n",
      "Cost: 0.9019024709882483\n",
      "-----Epoch:  690 -----\n",
      "Accuracy: 0.9079\n",
      "Cost: 0.9017748916359378\n",
      "-----Epoch:  700 -----\n",
      "Accuracy: 0.9083\n",
      "Cost: 0.901641256264278\n",
      "-----Epoch:  710 -----\n",
      "Accuracy: 0.9086666666666666\n",
      "Cost: 0.9014912028212654\n",
      "-----Epoch:  720 -----\n",
      "Accuracy: 0.9091\n",
      "Cost: 0.9013246703886818\n",
      "-----Epoch:  730 -----\n",
      "Accuracy: 0.90965\n",
      "Cost: 0.9011523729510738\n",
      "-----Epoch:  740 -----\n",
      "Accuracy: 0.9102666666666667\n",
      "Cost: 0.9009850452871236\n",
      "-----Epoch:  750 -----\n",
      "Accuracy: 0.91065\n",
      "Cost: 0.9008270965323476\n",
      "-----Epoch:  760 -----\n",
      "Accuracy: 0.9108833333333334\n",
      "Cost: 0.9006779725445004\n",
      "-----Epoch:  770 -----\n",
      "Accuracy: 0.9111666666666667\n",
      "Cost: 0.9005355782142984\n",
      "-----Epoch:  780 -----\n",
      "Accuracy: 0.9114\n",
      "Cost: 0.900398259054139\n",
      "-----Epoch:  790 -----\n",
      "Accuracy: 0.9118166666666667\n",
      "Cost: 0.9002645070331897\n",
      "-----Epoch:  800 -----\n",
      "Accuracy: 0.9122333333333333\n",
      "Cost: 0.9001333829967645\n",
      "-----Epoch:  810 -----\n",
      "Accuracy: 0.9125666666666666\n",
      "Cost: 0.9000041779593891\n",
      "-----Epoch:  820 -----\n",
      "Accuracy: 0.9128\n",
      "Cost: 0.8998764009015079\n",
      "-----Epoch:  830 -----\n",
      "Accuracy: 0.91325\n",
      "Cost: 0.899749949516488\n",
      "-----Epoch:  840 -----\n",
      "Accuracy: 0.91365\n",
      "Cost: 0.8996248823305052\n",
      "-----Epoch:  850 -----\n",
      "Accuracy: 0.91415\n",
      "Cost: 0.8995012871381484\n",
      "-----Epoch:  860 -----\n",
      "Accuracy: 0.9144333333333333\n",
      "Cost: 0.8993791532780944\n",
      "-----Epoch:  870 -----\n",
      "Accuracy: 0.9148166666666666\n",
      "Cost: 0.8992585822122137\n",
      "-----Epoch:  880 -----\n",
      "Accuracy: 0.9152\n",
      "Cost: 0.8991396146745361\n",
      "-----Epoch:  890 -----\n",
      "Accuracy: 0.9153666666666667\n",
      "Cost: 0.8990223300193142\n",
      "-----Epoch:  900 -----\n",
      "Accuracy: 0.9158333333333334\n",
      "Cost: 0.8989067870254505\n",
      "-----Epoch:  910 -----\n",
      "Accuracy: 0.9162833333333333\n",
      "Cost: 0.8987929152333892\n",
      "-----Epoch:  920 -----\n",
      "Accuracy: 0.9166666666666666\n",
      "Cost: 0.8986806865480671\n",
      "-----Epoch:  930 -----\n",
      "Accuracy: 0.9170166666666667\n",
      "Cost: 0.8985700416008615\n",
      "-----Epoch:  940 -----\n",
      "Accuracy: 0.9172166666666667\n",
      "Cost: 0.898460959579429\n",
      "-----Epoch:  950 -----\n",
      "Accuracy: 0.9175166666666666\n",
      "Cost: 0.8983534587053915\n",
      "-----Epoch:  960 -----\n",
      "Accuracy: 0.9178166666666666\n",
      "Cost: 0.8982474452536156\n",
      "-----Epoch:  970 -----\n",
      "Accuracy: 0.9182333333333333\n",
      "Cost: 0.8981428951852716\n",
      "-----Epoch:  980 -----\n",
      "Accuracy: 0.9185166666666666\n",
      "Cost: 0.8980398083291979\n",
      "-----Epoch:  990 -----\n",
      "Accuracy: 0.9189\n",
      "Cost: 0.8979381040741741\n",
      "-----Epoch:  1000 -----\n",
      "Accuracy: 0.9193\n",
      "Cost: 0.897837692870605\n",
      "-----Epoch:  1010 -----\n",
      "Accuracy: 0.9196833333333333\n",
      "Cost: 0.8977384717942161\n",
      "-----Epoch:  1020 -----\n",
      "Accuracy: 0.9199333333333334\n",
      "Cost: 0.8976405476474246\n",
      "-----Epoch:  1030 -----\n",
      "Accuracy: 0.92025\n",
      "Cost: 0.8975438828794279\n",
      "-----Epoch:  1040 -----\n",
      "Accuracy: 0.9204\n",
      "Cost: 0.8974484309588759\n",
      "-----Epoch:  1050 -----\n",
      "Accuracy: 0.9206666666666666\n",
      "Cost: 0.8973541749761242\n",
      "-----Epoch:  1060 -----\n",
      "Accuracy: 0.9210166666666667\n",
      "Cost: 0.8972610597028996\n",
      "-----Epoch:  1070 -----\n",
      "Accuracy: 0.9212166666666667\n",
      "Cost: 0.8971691281644216\n",
      "-----Epoch:  1080 -----\n",
      "Accuracy: 0.9214166666666667\n",
      "Cost: 0.8970783000760062\n",
      "-----Epoch:  1090 -----\n",
      "Accuracy: 0.9217\n",
      "Cost: 0.8969885280623748\n",
      "-----Epoch:  1100 -----\n",
      "Accuracy: 0.9219\n",
      "Cost: 0.8968996643666995\n",
      "-----Epoch:  1110 -----\n",
      "Accuracy: 0.9221333333333334\n",
      "Cost: 0.8968117622632342\n",
      "-----Epoch:  1120 -----\n",
      "Accuracy: 0.9223166666666667\n",
      "Cost: 0.8967247886551971\n",
      "-----Epoch:  1130 -----\n",
      "Accuracy: 0.9225\n",
      "Cost: 0.8966387805428858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  1140 -----\n",
      "Accuracy: 0.9227166666666666\n",
      "Cost: 0.8965537352747958\n",
      "-----Epoch:  1150 -----\n",
      "Accuracy: 0.9229333333333334\n",
      "Cost: 0.896469622296591\n",
      "-----Epoch:  1160 -----\n",
      "Accuracy: 0.9232333333333334\n",
      "Cost: 0.8963863551146648\n",
      "-----Epoch:  1170 -----\n",
      "Accuracy: 0.9234833333333333\n",
      "Cost: 0.8963039271759787\n",
      "-----Epoch:  1180 -----\n",
      "Accuracy: 0.9236666666666666\n",
      "Cost: 0.896222236591327\n",
      "-----Epoch:  1190 -----\n",
      "Accuracy: 0.9239333333333334\n",
      "Cost: 0.8961412851168208\n",
      "-----Epoch:  1200 -----\n",
      "Accuracy: 0.9241833333333334\n",
      "Cost: 0.8960611796262488\n",
      "-----Epoch:  1210 -----\n",
      "Accuracy: 0.9244666666666667\n",
      "Cost: 0.8959819167451053\n",
      "-----Epoch:  1220 -----\n",
      "Accuracy: 0.9246166666666666\n",
      "Cost: 0.8959034795456161\n",
      "-----Epoch:  1230 -----\n",
      "Accuracy: 0.9249333333333334\n",
      "Cost: 0.8958258056436827\n",
      "-----Epoch:  1240 -----\n",
      "Accuracy: 0.9251\n",
      "Cost: 0.8957489369806815\n",
      "-----Epoch:  1250 -----\n",
      "Accuracy: 0.9253166666666667\n",
      "Cost: 0.8956728438344156\n",
      "-----Epoch:  1260 -----\n",
      "Accuracy: 0.92555\n",
      "Cost: 0.8955974870569681\n",
      "-----Epoch:  1270 -----\n",
      "Accuracy: 0.9258\n",
      "Cost: 0.8955228605421961\n",
      "-----Epoch:  1280 -----\n",
      "Accuracy: 0.92595\n",
      "Cost: 0.8954489471184922\n",
      "-----Epoch:  1290 -----\n",
      "Accuracy: 0.9262666666666667\n",
      "Cost: 0.8953757335463681\n",
      "-----Epoch:  1300 -----\n",
      "Accuracy: 0.9265333333333333\n",
      "Cost: 0.895303203637105\n",
      "-----Epoch:  1310 -----\n",
      "Accuracy: 0.9267166666666666\n",
      "Cost: 0.8952313156792752\n",
      "-----Epoch:  1320 -----\n",
      "Accuracy: 0.9268666666666666\n",
      "Cost: 0.8951600170058787\n",
      "-----Epoch:  1330 -----\n",
      "Accuracy: 0.9270666666666667\n",
      "Cost: 0.8950893783126693\n",
      "-----Epoch:  1340 -----\n",
      "Accuracy: 0.9272\n",
      "Cost: 0.8950193596997534\n",
      "-----Epoch:  1350 -----\n",
      "Accuracy: 0.92735\n",
      "Cost: 0.8949499209945918\n",
      "-----Epoch:  1360 -----\n",
      "Accuracy: 0.9275333333333333\n",
      "Cost: 0.8948810692586207\n",
      "-----Epoch:  1370 -----\n",
      "Accuracy: 0.9277\n",
      "Cost: 0.8948128610343669\n",
      "-----Epoch:  1380 -----\n",
      "Accuracy: 0.9278166666666666\n",
      "Cost: 0.8947452670388008\n",
      "-----Epoch:  1390 -----\n",
      "Accuracy: 0.9280333333333334\n",
      "Cost: 0.8946782523480319\n",
      "-----Epoch:  1400 -----\n",
      "Accuracy: 0.9282333333333334\n",
      "Cost: 0.8946118220315424\n",
      "-----Epoch:  1410 -----\n",
      "Accuracy: 0.9283333333333333\n",
      "Cost: 0.8945459178146534\n",
      "-----Epoch:  1420 -----\n",
      "Accuracy: 0.9287333333333333\n",
      "Cost: 0.8944805644229178\n",
      "-----Epoch:  1430 -----\n",
      "Accuracy: 0.9288166666666666\n",
      "Cost: 0.8944157161349267\n",
      "-----Epoch:  1440 -----\n",
      "Accuracy: 0.92905\n",
      "Cost: 0.8943513876084429\n",
      "-----Epoch:  1450 -----\n",
      "Accuracy: 0.9292166666666667\n",
      "Cost: 0.8942875803462498\n",
      "-----Epoch:  1460 -----\n",
      "Accuracy: 0.9294166666666667\n",
      "Cost: 0.8942243409299435\n",
      "-----Epoch:  1470 -----\n",
      "Accuracy: 0.9296166666666666\n",
      "Cost: 0.89416166370398\n",
      "-----Epoch:  1480 -----\n",
      "Accuracy: 0.9298666666666666\n",
      "Cost: 0.8940994018452532\n",
      "-----Epoch:  1490 -----\n",
      "Accuracy: 0.9300666666666667\n",
      "Cost: 0.8940376120971685\n",
      "-----Epoch:  1500 -----\n",
      "Accuracy: 0.9302333333333334\n",
      "Cost: 0.893976343140177\n",
      "-----Epoch:  1510 -----\n",
      "Accuracy: 0.9303833333333333\n",
      "Cost: 0.8939154575478008\n",
      "-----Epoch:  1520 -----\n",
      "Accuracy: 0.9305166666666667\n",
      "Cost: 0.8938550225036422\n",
      "-----Epoch:  1530 -----\n",
      "Accuracy: 0.93065\n",
      "Cost: 0.8937950577410848\n",
      "-----Epoch:  1540 -----\n",
      "Accuracy: 0.93075\n",
      "Cost: 0.8937355599911321\n",
      "-----Epoch:  1550 -----\n",
      "Accuracy: 0.9309666666666667\n",
      "Cost: 0.8936764846641619\n",
      "-----Epoch:  1560 -----\n",
      "Accuracy: 0.9311\n",
      "Cost: 0.8936178744006109\n",
      "-----Epoch:  1570 -----\n",
      "Accuracy: 0.9312666666666667\n",
      "Cost: 0.8935597100788307\n",
      "-----Epoch:  1580 -----\n",
      "Accuracy: 0.9314833333333333\n",
      "Cost: 0.8935019663475515\n",
      "-----Epoch:  1590 -----\n",
      "Accuracy: 0.9316833333333333\n",
      "Cost: 0.8934446155141513\n",
      "-----Epoch:  1600 -----\n",
      "Accuracy: 0.93185\n",
      "Cost: 0.8933876830915559\n",
      "-----Epoch:  1610 -----\n",
      "Accuracy: 0.9319833333333334\n",
      "Cost: 0.8933311813184112\n",
      "-----Epoch:  1620 -----\n",
      "Accuracy: 0.9320166666666667\n",
      "Cost: 0.8932750899907945\n",
      "-----Epoch:  1630 -----\n",
      "Accuracy: 0.9321833333333334\n",
      "Cost: 0.8932194125000779\n",
      "-----Epoch:  1640 -----\n",
      "Accuracy: 0.9323166666666667\n",
      "Cost: 0.8931641231933075\n",
      "-----Epoch:  1650 -----\n",
      "Accuracy: 0.9323833333333333\n",
      "Cost: 0.8931091768182617\n",
      "-----Epoch:  1660 -----\n",
      "Accuracy: 0.9324833333333333\n",
      "Cost: 0.8930546090572561\n",
      "-----Epoch:  1670 -----\n",
      "Accuracy: 0.93265\n",
      "Cost: 0.8930004389097994\n",
      "-----Epoch:  1680 -----\n",
      "Accuracy: 0.93275\n",
      "Cost: 0.8929466309596532\n",
      "-----Epoch:  1690 -----\n",
      "Accuracy: 0.9328\n",
      "Cost: 0.8928931555250217\n",
      "-----Epoch:  1700 -----\n",
      "Accuracy: 0.933\n",
      "Cost: 0.8928400247010202\n",
      "-----Epoch:  1710 -----\n",
      "Accuracy: 0.9332166666666667\n",
      "Cost: 0.892787299460286\n",
      "-----Epoch:  1720 -----\n",
      "Accuracy: 0.9333\n",
      "Cost: 0.892734888056031\n",
      "-----Epoch:  1730 -----\n",
      "Accuracy: 0.9334333333333333\n",
      "Cost: 0.8926827869789266\n",
      "-----Epoch:  1740 -----\n",
      "Accuracy: 0.9335833333333333\n",
      "Cost: 0.892631025073923\n",
      "-----Epoch:  1750 -----\n",
      "Accuracy: 0.9337\n",
      "Cost: 0.8925795797495517\n",
      "-----Epoch:  1760 -----\n",
      "Accuracy: 0.9339\n",
      "Cost: 0.8925283711406924\n",
      "-----Epoch:  1770 -----\n",
      "Accuracy: 0.93405\n",
      "Cost: 0.8924774764467387\n",
      "-----Epoch:  1780 -----\n",
      "Accuracy: 0.9342\n",
      "Cost: 0.8924269175210283\n",
      "-----Epoch:  1790 -----\n",
      "Accuracy: 0.93435\n",
      "Cost: 0.892376620086461\n",
      "-----Epoch:  1800 -----\n",
      "Accuracy: 0.9344833333333333\n",
      "Cost: 0.8923266522424338\n",
      "-----Epoch:  1810 -----\n",
      "Accuracy: 0.9346\n",
      "Cost: 0.8922769701357677\n",
      "-----Epoch:  1820 -----\n",
      "Accuracy: 0.9347166666666666\n",
      "Cost: 0.8922275875539325\n",
      "-----Epoch:  1830 -----\n",
      "Accuracy: 0.9349333333333333\n",
      "Cost: 0.89217847966979\n",
      "-----Epoch:  1840 -----\n",
      "Accuracy: 0.9350166666666667\n",
      "Cost: 0.8921296887268\n",
      "-----Epoch:  1850 -----\n",
      "Accuracy: 0.9351833333333334\n",
      "Cost: 0.892081185869137\n",
      "-----Epoch:  1860 -----\n",
      "Accuracy: 0.9353666666666667\n",
      "Cost: 0.8920330056495724\n",
      "-----Epoch:  1870 -----\n",
      "Accuracy: 0.9354833333333333\n",
      "Cost: 0.8919851322964492\n",
      "-----Epoch:  1880 -----\n",
      "Accuracy: 0.9355666666666667\n",
      "Cost: 0.891937572250372\n",
      "-----Epoch:  1890 -----\n",
      "Accuracy: 0.9355833333333333\n",
      "Cost: 0.8918903192401867\n",
      "-----Epoch:  1900 -----\n",
      "Accuracy: 0.9357\n",
      "Cost: 0.8918433459772819\n",
      "-----Epoch:  1910 -----\n",
      "Accuracy: 0.9358666666666666\n",
      "Cost: 0.8917966804860434\n",
      "-----Epoch:  1920 -----\n",
      "Accuracy: 0.93595\n",
      "Cost: 0.8917503020228347\n",
      "-----Epoch:  1930 -----\n",
      "Accuracy: 0.9360666666666667\n",
      "Cost: 0.8917042714436805\n",
      "-----Epoch:  1940 -----\n",
      "Accuracy: 0.9361833333333334\n",
      "Cost: 0.8916585580339048\n",
      "-----Epoch:  1950 -----\n",
      "Accuracy: 0.9363333333333334\n",
      "Cost: 0.8916131317256172\n",
      "-----Epoch:  1960 -----\n",
      "Accuracy: 0.9364666666666667\n",
      "Cost: 0.8915679840867609\n",
      "-----Epoch:  1970 -----\n",
      "Accuracy: 0.9365166666666667\n",
      "Cost: 0.8915230842224446\n",
      "-----Epoch:  1980 -----\n",
      "Accuracy: 0.9366833333333333\n",
      "Cost: 0.8914784840966645\n",
      "-----Epoch:  1990 -----\n",
      "Accuracy: 0.9368666666666666\n",
      "Cost: 0.8914341788115322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbb84469a60>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_net = NeuralNet('multi_logloss')\n",
    "mnist_net.addLayer(64, 'reLu')\n",
    "mnist_net.addLayer(10, 'softmax')\n",
    "costs, weights = mnist_net.fit(X_train, y_train, 2000, 60000)\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.48\n"
     ]
    }
   ],
   "source": [
    "y_pred = mnist_net.predict(X_test)\n",
    "test_accuracy = 100*np.sum(y_test == np.argmax(y_pred, 0), axis=0) / X_test.shape[1]\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  0 -----\n",
      "Accuracy: 0.082\n",
      "Cost: 2.0958753613040217\n",
      "-----Epoch:  10 -----\n",
      "Accuracy: 0.898\n",
      "Cost: 0.4279409782747813\n",
      "-----Epoch:  20 -----\n",
      "Accuracy: 0.91\n",
      "Cost: 0.4208167996239343\n",
      "-----Epoch:  30 -----\n",
      "Accuracy: 0.928\n",
      "Cost: 0.4160737275963439\n",
      "-----Epoch:  40 -----\n",
      "Accuracy: 0.946\n",
      "Cost: 0.4124927808790041\n",
      "-----Epoch:  50 -----\n",
      "Accuracy: 0.95\n",
      "Cost: 0.40936767895819387\n",
      "-----Epoch:  60 -----\n",
      "Accuracy: 0.956\n",
      "Cost: 0.40681250686733483\n",
      "-----Epoch:  70 -----\n",
      "Accuracy: 0.964\n",
      "Cost: 0.40478491793401083\n",
      "-----Epoch:  80 -----\n",
      "Accuracy: 0.968\n",
      "Cost: 0.403095693615667\n",
      "-----Epoch:  90 -----\n",
      "Accuracy: 0.972\n",
      "Cost: 0.40174250051638577\n",
      "-----Epoch:  100 -----\n",
      "Accuracy: 0.976\n",
      "Cost: 0.4006916534545362\n",
      "-----Epoch:  110 -----\n",
      "Accuracy: 0.982\n",
      "Cost: 0.3998096567363156\n",
      "-----Epoch:  120 -----\n",
      "Accuracy: 0.984\n",
      "Cost: 0.3990667941488453\n",
      "-----Epoch:  130 -----\n",
      "Accuracy: 0.99\n",
      "Cost: 0.3984032226694662\n",
      "-----Epoch:  140 -----\n",
      "Accuracy: 0.992\n",
      "Cost: 0.3978278135733451\n",
      "-----Epoch:  150 -----\n",
      "Accuracy: 0.992\n",
      "Cost: 0.39729807527110134\n",
      "-----Epoch:  160 -----\n",
      "Accuracy: 0.992\n",
      "Cost: 0.39682603919598874\n",
      "-----Epoch:  170 -----\n",
      "Accuracy: 0.992\n",
      "Cost: 0.3963963440166345\n",
      "-----Epoch:  180 -----\n",
      "Accuracy: 0.992\n",
      "Cost: 0.39599332357131073\n",
      "-----Epoch:  190 -----\n",
      "Accuracy: 0.996\n",
      "Cost: 0.39559272811025936\n",
      "-----Epoch:  200 -----\n",
      "Accuracy: 0.996\n",
      "Cost: 0.395221140572031\n",
      "-----Epoch:  210 -----\n",
      "Accuracy: 0.996\n",
      "Cost: 0.3948931014085507\n",
      "-----Epoch:  220 -----\n",
      "Accuracy: 0.996\n",
      "Cost: 0.3946063078583102\n",
      "-----Epoch:  230 -----\n",
      "Accuracy: 0.996\n",
      "Cost: 0.394388816715478\n",
      "-----Epoch:  240 -----\n",
      "Accuracy: 0.998\n",
      "Cost: 0.3942322466784242\n",
      "-----Epoch:  250 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3941048958039066\n",
      "-----Epoch:  260 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3940111292629068\n",
      "-----Epoch:  270 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39392815588528385\n",
      "-----Epoch:  280 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.393852452984865\n",
      "-----Epoch:  290 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3937859097316985\n",
      "-----Epoch:  300 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39372509730420874\n",
      "-----Epoch:  310 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3936686021556319\n",
      "-----Epoch:  320 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39362007179306374\n",
      "-----Epoch:  330 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3935780641228215\n",
      "-----Epoch:  340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.393541057441017\n",
      "-----Epoch:  350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39350935031988105\n",
      "-----Epoch:  360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.393479803998206\n",
      "-----Epoch:  370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3934546702664004\n",
      "-----Epoch:  380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3934320437562893\n",
      "-----Epoch:  390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3934122120977084\n",
      "-----Epoch:  400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39339484773022604\n",
      "-----Epoch:  410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39337877161926804\n",
      "-----Epoch:  420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3933649339355144\n",
      "-----Epoch:  430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3933524076944708\n",
      "-----Epoch:  440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3933411308412586\n",
      "-----Epoch:  450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.393330616549099\n",
      "-----Epoch:  460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3933213247028789\n",
      "-----Epoch:  470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3933125747331705\n",
      "-----Epoch:  480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3933043675494906\n",
      "-----Epoch:  490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932969593669019\n",
      "-----Epoch:  500 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39329005854301585\n",
      "-----Epoch:  510 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39328377429617095\n",
      "-----Epoch:  520 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39327799365162497\n",
      "-----Epoch:  530 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932726321899657\n",
      "-----Epoch:  540 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932676678673196\n",
      "-----Epoch:  550 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39326295076107604\n",
      "-----Epoch:  560 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932586072706918\n",
      "-----Epoch:  570 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39325462160281704\n",
      "-----Epoch:  580 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39325082709518705\n",
      "-----Epoch:  590 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932472416193758\n",
      "-----Epoch:  600 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39324391621020804\n",
      "-----Epoch:  610 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39324083053427183\n",
      "-----Epoch:  620 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932378276477184\n",
      "-----Epoch:  630 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39323501156449636\n",
      "-----Epoch:  640 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932324054546727\n",
      "-----Epoch:  650 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932297772556404\n",
      "-----Epoch:  660 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932274105119338\n",
      "-----Epoch:  670 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39322517601971185\n",
      "-----Epoch:  680 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932229824568664\n",
      "-----Epoch:  690 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932209183897894\n",
      "-----Epoch:  700 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932189691624881\n",
      "-----Epoch:  710 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.393217069381264\n",
      "-----Epoch:  720 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39321526504513005\n",
      "-----Epoch:  730 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39321354151190246\n",
      "-----Epoch:  740 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39321189534623907\n",
      "-----Epoch:  750 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39321031871018397\n",
      "-----Epoch:  760 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932087739146726\n",
      "-----Epoch:  770 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39320727952464096\n",
      "-----Epoch:  780 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39320586213454783\n",
      "-----Epoch:  790 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39320450006402496\n",
      "-----Epoch:  800 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39320321292965044\n",
      "-----Epoch:  810 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39320195195578617\n",
      "-----Epoch:  820 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3932007483164395\n",
      "-----Epoch:  830 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3931995836284812\n",
      "-----Epoch:  840 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3931985003029777\n",
      "-----Epoch:  850 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3931974310168616\n",
      "-----Epoch:  860 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39319639181278015\n",
      "-----Epoch:  870 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39319538182024333\n",
      "-----Epoch:  880 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3931944132186235\n",
      "-----Epoch:  890 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39319348194292486\n",
      "-----Epoch:  900 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3931925880322501\n",
      "-----Epoch:  910 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39319171396216235\n",
      "-----Epoch:  920 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39319088206681085\n",
      "-----Epoch:  930 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39319006882423935\n",
      "-----Epoch:  940 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3931892983749957\n",
      "-----Epoch:  950 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3931885173416214\n",
      "-----Epoch:  960 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39318778716881014\n",
      "-----Epoch:  970 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3931870474107856\n",
      "-----Epoch:  980 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.3931863546677381\n",
      "-----Epoch:  990 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.39318566463809246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbb84426c40>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TRAINING ON MNIST w batches\n",
    "\n",
    "mnist_net_batches = NeuralNet('multi_logloss')\n",
    "mnist_net_batches.addLayer(64, 'reLu')\n",
    "mnist_net_batches.addLayer(10, 'softmax')\n",
    "costs_batches, weights_batches = mnist_net_batches.fit(X_train, y_train, 1000, 500)\n",
    "plt.plot(costs_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.48\n"
     ]
    }
   ],
   "source": [
    "y_pred_batches = mnist_net_batches.predict(X_test)\n",
    "test_accuracy_batches = 100*np.sum(y_test == np.argmax(y_pred_batches, 0), axis=0) / X_test.shape[1]\n",
    "print(test_accuracy_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch:  0 -----\n",
      "Accuracy: 0.114\n",
      "Cost: 2.3547322558770056\n",
      "-----Epoch:  10 -----\n",
      "Accuracy: 0.898\n",
      "Cost: 0.4952686834062077\n",
      "-----Epoch:  20 -----\n",
      "Accuracy: 0.934\n",
      "Cost: 0.48566714755921203\n",
      "-----Epoch:  30 -----\n",
      "Accuracy: 0.949\n",
      "Cost: 0.48100414283106774\n",
      "-----Epoch:  40 -----\n",
      "Accuracy: 0.957\n",
      "Cost: 0.4780961821837154\n",
      "-----Epoch:  50 -----\n",
      "Accuracy: 0.962\n",
      "Cost: 0.4760522597841494\n",
      "-----Epoch:  60 -----\n",
      "Accuracy: 0.963\n",
      "Cost: 0.474353825532293\n",
      "-----Epoch:  70 -----\n",
      "Accuracy: 0.968\n",
      "Cost: 0.4728236657681273\n",
      "-----Epoch:  80 -----\n",
      "Accuracy: 0.971\n",
      "Cost: 0.4715893049076693\n",
      "-----Epoch:  90 -----\n",
      "Accuracy: 0.975\n",
      "Cost: 0.4705963092846006\n",
      "-----Epoch:  100 -----\n",
      "Accuracy: 0.976\n",
      "Cost: 0.4697178444479717\n",
      "-----Epoch:  110 -----\n",
      "Accuracy: 0.977\n",
      "Cost: 0.4688948733375247\n",
      "-----Epoch:  120 -----\n",
      "Accuracy: 0.978\n",
      "Cost: 0.46813370170259866\n",
      "-----Epoch:  130 -----\n",
      "Accuracy: 0.98\n",
      "Cost: 0.4674565028603119\n",
      "-----Epoch:  140 -----\n",
      "Accuracy: 0.985\n",
      "Cost: 0.4668865447349548\n",
      "-----Epoch:  150 -----\n",
      "Accuracy: 0.987\n",
      "Cost: 0.46635121329056467\n",
      "-----Epoch:  160 -----\n",
      "Accuracy: 0.989\n",
      "Cost: 0.4658773572965509\n",
      "-----Epoch:  170 -----\n",
      "Accuracy: 0.991\n",
      "Cost: 0.4654715500825646\n",
      "-----Epoch:  180 -----\n",
      "Accuracy: 0.992\n",
      "Cost: 0.4651026504504065\n",
      "-----Epoch:  190 -----\n",
      "Accuracy: 0.992\n",
      "Cost: 0.46476727660987205\n",
      "-----Epoch:  200 -----\n",
      "Accuracy: 0.993\n",
      "Cost: 0.4644662337383695\n",
      "-----Epoch:  210 -----\n",
      "Accuracy: 0.993\n",
      "Cost: 0.46417049069923705\n",
      "-----Epoch:  220 -----\n",
      "Accuracy: 0.994\n",
      "Cost: 0.46390055933429736\n",
      "-----Epoch:  230 -----\n",
      "Accuracy: 0.995\n",
      "Cost: 0.4636366323328858\n",
      "-----Epoch:  240 -----\n",
      "Accuracy: 0.995\n",
      "Cost: 0.46340297362001476\n",
      "-----Epoch:  250 -----\n",
      "Accuracy: 0.995\n",
      "Cost: 0.46317986242001735\n",
      "-----Epoch:  260 -----\n",
      "Accuracy: 0.996\n",
      "Cost: 0.4629620723336372\n",
      "-----Epoch:  270 -----\n",
      "Accuracy: 0.996\n",
      "Cost: 0.46275826172208373\n",
      "-----Epoch:  280 -----\n",
      "Accuracy: 0.996\n",
      "Cost: 0.46256839354180174\n",
      "-----Epoch:  290 -----\n",
      "Accuracy: 0.997\n",
      "Cost: 0.46240133191375254\n",
      "-----Epoch:  300 -----\n",
      "Accuracy: 0.997\n",
      "Cost: 0.46226689121469905\n",
      "-----Epoch:  310 -----\n",
      "Accuracy: 0.998\n",
      "Cost: 0.4621558079828789\n",
      "-----Epoch:  320 -----\n",
      "Accuracy: 0.998\n",
      "Cost: 0.4620694857820064\n",
      "-----Epoch:  330 -----\n",
      "Accuracy: 0.999\n",
      "Cost: 0.4619921392019459\n",
      "-----Epoch:  340 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.4619314451675284\n",
      "-----Epoch:  350 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.4618767259914324\n",
      "-----Epoch:  360 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.46183312576892754\n",
      "-----Epoch:  370 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.4617903499884454\n",
      "-----Epoch:  380 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.4617564281836696\n",
      "-----Epoch:  390 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.4617252178538819\n",
      "-----Epoch:  400 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.46169765602387086\n",
      "-----Epoch:  410 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.4616741852269039\n",
      "-----Epoch:  420 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.4616515329889504\n",
      "-----Epoch:  430 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.46163108156008364\n",
      "-----Epoch:  440 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.46161400267957853\n",
      "-----Epoch:  450 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.4615987823204522\n",
      "-----Epoch:  460 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.46158460849746386\n",
      "-----Epoch:  470 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.46157135389277815\n",
      "-----Epoch:  480 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.4615599972676094\n",
      "-----Epoch:  490 -----\n",
      "Accuracy: 1.0\n",
      "Cost: 0.4615490464835777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21a83e519d0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TRAINING MNIST WITH TWO HIDDEN LAYERS + BATCHES\n",
    "\n",
    "mnist_net_multipHidden_batches = NeuralNet('multi_logloss')\n",
    "mnist_net_multipHidden_batches.addLayer(64, 'reLu')\n",
    "mnist_net_multipHidden_batches.addLayer(64, 'reLu')\n",
    "mnist_net_multipHidden_batches.addLayer(10, 'softmax')\n",
    "costs, weights_multipHidden_batches = mnist_net_multipHidden_batches.fit(X_train, y_train, 500, 1000)\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-8d5d49bce8e2>:22: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(Z) / sum(np.exp(Z))\n",
      "<ipython-input-3-8d5d49bce8e2>:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(Z) / sum(np.exp(Z))\n"
     ]
    }
   ],
   "source": [
    "y_pred_multipHidden_batches = mnist_net_multipHidden_batches.predict(X_test)\n",
    "test_accuracy_multipHidden_batches = 100*np.sum(y_test == np.argmax(y_pred_multipHidden_batches, 0), axis=0) / X_test.shape[1]\n",
    "print(test_accuracy_multipHidden_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(img_index, net):\n",
    "    plt.imshow(X_test[:, img_index].reshape(28, 28))\n",
    "    print(np.argmax(net.predict(X_test[:, img_index].reshape(784, 1)), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(1001, mnist_net_multipHidden_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net = NeuralNet('multi_logloss')\n",
    "test_net.addLayer(64, 'reLu')\n",
    "test_net.addLayer(64, 'reLu')\n",
    "test_net.addLayer(10, 'softmax')\n",
    "test_net.set_weights(weights_multipHidden_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(999, test_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
